
# âš™ï¸ Hiperparametre Ayarlama (Hyperparameter Tuning)


<img width="608" height="317" alt="image" src="https://github.com/user-attachments/assets/b35a7f99-366f-4295-a34d-d69b927609d4" />

Åimdiye kadar modelleri varsayÄ±lan ayarlarÄ±yla eÄŸittik. Ancak her modelin, Ã¶ÄŸrenme sÃ¼recini kontrol eden ayarlamamÄ±z gereken dÃ¼ÄŸmeleri (hiperparametreleri) vardÄ±r.

* the notebook used through these lessons [here](https://colab.research.google.com/drive/1ylkEZoO__dkCAFlG2tikQHh34OuXlGcL?usp=sharing)
---

## 1ï¸âƒ£ Parametreler (Parameters) ve Hiperparametreler (Hyperparameters)

| ğŸ–¼ï¸ Kavram | TanÄ±m | Ã–rnek | Kontrol Eden |
| :--- | :--- | :--- | :--- |
| **Parametreler** | Model tarafÄ±ndan **eÄŸitim sÄ±rasÄ±nda Ã¶ÄŸrenilen** deÄŸerlerdir. | Lineer Regresyondaki **katsayÄ±lar** (coefficients). | Model (Veriden Ã¶ÄŸrenilir). |
| **Hiperparametreler** | Ã–ÄŸrenme sÃ¼recini kontrol etmek iÃ§in **eÄŸitimden Ã¶nce bizim tarafÄ±mÄ±zdan belirlenen** ayarlardÄ±r. | Karar AÄŸacÄ±nÄ±n **Maksimum DerinliÄŸi** (max_depth), kNN'deki **KomÅŸu SayÄ±sÄ±** (n_neighbors). | Veri Bilimcisi (Ã–nceden ayarlanÄ±r). |

### ğŸ§­ Temel Hiperparametre Ã–rnekleri

| Model | ğŸ› ï¸ Ã–rnek Hiperparametreler |
| :--- | :--- |
| **Karar AÄŸacÄ±** (Decision Tree) | **Maksimum Derinlik** (max_depth), **Minimum Ã–rnek BÃ¶lme** (min_samples_split) |
| **Rastgele Orman** (Random Forest) | **Tahminci SayÄ±sÄ±** (n_estimators - AÄŸaÃ§ sayÄ±sÄ±), **Maksimum Ã–zellik SayÄ±sÄ±** (max_features) |
| **kNN** | **KomÅŸu SayÄ±sÄ±** (n_neighbors), **UzaklÄ±k MetriÄŸi** (distance metric) |
| **Polinom Regresyon** (Polynomial Regression) | **Polinom Derecesi** (degree of polynomial) |

---

## 2ï¸âƒ£ âš ï¸ VarsayÄ±lan DeÄŸerlerin SorunlarÄ±

Hiperparametreleri doÄŸru seÃ§mek, bir makinenin ayarlarÄ±nÄ± doÄŸru yapmaya benzer. YanlÄ±ÅŸ ayarlar, modelin potansiyelinin altÄ±nda kalmasÄ±na neden olabilir.

| Senaryo | SonuÃ§ | Etkisi |
| :--- | :--- | :--- |
| **Ayarlar Ã§ok basit / dÃ¼ÅŸÃ¼k** | **Eksik Uyum** (Underfit) | Model Ã§ok basittir ve verideki kalÄ±plarÄ± yeterince yakalayamaz. DÃ¼ÅŸÃ¼k eÄŸitim ve test performansÄ±. |
| **Ayarlar Ã§ok karmaÅŸÄ±k / yÃ¼ksek** | **AÅŸÄ±rÄ± Uyum** (Overfit) | Model eÄŸitim verisine Ã§ok fazla Ã¶zelleÅŸir, yeni verilerde kÃ¶tÃ¼ performans gÃ¶sterir. YÃ¼ksek varyans. |
| **Verimsizlik** | Modelin yavaÅŸ Ã§alÄ±ÅŸmasÄ± | Ã–zellikle Rastgele Orman'da Ã§ok fazla aÄŸaÃ§ (n_estimators) kullanmak eÄŸitim sÃ¼resini uzatÄ±r. |

> **ğŸ’¡ Ana Ã‡Ä±karÄ±m:** **Ayarlama (Tuning)**, modelin yeni verilerde en yÃ¼ksek performansÄ± gÃ¶stermesi iÃ§in en iyi ayarlarÄ± bulmayÄ± amaÃ§lar.

### Rastgele Orman Ã–rneÄŸi

| Hiperparametre | DeÄŸer Durumu | Modelin DavranÄ±ÅŸÄ± |
| :--- | :--- | :--- |
| **AÄŸaÃ§ SayÄ±sÄ±** (n\_estimators) | **Ã‡ok Az** | Model yeterli karmaÅŸÄ±klÄ±ÄŸÄ± yakalayamayabilir, **eksik uyum** riski artar. |
| **AÄŸaÃ§ SayÄ±sÄ±** (n\_estimators) | **Ã‡ok Fazla** | Modelin Ã§alÄ±ÅŸma sÃ¼resi uzar; genellikle aÅŸÄ±rÄ± uyuma karÅŸÄ± dayanÄ±klÄ± olsa da gereksiz hesaplama maliyeti yaratÄ±r. |

---

## 3ï¸âƒ£ ğŸ› ï¸ Hiperparametre Ayarlama YÃ¶ntemleri

En iyi hiperparametre kombinasyonunu bulmak iÃ§in kullanÄ±lan yaygÄ±n yÃ¶ntemler ÅŸunlardÄ±r:

| ğŸ” YÃ¶ntem | AmaÃ§ |
| :--- | :--- |
| **Manuel Ayarlama** (Manual Tuning) | Veri bilimcisinin deneyimine dayalÄ± olarak ayarlarÄ± deneme yanÄ±lma ile deÄŸiÅŸtirmesi. |
| **Izgara AramasÄ±** (Grid Search) | Belirlenen tÃ¼m hiperparametre deÄŸerlerinin **her kombinasyonunu** sistematik olarak denemek. |
| **Rastgele Arama** (Random Search) | Hiperparametre aralÄ±ÄŸÄ±nda rastgele seÃ§ilen **bir alt kÃ¼mesini** denemek. Genellikle Grid Search'ten daha verimlidir. |
| **Arama ile Ã‡apraz DoÄŸrulama** (Cross-Validation with Search) | En iyi ayarlarÄ± bulurken, aÅŸÄ±rÄ± uyumu Ã¶nlemek ve sonuÃ§larÄ±n gÃ¼venilirliÄŸini artÄ±rmak iÃ§in **Ã‡apraz DoÄŸrulama** (Cross-Validation) tekniÄŸini kullanmak. |


# ğŸ› ï¸ Hiperparametre Ayarlama YÃ¶ntemleri I: Manuel ve Izgara AramasÄ±

<img width="585" height="370" alt="image" src="https://github.com/user-attachments/assets/ce7be888-6159-45de-9e7d-9f84055c6a63" />

Model performansÄ±nÄ± optimize etmek iÃ§in hiperparametreleri (hyperparameters) ayarlamak kritik Ã¶neme sahiptir. Ä°ÅŸte en yaygÄ±n iki yÃ¶ntem:

---

## 1ï¸âƒ£ ğŸ‘‹ Manuel Ayarlama (Manual Tuning)

| ğŸ–¼ï¸ Ã–zellik | AÃ§Ä±klama |
| :--- | :--- |
| **YÃ¶ntem** | En basit ancak en Ã§ok zaman alan yÃ¶ntemdir. Veri bilimcisi, hiperparametreleri **deneme-yanÄ±lma (trial and error)** yoluyla kendi deneyimine dayanarak ayarlar. |
| **Ã–rnek** | kNN modelinde en iyi sonucu veren `k` deÄŸerini (Ã¶rn. 3, 5, 7) tek tek test etmek. |
| **âœ… ArtÄ±larÄ±** | SÃ¼reÃ§ Ã¼zerinde **tam kontrole** sahip olursunuz. Sezgiseldir. |
| **âŒ Eksileri** | YavaÅŸ ve bÃ¼yÃ¼k, karmaÅŸÄ±k modeller iÃ§in **pratik deÄŸildir**. En iyi kombinasyonu bulamama riski yÃ¼ksektir, Ã§Ã¼nkÃ¼ sÄ±nÄ±rlÄ± sayÄ±da deneme yapÄ±lÄ±r. |

---

## 2ï¸âƒ£ ğŸŒ Izgara AramasÄ± (Grid Search)

| ğŸ–¼ï¸ Ã–zellik | AÃ§Ä±klama |
| :--- | :--- |
| **YÃ¶ntem** | Hiperparametre optimizasyonuna **sistematik** bir yaklaÅŸÄ±mdÄ±r. Her bir hiperparametre iÃ§in olasÄ± deÄŸerlerin bir listesini (bir Ä±zgara/grid) tanÄ±mlarsÄ±nÄ±z ve algoritma bu deÄŸerlerin **her kombinasyonunu** dener. |
| **Ã–rnek** | Rastgele Orman (Random Forest) iÃ§in `max_depth` (3, 5, 7) ve `n_estimators` (50, 100, 200) deÄŸerlerini tanÄ±mlamak. Izgara AramasÄ±, tÃ¼m $3 \times 3 = 9$ kombinasyonu da dener. |
| **AmacÄ±** | Eksik uyum (underfitting) ve aÅŸÄ±rÄ± uyum (overfitting) arasÄ±ndaki en iyi dengeyi saÄŸlayan kombinasyonu bulmaktÄ±r. |
| **âœ… ArtÄ±larÄ±** | **KapsamlÄ±dÄ±r**; belirlenen aralÄ±ktaki tÃ¼m olasÄ±lÄ±klarÄ±n test edilmesini garanti eder. En iyi performansÄ± veren kombinasyonu kesinlikle bulur. |
| **âŒ Eksileri** | **Ã‡ok yavaÅŸ** olabilir, Ã¶zellikle birden fazla hiperparametre ve geniÅŸ aralÄ±klar sÃ¶z konusuysa (kombinasyon sayÄ±sÄ± katlanarak artar). |

### ğŸ› ï¸ Grid Search Uygulama DetaylarÄ± (Scikit-learn)

| Parametre | TanÄ±m | AmaÃ§ |
| :--- | :--- | :--- |
| **estimator=tree\_model** | Ayarlamak istediÄŸiniz model (Ã¶rn. DecisionTreeRegressor). | Hangi modelin optimize edileceÄŸini tanÄ±mlar. |
| **param\_grid=param\_grid** | Denenecek hiperparametrelerin ve deÄŸerlerinin sÃ¶zlÃ¼ÄŸÃ¼ (dictionary). | Aranacak ayar kombinasyonlarÄ±nÄ± tanÄ±mlar. |
| **cv=5** | Her parametre kombinasyonu iÃ§in **5 katlÄ± Ã§apraz doÄŸrulama** (5-fold cross-validation) kullanÄ±lÄ±r. | SonuÃ§larÄ±n gÃ¼venilirliÄŸini artÄ±rÄ±r ve aÅŸÄ±rÄ± uyumu Ã¶nlemeye yardÄ±mcÄ± olur. |
| **scoring='neg\_mean\_squared\_error'** | KullanÄ±lan deÄŸerlendirme metriÄŸi (scoring metric). MSE'nin dÃ¼ÅŸÃ¼k olmasÄ± daha iyi olduÄŸu iÃ§in, scikit-learn bunu tersine Ã§evirir (`negative MSE`) bÃ¶ylece en yÃ¼ksek puan en iyi sonucu gÃ¶sterir. | Modellerin nasÄ±l sÄ±ralanacaÄŸÄ±nÄ± belirler. |
| **n\_jobs=-1** | EÄŸitim sÃ¼resini hÄ±zlandÄ±rmak iÃ§in tÃ¼m CPU Ã§ekirdeklerini (all CPU cores) paralel eÄŸitim iÃ§in kullanÄ±r. | SÃ¼reÃ§ verimliliÄŸini artÄ±rÄ±r. |
| **verbose=1** | Ã‡alÄ±ÅŸma ilerlemesini (progress) ekrana yazdÄ±rÄ±r. | KullanÄ±cÄ±nÄ±n ne olduÄŸunu gÃ¶rmesini saÄŸlar. |


# ğŸ’» Kod AÃ§Ä±klamasÄ±: GridSearchCV ile Karar AÄŸacÄ± Regresyonu Optimizasyonu

AÅŸaÄŸÄ±daki tablo, Karar AÄŸacÄ± Regresyon modelini (Decision Tree Regressor) optimize etmek iÃ§in kullanÄ±lan **Izgara AramasÄ± (Grid Search)** yÃ¶ntemine ait Python kod satÄ±rlarÄ±nÄ±n iÅŸlevlerini detaylÄ±ca aÃ§Ä±klamaktadÄ±r.

| Kod SatÄ±rÄ± (Code Line) | AÃ§Ä±klama (TÃ¼rkÃ§e) | AmaÃ§ (Goal) |
| :--- | :--- | :--- |
| `from sklearn.model_selection import GridSearchCV` | Gerekli KÃ¼tÃ¼phane Ä°thalatÄ±: Hiperparametre optimizasyonu iÃ§in scikit-learn'den `GridSearchCV` sÄ±nÄ±fÄ±nÄ± iÃ§e aktarÄ±r. | Izgara AramasÄ± algoritmasÄ±nÄ± kullanÄ±ma hazÄ±rlar. |
| `dt = DecisionTreeRegressor(random_state=42)` | Model TanÄ±mlama: Ayarlamak istediÄŸimiz temel model olan bir Karar AÄŸacÄ± Regresyonu (Decision Tree Regressor) nesnesi oluÅŸturulur. `random_state` ile sonuÃ§larÄ±n tekrarlanabilirliÄŸi saÄŸlanÄ±r. | Optimizasyon yapÄ±lacak temel modeli hazÄ±rlar. |
| `param_grid = {...}` | Arama IzgarasÄ± TanÄ±mlama: Denenecek hiperparametrelerin ve olasÄ± deÄŸerlerin listesi bir sÃ¶zlÃ¼k (`dictionary`) iÃ§inde tanÄ±mlanÄ±r. | Aranacak tÃ¼m olasÄ± kombinasyonlarÄ± (Ä±zgarayÄ±) oluÅŸturur. |
| `'max_depth': [3, 5, 10, 20, None]` | Karar aÄŸacÄ±nÄ±n maksimum derinliÄŸini kontrol eder. (`None` sÄ±nÄ±rsÄ±z derinlik demektir). | Model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± ve aÅŸÄ±rÄ± uyum riskini yÃ¶netir. |
| `'min_samples_split': [2, 5, 10]` | Bir dÃ¼ÄŸÃ¼mÃ¼ bÃ¶lmek iÃ§in gereken minimum Ã¶rnek sayÄ±sÄ±nÄ± belirler. | AÄŸacÄ±n ne kadar detaya ineceÄŸini kontrol eder. |
| `'min_samples_leaf': [1, 5, 10]` | Bir yaprak dÃ¼ÄŸÃ¼mde (leaf node) bulunmasÄ± gereken minimum Ã¶rnek sayÄ±sÄ±nÄ± belirler. | AÅŸÄ±rÄ± uyumu (overfitting) azaltmaya yardÄ±mcÄ± olur. |
| `'max_features': [None, 3, 5, 0.5, 0.8]` | En iyi bÃ¶lmeyi ararken gÃ¶z Ã¶nÃ¼nde bulundurulacak Ã¶zellik sayÄ±sÄ±nÄ±/oranÄ±nÄ± belirler. | AÄŸacÄ±n rastgeleliÄŸini ve varyansÄ±nÄ± kontrol eder. |
| `grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)` | Izgara AramasÄ± Kurulumu: `GridSearchCV` nesnesi kurulur; `cv=5` (5 katlÄ± Ã§apraz doÄŸrulama) ve `n_jobs=-1` (tÃ¼m CPU Ã§ekirdeklerini kullan) ayarlarÄ± verilir. | Arama sÃ¼recinin nasÄ±l iÅŸleyeceÄŸini yapÄ±landÄ±rÄ±r. |
| `scoring='neg_mean_squared_error'` | Her kombinasyonun performansÄ±nÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lan metriÄŸi belirler. MSE'nin dÃ¼ÅŸÃ¼k olmasÄ± daha iyi olduÄŸu iÃ§in, scikit-learn bunu tersine Ã§evirir (negatif MSE). | PerformansÄ±n nasÄ±l deÄŸerlendirileceÄŸini tanÄ±mlar. |
| `n_jobs=-1` | Ä°ÅŸlemi hÄ±zlandÄ±rmak iÃ§in tÃ¼m mevcut CPU Ã§ekirdeklerini paralel olarak kullanÄ±r. | Hesaplama sÃ¼resini optimize eder. |
| `verbose=1` | Ä°ÅŸlem sÄ±rasÄ±nda ilerlemeyi ekrana yazdÄ±rÄ±r. | KullanÄ±cÄ±nÄ±n sÃ¼reci takip etmesini saÄŸlar. |
| `grid_search.fit(X_train, y_train)` | EÄŸitim ve Arama: Izgara AramasÄ± baÅŸlatÄ±lÄ±r. TÃ¼m kombinasyonlar Ã‡apraz DoÄŸrulama (Cross-Validation) kullanÄ±larak test edilir. | En iyi parametre setini bulmak iÃ§in tÃ¼m kombinasyonlarÄ± test eder. |
| `print("Best Hyperparameters:", grid_search.best_params_)` | En Ä°yi AyarlarÄ±n Ã‡Ä±ktÄ±sÄ±: Ã‡apraz doÄŸrulama sonuÃ§larÄ±na gÃ¶re en yÃ¼ksek puanÄ± (best score) getiren hiperparametre deÄŸerlerini yazdÄ±rÄ±r. | En iyi optimize edilmiÅŸ parametre setini sunar. |
| `best_tree_model = grid_search.best_estimator_` | En Ä°yi EÄŸitilmiÅŸ Model: Izgara AramasÄ±nÄ±n bulduÄŸu en iyi hiperparametrelerle eÄŸitilmiÅŸ modeli kaydeder. | DeÄŸerlendirme iÃ§in optimize edilmiÅŸ modeli seÃ§er. |
| `y_pred = best_tree_model.predict(X_test)` | Tahmin: Optimize edilmiÅŸ model, gÃ¶rÃ¼lmemiÅŸ test verileri Ã¼zerinde tahminler yapmak iÃ§in kullanÄ±lÄ±r. | Modelin gerÃ§ek genelleme performansÄ±nÄ± Ã¶lÃ§meye hazÄ±rlar. |
| `evaluate(y_test, y_pred)` | SonuÃ§ Raporlama: GerÃ§ek deÄŸerler (`y_test`) ve tahminler (`y_pred`) kullanÄ±larak MAE, RMSE, $R^2$ gibi son performans metrikleri hesaplanÄ±r ve gÃ¶rÃ¼ntÃ¼lenir. | Optimizasyonun nihai etkisini Ã¶lÃ§er. |


# ğŸŒ Izgara AramasÄ± (Grid Search) ile Hiperparametre Ayarlama

Bu konu, Karar AÄŸacÄ± Regresyonu (Decision Tree Regression) Ã¼zerinden, modelin performansÄ±nÄ± sistematik olarak optimize etme yÃ¶ntemini (Grid Search) detaylÄ±ca aÃ§Ä±klamaktadÄ±r.

| ğŸ–¼ï¸ Kavram | AÃ§Ä±klama (TÃ¼rkÃ§e/Ä°ngilizce) | AmaÃ§ ve Vurgu |
| :--- | :--- | :--- |
| **Model TanÄ±mlama** | Ayarlanacak temel model (`DecisionTreeRegressor`) bir nesne olarak tanÄ±mlanÄ±r. | Optimizasyonun odak noktasÄ±nÄ± belirler. |
| **Arama IzgarasÄ±** (param\_grid) | Denenecek hiperparametrelerin (hyperparameters) ve her birine ait aday deÄŸer listelerinin tanÄ±mlandÄ±ÄŸÄ± sÃ¶zlÃ¼ktÃ¼r (dictionary). | Aranacak tÃ¼m olasÄ± kombinasyonlarÄ± (Grid) oluÅŸturur. |
| **Ã–rnek Hiperparametreler** | `max_depth` (Maksimum Derinlik), `min_samples_split` (Minimum BÃ¶lme Ã–rnek SayÄ±sÄ±), `max_features` (Maksimum Ã–zellik SayÄ±sÄ±). | Modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±, aÅŸÄ±rÄ± uyum (overfitting) ve eksik uyum (underfitting) dengesini kontrol etmek. |
| **GridSearchCV** | **Izgara AramasÄ± Ã‡apraz DoÄŸrulama** sÄ±nÄ±fÄ±dÄ±r. `estimator` (tahminci), `param_grid` (parametre Ä±zgarasÄ±) ve `cv` (Ã‡apraz DoÄŸrulama) ayarlarÄ± ile kurulur. | Belirtilen tÃ¼m kombinasyonlarÄ± sistematik olarak, gÃ¼venilirliÄŸi artÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde test eder. |
| **Ã‡apraz DoÄŸrulama** (cv) | `cv=5` deÄŸeri, her bir parametre kombinasyonunun 5 katlÄ± Ã§apraz doÄŸrulama (5-fold cross-validation) ile test edileceÄŸini belirtir. | SeÃ§ilen parametrelerin aÅŸÄ±rÄ± uyumlu (overfit) olmadÄ±ÄŸÄ±ndan ve genellenebilir (generalizable) olduÄŸundan emin olmak. |
| **Puanlama MetriÄŸi** (scoring) | `neg_mean_squared_error` kullanÄ±lÄ±r. MetriÄŸin tersine Ã§evrilmesiyle (negatif alÄ±narak), en yÃ¼ksek puan en iyi model anlamÄ±na gelir. | Modelleri karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lan objektif Ã¶lÃ§Ã¼tÃ¼ tanÄ±mlar. |
| **EÄŸitim** (fit) | `grid_search.fit(X_train, y_train)` komutu, arama sÃ¼recini baÅŸlatÄ±r. TÃ¼m kombinasyonlar denenir ve en iyi performansÄ± veren set bulunur. | Optimizasyon iÅŸlemini yÃ¼rÃ¼tÃ¼r ve en iyi parametreleri (best\_params\_) bulur. |
| **En Ä°yi Tahminci** (best\_estimator\_) | Izgara AramasÄ±nÄ±n bulduÄŸu en iyi hiperparametrelerle eÄŸitilmiÅŸ olan nihai modeldir. | Test verisi Ã¼zerinde genelleme performansÄ±nÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lan optimize edilmiÅŸ modeli temsil eder. |

---

### âœ… Ã–zet

**Izgara AramasÄ± (Grid Search)**, hiperparametre ayarlama sÃ¼recini otomatikleÅŸtirerek, manuel denemelerin zaman kaybÄ± olmadan bir modelin teorik olarak mÃ¼mkÃ¼n olan en iyi performansÄ±na ulaÅŸmasÄ±nÄ± saÄŸlar. Ancak, denenecek kombinasyon sayÄ±sÄ± arttÄ±kÃ§a sÃ¼re uzar.



# ğŸ² Hiperparametre Ayarlama YÃ¶ntemleri II: Rastgele Arama (Random Search)

<img width="633" height="336" alt="image" src="https://github.com/user-attachments/assets/38c8ecd6-a9f5-4b41-8773-7aecc377a02e" />

Rastgele Arama (Random Search), Izgara AramasÄ±'nÄ±n (Grid Search) zaman kÄ±sÄ±tlamalarÄ±nÄ± aÅŸmak iÃ§in geliÅŸtirilmiÅŸ, daha verimli bir optimizasyon yÃ¶ntemidir.

---

## 3ï¸âƒ£ ğŸ² Rastgele Arama (Random Search)

| ğŸ–¼ï¸ Ã–zellik | AÃ§Ä±klama (TÃ¼rkÃ§e/Ä°ngilizce) | AmaÃ§ ve Vurgu |
| :--- | :--- | :--- |
| **YÃ¶ntem** | Hiperparametre deÄŸerlerinin tÃ¼m kombinasyonlarÄ±nÄ± denemek yerine, **rastgele olarak seÃ§ilen** belirli sayÄ±da kombinasyonu test eder. | Deneme sayÄ±sÄ±nÄ± sÄ±nÄ±rlayarak, **Izgara AramasÄ±'ndan Ã§ok daha hÄ±zlÄ±** sonuÃ§ elde etmektir. |
| **Kapsam** | Rastgele seÃ§im sayesinde, belirlenen aralÄ±kta **geniÅŸ bir olasÄ±lÄ±k yelpazesini** kapsar. | En iyi kombinasyonu kaÃ§Ä±rma riski olsa da, genellikle makul bir sÃ¼rede "Ã§ok iyi" bir kombinasyon bulur. |
| **âœ… ArtÄ±larÄ±** | **Grid Search'ten Ã¶nemli Ã¶lÃ§Ã¼de daha hÄ±zlÄ±dÄ±r**. Ã–zellikle birÃ§ok hiperparametre veya geniÅŸ aralÄ±klar olduÄŸunda zaman tasarrufu saÄŸlar. | Hesaplama verimliliÄŸini maksimize eder. |
| **âŒ Eksileri** | Mutlak en iyi kombinasyonu (global optimum) kaÃ§Ä±rma riski vardÄ±r, Ã§Ã¼nkÃ¼ tÃ¼m olasÄ±lÄ±klar test edilmez. | KapsamlÄ±lÄ±k (Exhaustiveness) aÃ§Ä±sÄ±ndan Grid Search kadar titiz deÄŸildir. |

### ğŸš€ Rastgele Arama Ã‡alÄ±ÅŸma Ã–rneÄŸi

Random Search genellikle hÄ±z kazanmak iÃ§in verinin veya modelin kÃ¼Ã§Ã¼ltÃ¼lmesiyle birlikte kullanÄ±lÄ±r.

| Kod/AdÄ±m | AÃ§Ä±klama (TÃ¼rkÃ§e) | Vurgulanan AmaÃ§ |
| :--- | :--- | :--- |
| **Veri Alt KÃ¼mesi KullanÄ±mÄ±** | AramayÄ± daha da hÄ±zlandÄ±rmak iÃ§in eÄŸitim verisinin bir **alt kÃ¼mesi** (subset) kullanÄ±labilir. | Optimizasyonun erken aÅŸamalarÄ±nda hÄ±zlÄ± geri bildirim almak. |
| **KÃ¼Ã§Ã¼k Model EÄŸitimi** | AramayÄ± yaparken, daha hÄ±zlÄ± Ã§alÄ±ÅŸan (Ã¶rneÄŸin daha az aÄŸaca sahip `n_estimators=10` olan) bir Rastgele Orman (Random Forest) kullanÄ±lÄ±r. | Ä°lk aÅŸamada hÄ±z odaklÄ± optimizasyon yapmak. |
| **$cv=3$ ile GridSearchCV/RandomizedSearchCV** | Her kombinasyon iÃ§in 3 katlÄ± Ã§apraz doÄŸrulama (3-fold cross-validation) kullanÄ±lÄ±r. | AramanÄ±n hÄ±zÄ±na odaklanÄ±rken gÃ¼venilirliÄŸi korumak. |
| **Son Refit (Yeniden EÄŸitme)** | En iyi hiperparametreler bulunduktan sonra, bu en iyi ayarlar kullanÄ±larak **tÃ¼m veri** ve **daha bÃ¼yÃ¼k bir model** (Ã¶rn. `n_estimators=300`) yeniden eÄŸitilir. | HÄ±zlÄ± arama ile bulunan **en iyi ayarlarÄ±**, nihai, gÃ¼Ã§lÃ¼ model Ã¼zerinde uygulamak. |

### ğŸ› ï¸ GridSearchCV (Scikit-learn) Parametrelerinin TekrarÄ±

| Parametre | VurguladÄ±ÄŸÄ± Metrik |
| :--- | :--- |
| **estimator=tree\_model** | Ayarlanacak temel modeli belirtir. |
| **param\_grid=param\_grid** | Aranacak hiperparametre aralÄ±ÄŸÄ±nÄ± belirler. |
| **cv=3** | Her kombinasyonun 3 katlÄ± Ã‡apraz DoÄŸrulama (Cross-Validation) ile test edilmesini saÄŸlar. |
| **scoring='r2'** | Optimize edilecek deÄŸerlendirme metriÄŸini (bu Ã¶rnekte $R^2$) belirtir. |
| **n\_jobs=-1, verbose=1** | Ä°ÅŸlemcinin tÃ¼m Ã§ekirdeklerini kullanÄ±r ve sÃ¼reci ekrana yazar (paralellik ve izlenebilirlik). |

# âš™ï¸ HÄ±zlÄ± Hiperparametre Ayarlama (Fast Hyperparameter Tuning) Kod Analizi

Bu tablo, Rastgele Orman (Random Forest) modelinin optimizasyon sÃ¼recini hÄ±zlandÄ±rmak iÃ§in kullanÄ±lan ana Python sÄ±nÄ±flarÄ±nÄ± ve kritik hiperparametreleri aÃ§Ä±klamaktadÄ±r.

---

## ğŸš€ Fonksiyonlar ve Ana BileÅŸenler

| ğŸ–¼ï¸ BileÅŸen/SÄ±nÄ±f | Kod Ã–rneÄŸi | AÃ§Ä±klama (TÃ¼rkÃ§e/Ä°ngilizce) | AmaÃ§ ve Vurgu |
| :--- | :--- | :--- | :--- |
| **RandomForestRegressor** | `rf_fast`, `rf_final` | Rastgele Orman Regresyon modelini oluÅŸturur. Topluluk Ã¶ÄŸrenme (Ensemble learning) ile tahmin yapar. | Modelin temel yapÄ±sÄ±nÄ± ve tahmin mekanizmasÄ±nÄ± saÄŸlar. |
| **GridSearchCV** | `grid = GridSearchCV(...)` | Hiperparametre optimizasyonu iÃ§in **Izgara AramasÄ±** sÄ±nÄ±fÄ±dÄ±r. TanÄ±mlanan tÃ¼m kombinasyonlarÄ± sistematik olarak dener. | En iyi hiperparametre kombinasyonunu bulmak. |
| **train\_test\_split** | `train_test_split(X_train, y_train, train_size=0.5)` | BÃ¼yÃ¼k veri setini daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rmak veya veri setini eÄŸitim ve test olarak bÃ¶lmek iÃ§in kullanÄ±lÄ±r. | Optimizasyon sÃ¼resini kÄ±saltmak iÃ§in eÄŸitim verisinin bir **alt kÃ¼mesini (subset)** oluÅŸturmak. |
| **`**best_params`** | `**best_params` | Bir Python sÃ¶zlÃ¼ÄŸÃ¼nÃ¼n (dictionary) iÃ§eriÄŸini (anahtar:deÄŸer Ã§iftlerini) doÄŸrudan fonksiyon argÃ¼manlarÄ± olarak aÃ§ar (unpacking). | HÄ±zlÄ± aramada bulunan en iyi parametreleri (`grid.best_params_`) nihai modele otomatik olarak uygulamak. |

---

## ğŸ› ï¸ Regresyon Modeli Hiperparametreleri ve AyarlarÄ±

| Parametre/Ayar | DeÄŸer/Durum | AÃ§Ä±klama (TÃ¼rkÃ§e/Ä°ngilizce) | Vurgu |
| :--- | :--- | :--- | :--- |
| **`n_estimators`** (AÄŸaÃ§ SayÄ±sÄ±) | Arama: `10` <br> Final: `300` | Ormandaki karar aÄŸacÄ± (Decision Tree) sayÄ±sÄ±nÄ± belirler. | **HÄ±zlandÄ±rma Stratejisi:** Arama sÄ±rasÄ±nda az aÄŸaÃ§ (`10`) kullanÄ±p, final modelde en iyi performansÄ± almak iÃ§in Ã§ok aÄŸaÃ§ (`300`) kullanmak. |
| **`max_samples`** (Ã–rnek SayÄ±sÄ±) | Arama: `0.7` <br> Final: `None` | Her bir aÄŸacÄ±n eÄŸitim iÃ§in kullanacaÄŸÄ± veri satÄ±rlarÄ±nÄ±n oranÄ±nÄ±/sayÄ±sÄ±nÄ± belirler. | **HÄ±zlandÄ±rma Stratejisi:** Arama sÄ±rasÄ±nda her aÄŸacÄ±n satÄ±rlarÄ±n sadece %70'ini kullanmasÄ±. Final modelde tamamÄ±nÄ± kullanmak (`None`). |
| **`max_depth`** (Maks. Derinlik) | `[3, None]` | AÄŸacÄ±n maksimum derinliÄŸini sÄ±nÄ±rlar. (`None` = sÄ±nÄ±rsÄ±z). | Model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± ve aÅŸÄ±rÄ± uyum riskini yÃ¶netir. |
| **`min_samples_split`** | `[2, 10]` | Bir dÃ¼ÄŸÃ¼mÃ¼ bÃ¶lmek iÃ§in gereken minimum Ã¶rnek sayÄ±sÄ±. | AÄŸacÄ±n gereksiz detaylara inmesini engeller. |
| **`max_features`** | `[0.3, 0.6]` | En iyi bÃ¶lmeyi ararken rastgele seÃ§ilen Ã¶zelliklerin oranÄ±nÄ± belirler. | AÄŸaÃ§lar arasÄ±ndaki korelasyonu azaltarak modelin varyansÄ±nÄ± dÃ¼ÅŸÃ¼rmek (Random Forest'Ä±n temel Ã¶zelliÄŸi). |

---

## âš¡ Optimizasyon AyarlarÄ± (GridSearchCV Parametreleri)

| Parametre | DeÄŸer | AÃ§Ä±klama (TÃ¼rkÃ§e/Ä°ngilizce) | AmaÃ§ ve Fayda |
| :--- | :--- | :--- | :--- |
| **`cv`** (Ã‡apraz DoÄŸrulama) | `3` | Her kombinasyonun 3 katlÄ± Ã§apraz doÄŸrulama (3-fold Cross-Validation) ile test edilmesi. | **HÄ±zlandÄ±rma:** Daha az katlama (fold) kullanarak sÃ¼reyi kÄ±saltmak. |
| **`scoring`** (Puanlama MetriÄŸi) | `"r2"` | Optimizasyonun, en yÃ¼ksek $R^2$ skorunu bulmaya odaklanacaÄŸÄ±nÄ± belirtir. | Modelin aÃ§Ä±klayÄ±cÄ± gÃ¼cÃ¼nÃ¼ maksimize etme hedefi. |
| **`n_jobs`** (Ä°ÅŸlemci Ã‡ekirdeÄŸi) | `-1` | TÃ¼m mevcut CPU Ã§ekirdeklerini paralel eÄŸitim iÃ§in kullanÄ±r. | Ä°ÅŸlem sÃ¼resini dramatik ÅŸekilde hÄ±zlandÄ±rmak. |
| **`verbose`** | `0` | Ã‡alÄ±ÅŸma sÄ±rasÄ±nda Ã§Ä±ktÄ±larÄ±n (progress logs) minimum dÃ¼zeyde (veya hiÃ§) gÃ¶sterilmesi. | Konsol Ã§Ä±ktÄ±sÄ±nÄ± temiz tutmak. |



# ğŸ”„ Ã‡apraz DoÄŸrulama (Cross-Validation)

Ã‡apraz DoÄŸrulama, bir modelin performans tahmininin **gÃ¼venilirliÄŸini** artÄ±rmak ve tek bir eÄŸitim/test bÃ¶lmesinin getirdiÄŸi rastgele hatalardan kaÃ§Ä±nmak iÃ§in kullanÄ±lan temel bir tekniktir.

<img width="629" height="398" alt="image" src="https://github.com/user-attachments/assets/3853bcf3-3832-4e57-a8df-df7be71d6357" />

---

## 1ï¸âƒ£ Neden Ã‡apraz DoÄŸrulamaya (Cross-Validation) Ä°htiyaÃ§ DuyarÄ±z?

| Kavram | AÃ§Ä±klama | Risk |
| :--- | :--- | :--- |
| **Tek BÃ¶lme (Single Split)** | Veri setini yalnÄ±zca bir kez eÄŸitim (train) ve test (test) olarak ayÄ±rma. | Model deÄŸerlendirmesinin, **rastgele bir bÃ¶lmeye aÅŸÄ±rÄ± baÄŸÄ±mlÄ±** olmasÄ±. |
| **EÄŸitim Seti** (Train Set) | Modelin kalÄ±plarÄ± Ã¶ÄŸrendiÄŸi veri kÃ¼mesi. | EÄŸitim setinde iyi sonuÃ§, genellemeyi garanti etmez. |
| **Test Seti** (Test Set) | Modelin genelleme yeteneÄŸini kontrol ettiÄŸimiz gÃ¶rÃ¼lmemiÅŸ (unseen) veri kÃ¼mesi. | Test setinin ÅŸans eseri "Ã§ok kolay" veya "Ã§ok zor" olmasÄ±, performansÄ±mÄ±zÄ±n **yanÄ±ltÄ±cÄ±** gÃ¶rÃ¼nmesine neden olabilir. |

---

## 2ï¸âƒ£ K-KatlÄ± Ã‡apraz DoÄŸrulama (k-fold Cross-Validation) Nedir?

Ã‡apraz DoÄŸrulama, veriyi birden fazla parÃ§aya (kat/fold) bÃ¶lerek modelin gÃ¼venilir bir ÅŸekilde deÄŸerlendirilmesini saÄŸlayan bir tekniktir.

| AdÄ±m | AÃ§Ä±klama | Ã–rnek ($k=5$) |
| :--- | :--- | :--- |
| **1. BÃ¶lme** | Veri setini $k$ adet **eÅŸit parÃ§aya (kat/fold)** ayÄ±rÄ±n. | Veriyi 5 eÅŸit parÃ§aya bÃ¶lmek. |
| **2. Tekrarlama** | Ä°ÅŸlemi $k$ kez tekrarlayÄ±n. | 5 iterasyon (dÃ¶ngÃ¼) gerÃ§ekleÅŸtirilir. |
| **3. EÄŸitim/Test** | Her iterasyonda: $k-1$ katmanÄ±nÄ± **eÄŸitim** iÃ§in, kalan 1 katmanÄ± ise **test/doÄŸrulama** iÃ§in kullanÄ±n. | 4 parÃ§a ile modeli eÄŸitmek, 1 parÃ§a ile test etmek. |
| **4. Ortalama** | $k$ sonuÃ§ kÃ¼mesinin ortalamasÄ±nÄ± alÄ±n. | 5 farklÄ± test sonucunun ortalamasÄ±, modelin nihai ve daha **saÄŸlam (robust)** performans tahmini olur. |

> **â˜ï¸ Anahtar BaÄŸlantÄ±:** Ã‡apraz DoÄŸrulama, hiperparametre ayarlamasÄ± (hyperparameter tuning) ile birlikte kullanÄ±lÄ±r, Ã§Ã¼nkÃ¼ hiperparametrelerin yalnÄ±zca bir veri parÃ§asÄ±nda deÄŸil, verinin **farklÄ± bÃ¶lÃ¼mlerinde de iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan** emin olmaya yardÄ±mcÄ± olur.

### âœ… AvantajlarÄ± ve âŒ DezavantajlarÄ±

| Kategori | âœ… Avantajlar | âŒ Dezavantajlar |
| :--- | :--- | :--- |
| **GÃ¼venilirlik** | Performans tahminleri daha **saÄŸlam (robust)** ve gÃ¼venilirdir. | **Hesaplama Maliyeti:** Modeli bir kez yerine $k$ kez eÄŸitmeniz gerektiÄŸi iÃ§in daha maliyetlidir. |
| **Veri KullanÄ±mÄ±** | Veri setini daha verimli kullanÄ±r (her Ã¶rnek bir kez test setinde yer alÄ±r). | **Gereksizlik:** Ã‡ok bÃ¼yÃ¼k veri setleri iÃ§in her zaman gerekli deÄŸildir (tek bir eÄŸitim/test bÃ¶lmesi yeterli olabilir). |
| **KarÅŸÄ±laÅŸtÄ±rma** | Modelleri adil bir ÅŸekilde karÅŸÄ±laÅŸtÄ±rmaya yardÄ±mcÄ± olur. | |

---

## ğŸŒ Ã‡apraz DoÄŸrulama ve Hiperparametre Ayarlama UygulamasÄ±

Ã‡apraz DoÄŸrulama, Izgara AramasÄ± (Grid Search) veya Rastgele Arama (Random Search) gibi yÃ¶ntemlerin temelini oluÅŸturur.

### Uygulama Ã–rneÄŸi (Rastgele Orman)

| Hiperparametre | Aday DeÄŸerler | Toplam Kombinasyon | Grid Search + CV SÃ¼reci |
| :--- | :--- | :--- | :--- |
| **AÄŸaÃ§ SayÄ±sÄ±** (Number of Trees) | $[10, 50, 100]$ | $3 \times 3 = 9$ | Grid Search, bu 9 kombinasyonun her birini 5 katlÄ± Ã‡apraz DoÄŸrulama (CV) kullanarak test eder. |
| **Maks. Derinlik** (Max Depth) | $[5, 10, 15]$ | | Toplamda $9 \times 5 = 45$ eÄŸitim/test dÃ¶ngÃ¼sÃ¼ gerÃ§ekleÅŸtirilir. |

**SonuÃ§:** Ã‡apraz doÄŸrulama ile en dÃ¼ÅŸÃ¼k hatayÄ± veren (Ã¶rneÄŸin 50 aÄŸaÃ§ ve 10 derinlik) kombinasyon, en iyi hiperparametre seti olarak seÃ§ilir.


