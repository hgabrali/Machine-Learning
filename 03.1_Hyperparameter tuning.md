
# ⚙️ Hiperparametre Ayarlama (Hyperparameter Tuning)


<img width="608" height="317" alt="image" src="https://github.com/user-attachments/assets/b35a7f99-366f-4295-a34d-d69b927609d4" />

Şimdiye kadar modelleri varsayılan ayarlarıyla eğittik. Ancak her modelin, öğrenme sürecini kontrol eden ayarlamamız gereken düğmeleri (hiperparametreleri) vardır.

---

## 1️⃣ Parametreler (Parameters) ve Hiperparametreler (Hyperparameters)

| 🖼️ Kavram | Tanım | Örnek | Kontrol Eden |
| :--- | :--- | :--- | :--- |
| **Parametreler** | Model tarafından **eğitim sırasında öğrenilen** değerlerdir. | Lineer Regresyondaki **katsayılar** (coefficients). | Model (Veriden öğrenilir). |
| **Hiperparametreler** | Öğrenme sürecini kontrol etmek için **eğitimden önce bizim tarafımızdan belirlenen** ayarlardır. | Karar Ağacının **Maksimum Derinliği** (max_depth), kNN'deki **Komşu Sayısı** (n_neighbors). | Veri Bilimcisi (Önceden ayarlanır). |

### 🧭 Temel Hiperparametre Örnekleri

| Model | 🛠️ Örnek Hiperparametreler |
| :--- | :--- |
| **Karar Ağacı** (Decision Tree) | **Maksimum Derinlik** (max_depth), **Minimum Örnek Bölme** (min_samples_split) |
| **Rastgele Orman** (Random Forest) | **Tahminci Sayısı** (n_estimators - Ağaç sayısı), **Maksimum Özellik Sayısı** (max_features) |
| **kNN** | **Komşu Sayısı** (n_neighbors), **Uzaklık Metriği** (distance metric) |
| **Polinom Regresyon** (Polynomial Regression) | **Polinom Derecesi** (degree of polynomial) |

---

## 2️⃣ ⚠️ Varsayılan Değerlerin Sorunları

Hiperparametreleri doğru seçmek, bir makinenin ayarlarını doğru yapmaya benzer. Yanlış ayarlar, modelin potansiyelinin altında kalmasına neden olabilir.

| Senaryo | Sonuç | Etkisi |
| :--- | :--- | :--- |
| **Ayarlar çok basit / düşük** | **Eksik Uyum** (Underfit) | Model çok basittir ve verideki kalıpları yeterince yakalayamaz. Düşük eğitim ve test performansı. |
| **Ayarlar çok karmaşık / yüksek** | **Aşırı Uyum** (Overfit) | Model eğitim verisine çok fazla özelleşir, yeni verilerde kötü performans gösterir. Yüksek varyans. |
| **Verimsizlik** | Modelin yavaş çalışması | Özellikle Rastgele Orman'da çok fazla ağaç (n_estimators) kullanmak eğitim süresini uzatır. |

> **💡 Ana Çıkarım:** **Ayarlama (Tuning)**, modelin yeni verilerde en yüksek performansı göstermesi için en iyi ayarları bulmayı amaçlar.

### Rastgele Orman Örneği

| Hiperparametre | Değer Durumu | Modelin Davranışı |
| :--- | :--- | :--- |
| **Ağaç Sayısı** (n\_estimators) | **Çok Az** | Model yeterli karmaşıklığı yakalayamayabilir, **eksik uyum** riski artar. |
| **Ağaç Sayısı** (n\_estimators) | **Çok Fazla** | Modelin çalışma süresi uzar; genellikle aşırı uyuma karşı dayanıklı olsa da gereksiz hesaplama maliyeti yaratır. |

---

## 3️⃣ 🛠️ Hiperparametre Ayarlama Yöntemleri

En iyi hiperparametre kombinasyonunu bulmak için kullanılan yaygın yöntemler şunlardır:

| 🔍 Yöntem | Amaç |
| :--- | :--- |
| **Manuel Ayarlama** (Manual Tuning) | Veri bilimcisinin deneyimine dayalı olarak ayarları deneme yanılma ile değiştirmesi. |
| **Izgara Araması** (Grid Search) | Belirlenen tüm hiperparametre değerlerinin **her kombinasyonunu** sistematik olarak denemek. |
| **Rastgele Arama** (Random Search) | Hiperparametre aralığında rastgele seçilen **bir alt kümesini** denemek. Genellikle Grid Search'ten daha verimlidir. |
| **Arama ile Çapraz Doğrulama** (Cross-Validation with Search) | En iyi ayarları bulurken, aşırı uyumu önlemek ve sonuçların güvenilirliğini artırmak için **Çapraz Doğrulama** (Cross-Validation) tekniğini kullanmak. |


# 🛠️ Hiperparametre Ayarlama Yöntemleri I: Manuel ve Izgara Araması

<img width="585" height="370" alt="image" src="https://github.com/user-attachments/assets/ce7be888-6159-45de-9e7d-9f84055c6a63" />

Model performansını optimize etmek için hiperparametreleri (hyperparameters) ayarlamak kritik öneme sahiptir. İşte en yaygın iki yöntem:

---

## 1️⃣ 👋 Manuel Ayarlama (Manual Tuning)

| 🖼️ Özellik | Açıklama |
| :--- | :--- |
| **Yöntem** | En basit ancak en çok zaman alan yöntemdir. Veri bilimcisi, hiperparametreleri **deneme-yanılma (trial and error)** yoluyla kendi deneyimine dayanarak ayarlar. |
| **Örnek** | kNN modelinde en iyi sonucu veren `k` değerini (örn. 3, 5, 7) tek tek test etmek. |
| **✅ Artıları** | Süreç üzerinde **tam kontrole** sahip olursunuz. Sezgiseldir. |
| **❌ Eksileri** | Yavaş ve büyük, karmaşık modeller için **pratik değildir**. En iyi kombinasyonu bulamama riski yüksektir, çünkü sınırlı sayıda deneme yapılır. |

---

## 2️⃣ 🌐 Izgara Araması (Grid Search)

| 🖼️ Özellik | Açıklama |
| :--- | :--- |
| **Yöntem** | Hiperparametre optimizasyonuna **sistematik** bir yaklaşımdır. Her bir hiperparametre için olası değerlerin bir listesini (bir ızgara/grid) tanımlarsınız ve algoritma bu değerlerin **her kombinasyonunu** dener. |
| **Örnek** | Rastgele Orman (Random Forest) için `max_depth` (3, 5, 7) ve `n_estimators` (50, 100, 200) değerlerini tanımlamak. Izgara Araması, tüm $3 \times 3 = 9$ kombinasyonu da dener. |
| **Amacı** | Eksik uyum (underfitting) ve aşırı uyum (overfitting) arasındaki en iyi dengeyi sağlayan kombinasyonu bulmaktır. |
| **✅ Artıları** | **Kapsamlıdır**; belirlenen aralıktaki tüm olasılıkların test edilmesini garanti eder. En iyi performansı veren kombinasyonu kesinlikle bulur. |
| **❌ Eksileri** | **Çok yavaş** olabilir, özellikle birden fazla hiperparametre ve geniş aralıklar söz konusuysa (kombinasyon sayısı katlanarak artar). |

### 🛠️ Grid Search Uygulama Detayları (Scikit-learn)

| Parametre | Tanım | Amaç |
| :--- | :--- | :--- |
| **estimator=tree\_model** | Ayarlamak istediğiniz model (örn. DecisionTreeRegressor). | Hangi modelin optimize edileceğini tanımlar. |
| **param\_grid=param\_grid** | Denenecek hiperparametrelerin ve değerlerinin sözlüğü (dictionary). | Aranacak ayar kombinasyonlarını tanımlar. |
| **cv=5** | Her parametre kombinasyonu için **5 katlı çapraz doğrulama** (5-fold cross-validation) kullanılır. | Sonuçların güvenilirliğini artırır ve aşırı uyumu önlemeye yardımcı olur. |
| **scoring='neg\_mean\_squared\_error'** | Kullanılan değerlendirme metriği (scoring metric). MSE'nin düşük olması daha iyi olduğu için, scikit-learn bunu tersine çevirir (`negative MSE`) böylece en yüksek puan en iyi sonucu gösterir. | Modellerin nasıl sıralanacağını belirler. |
| **n\_jobs=-1** | Eğitim süresini hızlandırmak için tüm CPU çekirdeklerini (all CPU cores) paralel eğitim için kullanır. | Süreç verimliliğini artırır. |
| **verbose=1** | Çalışma ilerlemesini (progress) ekrana yazdırır. | Kullanıcının ne olduğunu görmesini sağlar. |


# 💻 Kod Açıklaması: GridSearchCV ile Karar Ağacı Regresyonu Optimizasyonu

Aşağıdaki tablo, Karar Ağacı Regresyon modelini (Decision Tree Regressor) optimize etmek için kullanılan **Izgara Araması (Grid Search)** yöntemine ait Python kod satırlarının işlevlerini detaylıca açıklamaktadır.

| Kod Satırı (Code Line) | Açıklama (Türkçe) | Amaç (Goal) |
| :--- | :--- | :--- |
| `from sklearn.model_selection import GridSearchCV` | Gerekli Kütüphane İthalatı: Hiperparametre optimizasyonu için scikit-learn'den `GridSearchCV` sınıfını içe aktarır. | Izgara Araması algoritmasını kullanıma hazırlar. |
| `dt = DecisionTreeRegressor(random_state=42)` | Model Tanımlama: Ayarlamak istediğimiz temel model olan bir Karar Ağacı Regresyonu (Decision Tree Regressor) nesnesi oluşturulur. `random_state` ile sonuçların tekrarlanabilirliği sağlanır. | Optimizasyon yapılacak temel modeli hazırlar. |
| `param_grid = {...}` | Arama Izgarası Tanımlama: Denenecek hiperparametrelerin ve olası değerlerin listesi bir sözlük (`dictionary`) içinde tanımlanır. | Aranacak tüm olası kombinasyonları (ızgarayı) oluşturur. |
| `'max_depth': [3, 5, 10, 20, None]` | Karar ağacının maksimum derinliğini kontrol eder. (`None` sınırsız derinlik demektir). | Model karmaşıklığını ve aşırı uyum riskini yönetir. |
| `'min_samples_split': [2, 5, 10]` | Bir düğümü bölmek için gereken minimum örnek sayısını belirler. | Ağacın ne kadar detaya ineceğini kontrol eder. |
| `'min_samples_leaf': [1, 5, 10]` | Bir yaprak düğümde (leaf node) bulunması gereken minimum örnek sayısını belirler. | Aşırı uyumu (overfitting) azaltmaya yardımcı olur. |
| `'max_features': [None, 3, 5, 0.5, 0.8]` | En iyi bölmeyi ararken göz önünde bulundurulacak özellik sayısını/oranını belirler. | Ağacın rastgeleliğini ve varyansını kontrol eder. |
| `grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)` | Izgara Araması Kurulumu: `GridSearchCV` nesnesi kurulur; `cv=5` (5 katlı çapraz doğrulama) ve `n_jobs=-1` (tüm CPU çekirdeklerini kullan) ayarları verilir. | Arama sürecinin nasıl işleyeceğini yapılandırır. |
| `scoring='neg_mean_squared_error'` | Her kombinasyonun performansını ölçmek için kullanılan metriği belirler. MSE'nin düşük olması daha iyi olduğu için, scikit-learn bunu tersine çevirir (negatif MSE). | Performansın nasıl değerlendirileceğini tanımlar. |
| `n_jobs=-1` | İşlemi hızlandırmak için tüm mevcut CPU çekirdeklerini paralel olarak kullanır. | Hesaplama süresini optimize eder. |
| `verbose=1` | İşlem sırasında ilerlemeyi ekrana yazdırır. | Kullanıcının süreci takip etmesini sağlar. |
| `grid_search.fit(X_train, y_train)` | Eğitim ve Arama: Izgara Araması başlatılır. Tüm kombinasyonlar Çapraz Doğrulama (Cross-Validation) kullanılarak test edilir. | En iyi parametre setini bulmak için tüm kombinasyonları test eder. |
| `print("Best Hyperparameters:", grid_search.best_params_)` | En İyi Ayarların Çıktısı: Çapraz doğrulama sonuçlarına göre en yüksek puanı (best score) getiren hiperparametre değerlerini yazdırır. | En iyi optimize edilmiş parametre setini sunar. |
| `best_tree_model = grid_search.best_estimator_` | En İyi Eğitilmiş Model: Izgara Aramasının bulduğu en iyi hiperparametrelerle eğitilmiş modeli kaydeder. | Değerlendirme için optimize edilmiş modeli seçer. |
| `y_pred = best_tree_model.predict(X_test)` | Tahmin: Optimize edilmiş model, görülmemiş test verileri üzerinde tahminler yapmak için kullanılır. | Modelin gerçek genelleme performansını ölçmeye hazırlar. |
| `evaluate(y_test, y_pred)` | Sonuç Raporlama: Gerçek değerler (`y_test`) ve tahminler (`y_pred`) kullanılarak MAE, RMSE, $R^2$ gibi son performans metrikleri hesaplanır ve görüntülenir. | Optimizasyonun nihai etkisini ölçer. |


# 🌐 Izgara Araması (Grid Search) ile Hiperparametre Ayarlama

Bu konu, Karar Ağacı Regresyonu (Decision Tree Regression) üzerinden, modelin performansını sistematik olarak optimize etme yöntemini (Grid Search) detaylıca açıklamaktadır.

| 🖼️ Kavram | Açıklama (Türkçe/İngilizce) | Amaç ve Vurgu |
| :--- | :--- | :--- |
| **Model Tanımlama** | Ayarlanacak temel model (`DecisionTreeRegressor`) bir nesne olarak tanımlanır. | Optimizasyonun odak noktasını belirler. |
| **Arama Izgarası** (param\_grid) | Denenecek hiperparametrelerin (hyperparameters) ve her birine ait aday değer listelerinin tanımlandığı sözlüktür (dictionary). | Aranacak tüm olası kombinasyonları (Grid) oluşturur. |
| **Örnek Hiperparametreler** | `max_depth` (Maksimum Derinlik), `min_samples_split` (Minimum Bölme Örnek Sayısı), `max_features` (Maksimum Özellik Sayısı). | Modelin karmaşıklığını, aşırı uyum (overfitting) ve eksik uyum (underfitting) dengesini kontrol etmek. |
| **GridSearchCV** | **Izgara Araması Çapraz Doğrulama** sınıfıdır. `estimator` (tahminci), `param_grid` (parametre ızgarası) ve `cv` (Çapraz Doğrulama) ayarları ile kurulur. | Belirtilen tüm kombinasyonları sistematik olarak, güvenilirliği artırılmış bir şekilde test eder. |
| **Çapraz Doğrulama** (cv) | `cv=5` değeri, her bir parametre kombinasyonunun 5 katlı çapraz doğrulama (5-fold cross-validation) ile test edileceğini belirtir. | Seçilen parametrelerin aşırı uyumlu (overfit) olmadığından ve genellenebilir (generalizable) olduğundan emin olmak. |
| **Puanlama Metriği** (scoring) | `neg_mean_squared_error` kullanılır. Metriğin tersine çevrilmesiyle (negatif alınarak), en yüksek puan en iyi model anlamına gelir. | Modelleri karşılaştırmak için kullanılan objektif ölçütü tanımlar. |
| **Eğitim** (fit) | `grid_search.fit(X_train, y_train)` komutu, arama sürecini başlatır. Tüm kombinasyonlar denenir ve en iyi performansı veren set bulunur. | Optimizasyon işlemini yürütür ve en iyi parametreleri (best\_params\_) bulur. |
| **En İyi Tahminci** (best\_estimator\_) | Izgara Aramasının bulduğu en iyi hiperparametrelerle eğitilmiş olan nihai modeldir. | Test verisi üzerinde genelleme performansını ölçmek için kullanılan optimize edilmiş modeli temsil eder. |

---

### ✅ Özet

**Izgara Araması (Grid Search)**, hiperparametre ayarlama sürecini otomatikleştirerek, manuel denemelerin zaman kaybı olmadan bir modelin teorik olarak mümkün olan en iyi performansına ulaşmasını sağlar. Ancak, denenecek kombinasyon sayısı arttıkça süre uzar.
