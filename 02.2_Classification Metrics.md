# Classification Metrics

# 📉 Model Değerlendirmesi: Bir Modelin İyi Olduğunu Nasıl Anlarız?

Model değerlendirmesi, bir makine öğrenimi modelinin gerçek dünya verilerinde ne kadar iyi performans gösterdiğini anlamak için kritik öneme sahiptir. Yalnızca tahmin yapması yeterli değildir; bu tahminlerin **kullanışlı** ve **güvenilir** olması gerekir.

---

## 📋 Temel Kavramlar ve Metrikler Tablosu

| Konu/Başlık | Açıklama | Görsel/Emoji |
| :--- | :--- | :--- |
| **Değerlendirmenin Önemi** | Bir modelin her zaman tahmin yapabilmesine rağmen, tüm tahminler kullanışlı değildir. Örneğin, bir modelin hayatta kalma oranının %62 olduğu Titanic verisinde "herkes öldü" demesi %62 doğruluk sağlar ancak **hayatta kalanları asla bulamadığı için işe yaramaz** bir modeldir. Bu, doğru metriklerin önemini gösterir. | 🚢🤷‍♀️ |
| **Veri Bölme: Eğitim vs. Test** | Modeli değerlendirmeden önce, görmediği veriler üzerinde test edildiğinden emin olmalıyız. Veri seti ikiye ayrılır: <ul><li>**Eğitim Seti:** Modeli **öğretmek** için kullanılır.</li><li>**Test Seti:** Modelin **yeni verilerdeki** performansını kontrol etmek için kullanılır.</li></ul>Aynı veride test etmek, modelin cevapları ezberlemesine ($\approx$ **Aşırı Uyum/Overfitting**) yol açar ve gerçek performansı göstermez. | 🧠➡️📝 |
| **Sınıflandırma Metriği: Doğruluk (Accuracy)** | En basit sınıflandırma değerlendirme metriğidir. Modelin **doğru yaptığı tahminlerin yüzdesidir.** <ul><li>**Formül:** $\text{Doğruluk} = \frac{\text{Doğru Tahmin Sayısı}}{\text{Toplam Tahmin Sayısı}}$</li><li>**Örnek:** 100 tahminden 85'i doğruysa, Doğruluk = %85.</li></ul> | ✅💯 |
| **⚠️ Doğruluk (Accuracy) ile İlgili Sorunlar** | Doğruluk iyi bir başlangıç olsa da, birçok durumda **yanıltıcı** olabilir ve daha detaylı araçlar (örn. Karışıklık Matrisi) gerektirir: | 🚨❌ |
| **Dengesiz Veri (Imbalanced Data)** | Veri sınıfları arasında büyük fark varsa (örn. dolandırıcılık tespiti: %99 "dolandırıcılık değil"), modelin her zaman "dolandırıcılık değil" tahmin etmesi %99 doğruluk verir, ancak **dolandırıcılığı asla yakalamadığı için işe yaramaz.** | ⚖️📉 |
| **Farklı Hata Maliyetleri** | Hatalar her zaman eşit derecede kötü değildir. Tıbbi teşhiste, hasta birini sağlıklı tahmin etmek (**yanlış negatif**) **hayatî tehlike** yaratabilirken, sağlıklı birini hasta tahmin etmek (**yanlış pozitif**) sadece rahatsızlık verir. Doğruluk bu hatalar arasındaki farkı gözetmez. | 🩺💔 |
| **Modelin Nerede Başarısız Olduğunu Gizlemesi** | Doğruluk tek bir sayı verir. Modelin yaptığı hataların **türünü** (örn. Titanic'te hayatta kalanı mı kaçırıyor, yoksa öleni mi yanlış tahmin ediyor?) göstermez. | 🔎❓ |
| **Sınıf Dağılımı Değişikliklerine Duyarsızlık** | Sınıflar arasındaki denge zamanla değişirse (örn. dolandırıcılık %1'den %10'a çıkarsa), önceden "doğru" görünen bir model aniden kötü performans gösterebilir. Doğruluk bu değişimi tek başına yeterince hızlı bir şekilde uyarmayabilir. | 🔄📢 |

# Confusion Matrix

<img width="567" height="330" alt="image" src="https://github.com/user-attachments/assets/e12e9ef5-0d47-466b-84d1-b92a347b8d9a" />

A **confusion matrix** is a simple table that shows how many predictions your model got right, and what kinds of errors it made.

# 📊 Karışıklık Matrisi (Confusion Matrix) Nedir?

Karışıklık Matrisi, bir sınıflandırma modelinin yaptığı doğru tahminlerin sayısını ve **ne tür hatalar** yaptığını gösteren basit ama güçlü bir tablodur. Modelin performansına dair **tam bir resim** sunar.

---

## 🧭 Karışıklık Matrisinin Yapısı ve Mantığı

| Kavram | Açıklama | Örnek Durum (Spam Tespiti) | Sonuç/Durum | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **Doğru Pozitif (TP)** | Model, pozitif sınıfı **doğru** tahmin etti. | Model, bir e-postayı **SPAM** olarak tahmin etti ve e-posta **gerçekten SPAM'di**. | Başarı, Doğru Tespit | ✅🎯 |
| **Doğru Negatif (TN)** | Model, negatif sınıfı **doğru** tahmin etti. | Model, bir e-postayı **SPAM DEĞİL** olarak tahmin etti ve e-posta **gerçekten SPAM DEĞİLDİ**. | Başarı, Doğru Reddetme | ✅🛡️ |
| **Yanlış Pozitif (FP)** | Model pozitif tahmin etti, ancak **gerçekte negatif'ti** ("Yanlış Alarm"). | Model, bir e-postayı **SPAM** olarak tahmin etti ancak e-posta **gerçekte SPAM DEĞİLDİ** (Önemli bir e-postanın kaçırılması). | Hata (Tip I), Yanlış Alarm | 🛑🔔 |
| **Yanlış Negatif (FN)** | Model negatif tahmin etti, ancak **gerçekte pozitif'ti** ("Gözden Kaçırma"). | Model, bir e-postayı **SPAM DEĞİL** olarak tahmin etti ancak e-posta **gerçekte SPAM'di** (Gereksiz e-postanın gelen kutusuna düşmesi). | Hata (Tip II), Gözden Kaçırma | ❌🙈 |

---

## ⚙️ Karışıklık Matrisi Nasıl Çalışır?

1. **Tahmin Üretme:** Modelinizden test verileri için tahminler ($y_{tahmin}$) alırsınız.
2. **Karşılaştırma:** Bu tahminleri, verinin **gerçek etiketleri** ($y_{gerçek}$) ile tek tek karşılaştırırsınız.
3. **Kategorilendirme:** Her bir tahmin, gerçek etikete göre TP, TN, FP veya FN kategorilerinden birine yerleştirilir.

Modelin yalnızca **doğru mu yanlış mı** tahmin ettiğine değil; **ne tür bir hata** yaptığına (Yanlış Pozitif mi, Yanlış Negatif mi) odaklanılır.

### Örnek Tablo Düzeni

Karışıklık matrisinin geleneksel yapısı (etiketlerin yerleşimi farklı kaynaklarda değişebilir, ancak mantık aynı kalır):

| | **Tahmin Edilen Pozitif** | **Tahmin Edilen Negatif** |
| :--- | :--- | :--- |
| **Gerçek Pozitif** | **Doğru Pozitif (TP)** | **Yanlış Negatif (FN)** |
| **Gerçek Negatif** | **Yanlış Pozitif (FP)** | **Doğru Negatif (TN)** |

> **Unutmayın:** Bazı kaynaklar satırları "Gerçek" ve sütunları "Tahmin Edilen" olarak alırken, bazıları tam tersini kullanır. Önemli olan, her hücredeki tanımın (TP, TN, FP, FN) neyi temsil ettiğini anlamaktır.
>
> # 🔍 Karışıklık Matrisi Uygulamaları: Dolandırıcılık vs. Spam

Karışıklık Matrisi, iki farklı ikili sınıflandırma probleminde (Dolandırıcılık Tespiti ve Spam Sınıflandırması) modelin yaptığı hataların türlerini ve önem derecelerini anlamak için kullanılır.

---

## 🔬 Karşılaştırmalı Hata Analizi Tablosu

| Kavram | Tipi | 1. Örnek: Dolandırıcılık Tespiti (Pozitif = Dolandırıcılık) | 2. Örnek: Spam Sınıflandırması (Pozitif = Spam) | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **Doğru Pozitif (TP)** | ✅ Doğru Tahmin | **Gerçek Dolandırıcılık** doğru şekilde **DOLANDIRICILIK** olarak işaretlendi. | **Gerçek Spam** doğru şekilde **SPAM** olarak işaretlendi. | 🎯💰 |
| **Doğru Negatif (TN)** | ✅ Doğru Tahmin | **Normal İşlem** doğru şekilde **NORMAL** olarak tanımlandı. | **Gerçek E-posta** doğru şekilde **SPAM DEĞİL** olarak sınıflandırıldı. | 🛡️📧 |
| **Yanlış Pozitif (FP)** | ❌ Tip 1 Hata | **Normal İşlem** yanlışlıkla **DOLANDIRICILIK** olarak işaretlendi. (Yanlış Alarm). | **Gerçek E-posta** yanlışlıkla **SPAM** olarak işaretlendi. (Kullanıcı için can sıkıcı). | 🔔🛑 |
| **Yanlış Negatif (FN)** | ❌ Tip 2 Hata | **Gerçek Dolandırıcılık** yanlışlıkla **NORMAL** işlem olarak gözden kaçırıldı. (Kaçırılan Vaka). | **Gerçek Spam** yanlışlıkla **SPAM DEĞİL** olarak sınıflandırıldı. (Gelen kutusuna düşen spam, **tehlikeli**). | 🚨🙈 |

---

## ⚖️ Hata Türlerinin Önemi ve Ölçeklendirme

### 1. Dolandırıcılık Tespiti Bağlamı

* **Pozitif Sınıf:** Dolandırıcılık (`Fraud`).
* **Önem:** **Gerçek dolandırıcılığı yakalamak (TP)**, yanlış alarm vermekten (FP) daha önemlidir.
* **FN Maliyeti:** Modelin gerçek dolandırıcılığı kaçırması büyük finansal kayıplara yol açabilir.

### 2. Spam Sınıflandırması Bağlamı

* **Pozitif Sınıf:** Spam.
* **FP Maliyeti:** Gerçek bir e-postanın spam kutusuna düşmesi (**FP**), kullanıcının önemli bilgileri kaçırmasına neden olur (Can sıkıcı).
* **FN Maliyeti:** Bir spam e-postanın gelen kutusuna düşmesi (**FN**), kullanıcıyı potansiyel tehlikeye (kimlik avı, virüs) maruz bırakır (Tehlikeli).

### Sonraki Adımlar

Karışıklık Matrisi, doğru ve yanlış tahminlerin **mutlak sayılarını** gösterir. Bu, haftalık bazda kaç e-postanın yanlışlıkla spam'e gönderildiği gibi ölçek hakkında fikir edinmek için kullanışlıdır.

Ancak, modelleri karşılaştırmak veya zaman içindeki performanslarını izlemek için **mutlak sayılar yerine göreceli metrikler** gereklidir. Bu kalite metrikleri (Doğruluk, Duyarlılık/Recall, Kesinlik/Precision, F1 Skoru) doğrudan Karışıklık Matrisi'nden türetilebilir.

---
# 🌟 Karışıklık Matrisi (Confusion Matrix) Neden Kullanışlıdır?

Doğruluk (Accuracy) tek bir sayı verirken, Karışıklık Matrisi, modelin performansına dair çok daha derin ve eyleme geçirilebilir bir bakış açısı sunar. Modelin **ne tür hatalar yaptığını** ve hangi sınıfta daha başarılı olduğunu detaylandırır.

---

## 🔑 Karışıklık Matrisinin Sağladığı Temel Avantajlar Tablosu

| Sağladığı Bilgi | Açıklama | Doğruluk'tan (Accuracy) Farkı | Emoji |
| :--- | :--- | :--- | :--- |
| **Hata Türlerini Ayırt Etme** | Modelin yaptığı hataların türünü gösterir: **Yanlış Pozitif (FP)** (Yanlış Alarm) mı daha fazla, yoksa **Yanlış Negatif (FN)** (Gözden Kaçırma) mı? Bu, probleme göre hangi hatanın maliyetinin daha yüksek olduğunu anlamamızı sağlar. | Doğruluk, tüm yanlış tahminleri tek bir 'hata' olarak sayar. | 🚨🔎 |
| **Sınıf Bazında Performans** | Modelin belirli bir sınıfı (örneğin, Titanic'te hayatta kalanlar) bulmakta mı yoksa diğer sınıfı (hayatta kalmayanlar) bulmakta mı daha iyi olduğunu netleştirir. | Doğruluk, modelin sınıf dağılımına olan hassasiyetini gizler. | 📊🎯 |
| **Gelişmiş Metriklere Temel** | Doğrudan Karışıklık Matrisi'nden **Kesinlik (Precision)**, **Duyarlılık (Recall)** ve **F1 Skoru** gibi daha güçlü ve dengesiz veri setlerinde dahi anlamlı olan metrikler türetilebilir. | Doğruluk, bu karmaşık metriklerin bileşenlerini sağlamaz. | ➕📐 |
| **Ölçek Hissi** | Hataların ve doğru tahminlerin **mutlak sayılarını** göstererek, problem ölçeği hakkında fikir verir. (*Örn: "Geçen hafta 500 gerçek dolandırıcılığı kaçırdık (FN)."*) | Doğruluk sadece yüzde verir, mutlak sayıları göstermez. | 🔢📏 |

---

## 💡 Örnek Kullanım Durumu: Titanic

| Durum | Karışıklık Matrisi Nasıl Yardımcı Olur? |
| :--- | :--- |
| **Amaç:** Hayatta kalanları bulmak kritik öneme sahiptir. | Matris, modelin kaç tane gerçek hayatta kalanı kaçırdığını (**FN**) ve kaç tane hayatta kalmayanı yanlışlıkla hayatta kaldı diye tahmin ettiğini (**FP**) gösterir. |
| **Analiz:** Modeliniz yüksek bir **FN** sayısına sahipse (çok sayıda hayatta kalanı kaçırıyorsa), bu, **Duyarlılık (Recall)** metriğinin düşük olacağı anlamına gelir. Bu bilgiyle modeli iyileştirmeye odaklanabilirsiniz. |

**Sonuç:** Karışıklık Matrisi, sadece **"ne kadar doğru"** sorusunu değil, aynı zamanda **"ne tür hatalar yapıyor ve hangi sınıflarda başarılı?"** sorusunu da yanıtlayarak model değerlendirmesini bir sonraki seviyeye taşır.





# 🔬 Karışıklık Matrisi'nin (Confusion Matrix) Matematiksel Kökeni

Karışıklık Matrisi (Confusion Matrix), doğrudan belirli bir olasılık başlığından esinlenmek yerine, **sınıflandırma performansını ölçme** ihtiyacından doğmuştur. Ancak, temel mantığı istatistik ve karar teorisindeki köklü kavramlarla yakından ilişkilidir.

---

## 1. 🥇 Ana İlişkili Başlık: Hipotez Testi ve Hata Türleri

Karışıklık Matrisi'nin temelindeki matematiksel ve istatistiksel mantık, en güçlü şekilde **Hipotez Testi** ve bu testlerde ortaya çıkan hata türleri ile ilişkilidir.

| Karışıklık Matrisi Kavramı | Hipotez Testi Karşılığı | İstatistiksel Gösterim | Açıklama | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **Yanlış Pozitif (FP)** | **Tip I Hata (False Alarm)** | Alfa ($\alpha$) | Boş hipotezin ($H_0$) **doğru olduğu halde** reddedilmesi. (*Örnek: Model, normal bir işlemi dolandırıcılık diye reddetti.*) | 🚨❌ |
| **Yanlış Negatif (FN)** | **Tip II Hata (Missed Case)** | Beta ($\beta$) | Boş hipotezin ($H_0$) **yanlış olduğu halde** reddedilememesi. (*Örnek: Model, gerçek dolandırıcılığı normal işlem diye gözden kaçırdı.*) | 🙈⚠️ |

**Sonuç:** Karışıklık Matrisi, sınıflandırma problemini, **hata maliyetlerinin** değerlendirildiği bir **Hipotez Testi** çerçevesine oturtan somut bir uygulamadır.

---

## 2. 📚 Esin Kaynağı Olabilecek Diğer Temel Alanlar

Karışıklık Matrisi'nin geliştirilmesi ve yaygınlaşması, genel olarak şu disiplinlerde kök salmıştır:

| Alan/Kavram | Açıklama | Emoji |
| :--- | :--- | :--- |
| **Karar Teorisi** | Bir kararın (pozitif/negatif tahmin) hem doğru hem de yanlış sonuçlarının **maliyetini ve faydasını** değerlendirir. Matris, bu kararların sonuçlarını kategorize etmemizi sağlar. | 🧠⚖️ |
| **İkili Sınıflandırma (Binary Classification)** | Matris, iki farklı sınıfı (örneğin Spam/Değil, Dolandırıcılık/Değil) ayırt etmeye çalışan sistemlerin performansını ölçmek için geliştirilmiş **standart bir araçtır**. | 🏷️0️⃣1️⃣ |
| **Desen Tanıma (Pattern Recognition)** | Özellikle 1900'lü yılların ortalarından itibaren desen tanıma algoritmaları gelişirken, bu algoritmaların doğruluğunu **detaylı ve kategorize edilmiş** bir şekilde ölçme ihtiyacıyla popülerlik kazanmıştır. | 🖼️🧐 |
| **Ölçüm Teorisi (Measurement Theory)** | Veri biliminde model performansının güvenilir ve tutarlı bir şekilde ölçülmesini sağlar. Matris, göreceli metrikler (Kesinlik, Duyarlılık vb.) türetmek için temel oluşturur. | 📏📈 |

---

## ⭐ Özet

Karışıklık Matrisi, makine öğreniminde kritik bir değerlendirme aracıdır. **Matematiksel kökeni** en güçlü şekilde **İstatistik ve Hipotez Testi'ndeki Tip I ve Tip II Hata** kavramlarına dayanır. Matris, bu soyut hata kavramlarını, sınıflandırma sonuçlarının **sayılabilir** ve **anlaşılabilir** bir tablo yapısıyla somutlaştırır.

---


# 📈 Model Değerlendirme: Duyarlılık (Recall), Kesinlik (Precision) ve F1 Skoru

Karışıklık Matrisi'ni anladıktan sonra, modelin performansını tek bir sayıdan (Doğruluk) daha derinlemesine analiz etmemizi sağlayan temel sınıflandırma metriklerini hesaplayabiliriz. Bu metrikler, bazı hataların diğerlerinden daha maliyetli olduğu durumlarda hayati önem taşır.

---

## 1. 🔍 Doğruluğu Yeniden Tanımlama (Accuracy Review)

Doğruluk, modelin toplam tahminler içinde doğru yaptığı tahminlerin yüzdesiydi. Karışıklık Matrisi terimleriyle Doğruluk:

$$\text{Doğruluk (Accuracy)} = \frac{\text{Doğru Pozitif (TP)} + \text{Doğru Negatif (TN)}}{\text{TP} + \text{TN} + \text{Yanlış Pozitif (FP)} + \text{Yanlış Negatif (FN)}}$$

| Metrik | Anlamı | Kısıtlılığı | Emoji |
| :--- | :--- | :--- | :--- |
| **Doğruluk (Accuracy)** | Modelin **genel olarak** ne kadar sık doğru tahmin yaptığı. | Hata türleri (FP vs. FN) arasındaki farkı görmezden gelir ve **dengesiz veri setlerinde** yanıltıcı olabilir. | ⚖️❓ |

---

## 2. 🎯 Duyarlılık (Recall) ve Kesinlik (Precision)

Bu metrikler, modelin pozitif sınıfı ne kadar iyi ele aldığını farklı açılardan değerlendirir. Spam sınıflandırma örneğini ($Pozitif = Spam$) kullanacağız.

### 2.1. Duyarlılık (Recall) - Gerçek Pozitiflerin Oranı

| Kavram | Açıklama | Formül | Spam Örneğindeki Odak ||
| :--- | :--- | :--- | :--- | :--- |
| **Duyarlılık (Recall)** | **Gerçekte pozitif olan vakaların** ne kadarını modelin **doğru yakaladığını** ölçer. Aynı zamanda *Hassasiyet (Sensitivity)* olarak da bilinir. | $$\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$$ | Modelin **gerçek spam e-postaları ne kadar başarıyla SPAM olarak işaretlediği** (Hiç spam kaçırıyor muyuz?). **Yüksek Recall**, **az FN** (gözden kaçırma) anlamına gelir. | 🎣✅ |
| **Ne Zaman Önemli?** | **Yanlış Negatif (FN)** maliyetinin çok yüksek olduğu durumlar (Örn: Tıbbi teşhis - hasta birini sağlıklı sanmak, Dolandırıcılık tespiti - gerçek dolandırıcılığı kaçırmak). | - | - | 🚨 |

### 2.2. Kesinlik (Precision) - Tahminlerin Güvenirliği

| Kavram | Açıklama | Formül | Spam Örneğindeki Odak ||
| :--- | :--- | :--- | :--- | :--- |
| **Kesinlik (Precision)** | Modelin **pozitif olarak tahmin ettiği vakaların** ne kadarının **gerçekten pozitif** olduğunu ölçer. | $$\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$$ | Modelin **SPAM olarak işaretlediği** e-postaların ne kadarının **gerçekten spam olduğu** (Yanlış alarm çalıyor muyuz?). **Yüksek Precision**, **az FP** (yanlış alarm) anlamına gelir. | 🛡️👍 |
| **Ne Zaman Önemli?** | **Yanlış Pozitif (FP)** maliyetinin çok yüksek olduğu durumlar (Örn: Yasal işlem başlatma - masum birini suçlamak, Spam Filtresi - önemli bir e-postayı spam klasörüne göndermek). | - | - | 🛑 |

---

## 3. ⚖️ F1 Skoru - Denge ve Uyum

Duyarlılık ve Kesinlik genellikle **ters orantılı** çalışır. Birini artırmak, diğerini düşürebilir. Her iki metriğin de önemli olduğu durumlarda, **F1 Skoru** kullanılır.

| Kavram | Açıklama | Formül | Odak ||
| :--- | :--- | :--- | :--- | :--- |
| **F1 Skoru** | **Kesinlik ve Duyarlılık'ın harmonik ortalamasıdır**. Her iki metriği de dikkate alan **tek bir dengeleyici metrik** sağlar. | $$\text{F1 Skoru} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$ | Modelin hem **gözden kaçırma (FN)** hem de **yanlış alarm (FP)** hatalarını aynı anda minimize ederek **dengeli** performans göstermesini ister. | 🤝💯 |
| **Ne Zaman Önemli?** | Sınıflandırma performansında hem **FN** hem de **FP** hatalarının maliyetinin yüksek ve her iki metriğin de optimize edilmesinin istendiği durumlar. | - | - | ✨ |

---

# 🗝️ Model Değerlendirme: Kilit Çıkarımlar ve Metrikler

Bir sınıflandırma modelinin performansını anlamak için tek başına Doğruluk (Accuracy) yeterli değildir. Aşağıdaki temel metrikler ve araçlar, modelin hatalarını ve gerçek dünya uygulamasındaki gücünü detaylıca analiz etmemizi sağlar.

---

## 📋 Temel Metrikler ve Kullanım Alanları Tablosu

| Metrik/Kavram | Açıklaması | Formül (Karışıklık Matrisi Terimleriyle) | Kullanım Alanı ve Önemi | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **Karışıklık Matrisi** | Modelin yaptığı doğru pozitif (TP), yanlış pozitif (FP), doğru negatif (TN) ve yanlış negatif (FN) sayılarının gösterildiği temel tablo. Modelin hatalarının **türünü ve nerede meydana geldiğini** gösterir. | $\text{TP, TN, FP, FN Sayıları}$ | Tüm metriklerin temelini oluşturur. Modelin **Yanlış Alarm (FP)** mı yoksa **Gözden Kaçırma (FN)** mı yaptığını netleştirir. | 📊👀 |
| **Doğruluk (Accuracy)** | Modelin toplam tahminler içinde **doğru yaptığı tahminlerin yüzdesi**. İyi bir başlangıçtır, ancak modelin sadece genel başarısını gösterir. | $\frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$ | **Genel Performans** için kullanılır. **Dengesiz veri** setlerinde tek başına yeterli ve yanıltıcı değildir. | ✅⚖️ |
| **Kesinlik (Precision)** | Modelin **pozitif olarak tahmin ettiği** durumların ne kadarının **gerçekte pozitif** olduğunu ölçer. Tahminlerin güvenilirliğini gösterir. | $\frac{\text{TP}}{\text{TP} + \text{FP}}$ | **Yanlış Pozitif (FP)** maliyetinin yüksek olduğu durumlar önemlidir. *Örnek: Spam tespiti* (Gerçek bir e-postanın spam kutusuna gitmemesi için). | 🛡️👍 |
| **Duyarlılık (Recall)** | **Gerçekte pozitif olan** durumların ne kadarını modelin **doğru olarak tanımladığını** ölçer. Gözden kaçırma oranını gösterir. (*Hassasiyet* olarak da bilinir.) | $\frac{\text{TP}}{\text{TP} + \text{FN}}$ | **Yanlış Negatif (FN)** maliyetinin yüksek olduğu durumlar önemlidir. *Örnek: Dolandırıcılık tespiti* (Gerçek dolandırıcılığı kaçırmamak için). | 🎣🚨 |
| **F1 Skoru** | Kesinlik ve Duyarlılık'ın **harmonik ortalamasıdır**. Her iki metriği de dikkate alan tek bir dengeleyici metrik sunar. | $2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ | Modelin hem **yanlış alarmı hem de gözden kaçırmayı minimize ederek** dengeli performans göstermesi istendiği zaman kullanılır. Dengesiz veri setlerinde faydalıdır. | 🤝✨ |

---

## 🎯 Problemin Türüne Göre Metrik Seçimi

Farklı iş problemleri, farklı hata türlerinin daha maliyetli olduğu anlamına gelir. Bu nedenle, kritik metrik problemin odağına göre değişir:

| Problem Türü | Kritik Hata Türü | Neden Kritik? | Önemli Metrik |
| :--- | :--- | :--- | :--- |
| **Dolandırıcılık Tespiti** | **Yanlış Negatif (FN)** | Gerçek bir dolandırıcılığı kaçırmak (FN) büyük finansal kayıplara neden olur. | **Duyarlılık (Recall)** olabildiğince yüksek tutulmalıdır. |
| **Spam Tespiti** | **Yanlış Pozitif (FP)** | Önemli bir e-postayı yanlışlıkla spam olarak işaretlemek (FP), kullanıcının işlerini aksatır. | **Kesinlik (Precision)** olabildiğince yüksek tutulmalıdır. |
| **Hastalık Teşhisi** | **Yanlış Negatif (FN)** | Hasta birini sağlıklı olarak teşhis etmek (FN), hayati tehlikeye yol açabilir. | **Duyarlılık (Recall)** hayati önem taşır. |
| **E-Ticaret Ürün Tavsiyesi**| **Yanlış Pozitif (FP)** | Alakasız bir ürünü tavsiye etmek (FP) kullanıcı deneyimini düşürür, ancak bir hatanın maliyeti düşüktür. | **Kesinlik (Precision)** genellikle daha önemlidir. |

---
---

# 🤖 Makine Öğrenimi Sınıflandırma Algoritmaları (ML Classification Algorithms)

<img width="848" height="441" alt="image" src="https://github.com/user-attachments/assets/aaa0b49c-48e1-4ee2-8c5a-562ec05d2d23" />

[Medium](https://ai.plainenglish.io/different-types-of-machine-learning-algorithms-28974016e108)

<img width="841" height="604" alt="image" src="https://github.com/user-attachments/assets/08e6989c-f19a-41ca-9272-87f35d5141b8" />

[TDS](https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501/)


* Şimdiye kadar ilk sınıflandırma modelimiz olan **Lojistik Regresyon**'u gördük. Sınıflandırma algoritmaları, verilen bilgilere (özelliklere) dayanarak **kategorileri (sınıfları)** tahmin etmemize yardımcı olur. Bu tahminler ikili (iki kategori) veya çoklu sınıf (ikiden fazla kategori) olabilir.

---

## 💡 Neden Birden Fazla Algoritma Öğrenmeliyiz?

Veri biliminde tek bir "en iyi" algoritma yoktur. Farklı algoritmalar, farklı veri yapılarına ve iş gereksinimlerine daha iyi uyum sağlar.

| Sebep | Açıklama | Emoji |
| :--- | :--- | :--- |
| **Farklı Veri, Farklı Araç** | Bazı modeller sayısal özelliklerle daha iyi çalışırken, diğerleri karmaşık örüntüleri veya kategorik verileri daha etkili bir şekilde ele alır. | 🛠️🧩 |
| **Doğruluk ve Performans** | Lojistik regresyonun kaçırabileceği karmaşık ilişkileri ve örüntüleri daha esnek modeller yakalayabilir. | 🎯🚀 |
| **Yorumlanabilirlik vs. Karmaşıklık** | **Karar Ağaçları** gibi bazı modeller teknik olmayan kişilere kolayca açıklanabilirken, **Yapay Sinir Ağları** gibi diğerleri "kara kutu" gibidir. | 🗣️❓ |
| **Gerçek Dünya Uygulamaları** | Uygulamada, veri bilimciler genellikle birden fazla modeli dener ve iş problemine en uygun olanı seçer. | 🌍🧪 |

---

## 🌳 Yaygın Sınıflandırma Algoritmaları

| Algoritma | Çalışma Prensibi | Temel Özellikler | Kullanım Alanı Örneği ||
| :--- | :--- | :--- | :--- | :--- |
| **Karar Ağaçları (Decision Trees)** | Veriyi kurallara dayalı dallara ayırarak tahmin yapar. | Yorumlaması kolaydır, ancak kontrol edilmezse **aşırı uyuma (overfitting)** eğilimlidir. | Müşteri risk analizi (Kurallar net görülebilir). | 🌳➡️ |
| **Rastgele Ormanlar (Random Forests)** | Birçok karar ağacının (ensemble) tahminlerini birleştirir. | Tek bir ağaca göre daha doğru ve daha sağlamdır (daha az aşırı uyum). | Finansal dolandırıcılık tespiti. | 🌲🌲🌲 |
| **k-En Yakın Komşu (kNN)** | Bir veri noktasını, en yakınındaki $k$ sayıda komşunun çoğunluk sınıfına göre sınıflandırır. | Basit bir mantığı vardır, ancak büyük veri setlerinde tahmin yapması yavaş olabilir. | Tavsiye sistemleri. | 👥⏱️ |
| **Destek Vektör Makineleri (SVMs)** | Sınıflar arasında en iyi ayırma sınırını ("hiper düzlem") bulur. | Yüksek boyutlu verilerde güçlüdür, ancak yorumlanması zordur. | Biyoinformatik ve görüntü sınıflandırma. | ✨📐 |
| **Naïve Bayes** | Olasılığa ve Bayes teoremine dayanır. Özelliklerin birbirinden bağımsız olduğunu varsayar. | Metin sınıflandırmada (spam filtreleri gibi) şaşırtıcı derecede iyi çalışır. Hızlıdır. | E-posta spam filtreleme. | 🎲📧 |
| **Yapay Sinir Ağları (Neural Networks)** | İnsan beyninden esinlenilmiştir; katmanlar halinde karmaşık örüntüleri öğrenir. | Çok karmaşık örüntüleri öğrenebilir, ancak büyük veri setleri ve yüksek hesaplama gücü gerektirir. | Görüntü tanıma, doğal dil işleme. | 🧠⚡ |

---
# ⚖️ Yanlılık-Varyans Değiş Tokuşu (Bias-Variance Tradeoff)

Yanlılık-Varyans Değiş Tokuşu, bir modelin karmaşıklığı ile yeni verilere genelleme yeteneği arasındaki temel çelişkiyi ifade eden, makine öğreniminin en önemli konseptlerinden biridir.

---

## 1. 🔍 Temel Kavramlar

 <img width="357" height="316" alt="image" src="https://github.com/user-attachments/assets/38643a68-6ef9-4fe1-934f-bf431edee4a1" /
 
| Kavram | Tanım (İngilizce Terim) | Model Durumu | Örnek ||
| :--- | :--- | :--- | :--- | :--- |
| **Yanlılık (Bias)** | Modeldeki yanlış varsayımlardan kaynaklanan hata. Modelin veri karmaşıklığını yakalayamayacak kadar **basit** olması. | **Eksik Uyum (Underfitting)** | Titanic hayatta kalma oranını tahmin etmek için sadece düz bir çizgi (Linear Regression) kullanmak. Model, temel ilişkileri göz ardı eder. | 👶❌ |
| **Varyans (Variance)** | Modelin, eğitim verisindeki küçük değişikliklere veya gürültüye karşı **aşırı duyarlı** olmasından kaynaklanan hata. | **Aşırı Uyum (Overfitting)** | Derinliği sınırsız bir Karar Ağacının eğitim setindeki her bir yolcuyu ezberlemesi (memorizing) ve test verisinde başarısız olması. | 🥵🧠 |

---

## 2. 🎯 Değiş Tokuş (Tradeoff) ve Hedef

<img width="726" height="259" alt="image" src="https://github.com/user-attachments/assets/ee0a30c9-3dd4-4a53-808c-b083a317ad1d" />

Yanlılık ve Varyans genellikle birbirinin tersi yönde çalışır. Birini azaltmak, genellikle diğerini artırır.

| Model Tipi | Özellikler | Hata Dengesi | Sonuç |
| :--- | :--- | :--- | :--- |
| **Basit Model** | Lojistik Regresyon, Sığ Karar Ağaçları | **Yüksek Yanlılık ($\uparrow$ Bias), Düşük Varyans ($\downarrow$ Variance)** | Veriyi yeterince öğrenemez. (Eksik Uyum) |
| **Karmaşık Model** | Derin Karar Ağaçları, Aşırı Uyumlu Yapay Sinir Ağları | **Düşük Yanlılık ($\downarrow$ Bias), Yüksek Varyans ($\uparrow$ Variance)** | Eğitim verisini ezberler, genelleme yapamaz. (Aşırı Uyum) |
| **İdeal Model** | **"Tatlı Nokta" (Sweet Spot)** | **Düşük Yanlılık, Düşük Varyans** | Verinin temel örüntülerini yakalar ve yeni verilere iyi genelleme yapar. |

### Görsel Sezgi

Modelin Karmaşıklık Düzeyine Göre Başarı Durumları:

| Durum (Genelleme) | Eğitim Doğruluğu (Training Accuracy) | Test/Doğrulama Doğruluğu (Test/Validation Accuracy) |
| :--- | :--- | :--- |
| **Eksik Uyum (Underfitting)** | Düşük | Düşük |
| **Aşırı Uyum (Overfitting)** | Yüksek | Düşük |
| **İdeal Uyum (Just Right)** | Yeterince Yüksek | Yeterince Yüksek ve birbirine Yakın |

## 3. 🔑 Özet ve Amaç

 <img width="659" height="390" alt="image" src="https://github.com/user-attachments/assets/60565a18-ee53-4cfe-80f6-fffc48506591" />
 
* **Yanlılık (Bias):** Modelin **çok basit** olmasından (Underfitting) kaynaklanan hatadır.
* **Varyans (Variance):** Modelin **aşırı duyarlı** olmasından (Overfitting) kaynaklanan hatadır.

**Amaç**, en düşük **eğitim hatasını** almak değil, Yanlılık ve Varyansın dengelendiği, yani en düşük **doğrulama/test hatasının** alındığı **tatlı noktayı** bulmaktır. Modelin iyi genelleme yapması (generalization) budur.



# 📈 Model Karmaşıklığı ve Hata İlişkisi (Bias-Variance Tradeoff)

<img width="642" height="346" alt="image" src="https://github.com/user-attachments/assets/516c2ce7-b77b-47dc-9a75-85587e0f931d" />

Model karmaşıklığının (Model Complexity) eğitim (training) ve doğrulama/test (validation/test) hataları üzerindeki etkisini incelemek, makine öğreniminde **genelleme (generalization)** yeteneğini anlamak için hayati önem taşır.

---

## 📉 Hata Eğrileri ve Anlamları

| Eğri | Kavram (İngilizce Terim) | Yönelim | Açıklama ||
| :--- | :--- | :--- | :--- | :--- |
| 🟦 **Mavi Çizgi** | Eğitim Hatası (Training Error) | **Daima Düşer** | Model karmaşıklaştıkça, eğitim verisini **ezberleme** yeteneği artar. Bu nedenle, eğitim hatası sürekli olarak azalır, hatta sıfıra yaklaşabilir. | 📚📉 |
| 🟩 **Yeşil Çizgi** | Doğrulama/Test Hatası (Validation/Test Error) | **Önce Düşer, Sonra Yükselir** | Model, başta daha iyi öğrendiği için hata düşer. Ancak model **çok karmaşıklaştığında**, genelleme yeteneğini kaybeder ve **ezberlediği** veriden farklı verilerde hata oranı tekrar **yükselir** (Aşırı Uyum). | ⬆️⬇️ |

---

## 🎯 Bölgeler ve Model Durumları

Model karmaşıklığına göre hataların kesişimi ve ayrışması, modelin üç temel durumunu tanımlar:

| Bölge | Durum (İngilizce Terim) | Karmaşıklık Düzeyi | Hata Durumu | Örnek ve Sonuç ||
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Sol** | Yüksek Yanlılık (High Bias) veya **Eksik Uyum (Underfitting)** | **Çok Basit** | Hem Eğitim Hatası hem de Doğrulama Hatası **Yüksek**dir. | Model, verideki temel örüntüleri bile yakalayamaz. (*Örn: Titanic verisini tek bir düz çizgiyle tahmin etmeye çalışmak.*) | 👶❌ |
| **Orta** | **Optimal Bölge (Optimal Zone)** veya **İyi Uyum (Good Fit)** | **Tam Ayarında** | Eğitim Hatası **Düşük** ve Doğrulama Hatası da **Düşüktür**. | Model, veriyi yeterince öğrenmiş ve yeni verilere iyi genelleme yapabiliyordur. **Modellerimizi bu bölgede isteriz.** | 🏆✨ |
| **Sağ** | Yüksek Varyans (High Variance) veya **Aşırı Uyum (Overfitting)** | **Çok Karmaşık** | Eğitim Hatası **Çok Düşük** iken, Doğrulama Hatası **Yüksek**tir. | Model, eğitim verisindeki gürültüyü ve tesadüfi örüntüleri ezberlemiştir. (*Örn: Her yolcunun özelliğini ezberleyen derin bir karar ağacı.*) | 🥵🧠 |

---

## 🛑 Neden Önemlidir?

Model oluştururken amacımız, **genelleme bölgesi** (generalization zone) adı verilen orta bölgeyi bulmaktır.

* **Eksik Uyumdan Kaçınmak:** Modelin çok basit olmasından ve düşük performanstan (poor performance) kaçınmalıyız.
* **Aşırı Uyumdan Kaçınmak:** Modelin çok karmaşık olmasından ve yeni verilerde kötü genelleme yapmasından (poor generalization) kaçınmalıyız.

---


# 🌳 Karar Ağacı (Decision Tree) Sınıflandırma Algoritması

<img width="681" height="434" alt="image" src="https://github.com/user-attachments/assets/deb619f5-86df-4980-8bb6-55dd573cb0f0" />

[scikitlearn](https://scikit-learn.org/stable/modules/tree.html)

Karar Ağaçları, en basit ve en sezgisel makine öğrenimi modellerinden biridir. Bir dizi evet/hayır sorusunu yanıtlayarak nihai bir karara ulaşma sürecini taklit eder.

---

## 1. ⚙️ Çalışma Prensibi

| Kavram | Açıklama | Örnek ||
| :--- | :--- | :--- | :--- |
| **Prensip** | Model, girdi özelliklerine (input features) dayalı "sorular" sorarak veriyi giderek daha küçük gruplara ayırır (böler). | Hayvan sınıflandırmasında: "Tüyleri var mı?" $\to$ Evet ise kuş yolu. $\to$ "Yüzüyor mu?" $\to$ Evet ise Ördek. | ❓⬇️ |
| **Yapı** | Her soru bir **dalı (branch)** temsil eder ve nihai karar, ağacın ucundaki **yaprakta (leaf)** alınır. | Model, her bir bölmede sınıf saflığını (purity) artırmayı (yani karışıklığı azaltmayı) hedefler. | 🌿🏷️ |
| **Kullanım** | Hem sayısal (numeric) hem de kategorik (categorical) veri tipleriyle çalışabilir. | Cinsiyet (Kategorik) $\to$ Yaş (Sayısal) $\to$ Bitiş. | 🔢🔠 |

---

## 2. ➕➖ Avantajlar ve Dezavantajlar

| Kategori | Özellik (İngilizce Terim) | Açıklama ||
| :--- | :--- | :--- | :--- |
| **Avantaj** | Kolay Yorumlanabilirlik (Easy to Interpret) | Kararlar, basit evet/hayır kuralları dizisi olarak açıkça görülebilir ve teknik olmayan kişilere anlatılabilir. | 🗣️👍 |
| **Avantaj** | Doğrusal Olmayan İlişkiler (Non-linear Relationships) | Verideki doğrusal olmayan (non-linear) ve karmaşık ilişkileri kolayca yakalayabilir. | 〰️💡 |
| **Dezavantaj** | Aşırı Uyuma Eğilim (Prone to Overfitting) | Model **çok karmaşıklaştığında**, eğitim verisindeki gürültüyü (noise) veya alakasız detayları ezberler; bu da yeni verilerde **düşük performansa** yol açar. | 🥵📉 |
| **Dezavantaj** | Kararsızlık (Instability) | Eğitim verisindeki küçük değişiklikler bile, ağacın tüm yapısını büyük ölçüde değiştirebilir. | 🤏📉 |
| **Dezavantaj** | Eksik Uyum (Underfitting) | Ağaç çok basit bırakılırsa (çok az bölme yapılırsa), verideki gerçek örüntüleri yakalayamaz. | 👶❌ |

---

## 3. 🛑 Aşırı Uyumdan Korunma Yolları

Karar Ağaçlarının en büyük zayıflığı olan aşırı uyumu (overfitting) önlemek için kullanılan başlıca teknikler:

| Teknik | Tanım (İngilizce Terim) | Uygulama Yöntemi | Sonuç ||
| :--- | :--- | :--- | :--- | :--- |
| **Ön Budama (Pre-pruning)** | Ağacın büyümesini **erken aşamada** durdurmak. | Ağacın maksimum derinliğine (`max_depth`) veya bir bölme için gereken minimum örnek sayısına (`min_samples_split`) limit koymak. | Ağacın karmaşıklığını sınırlar. | ✂️🌳 |
| **Geri Budama (Post-pruning)** | Ağaç tamamen büyütüldükten sonra, fazla gürültüyü yakalayan dalları **kesip atmak**. | Doğrulama (validation) verisindeki performansı düşürmeyen dalları kaldırmak. | Karmaşıklığı azaltır ve genellemeyi artırır. | 🔪🍃 |
| **Topluluk Yöntemleri (Ensemble Methods)** | Tek bir ağaç yerine birçok ağacı kullanmak. | **Rastgele Ormanlar (Random Forests)** gibi yöntemler, birçok ağacın tahminini alarak varyansı azaltır ve çok daha sağlam sonuçlar verir. | Daha yüksek doğruluk ve sağlamlık sağlar. | 🌲🌲🌲 |

 <img width="650" height="348" alt="image" src="https://github.com/user-attachments/assets/208e8d1b-a061-45f0-b843-e258b9c3b621" />

 # 🌳 Karar Ağaçları: Özellik Seçimi ve Önemi (Feature Selection & Importance)

Karar Ağaçları (Decision Trees) eğitilirken, modelin her adımda hangi özelliğe göre bölme yapacağına karar vermesi gerekir. Algoritma bu kararı, **sınıflar arasında en iyi ayrımı (best separation)** sağlayan özelliği hesaplayarak verir.

---

## 1. ⚙️ Bölme Mekanizması ve Amacı

| Aşama | Süreç (İşleyiş Mantığı) | Amaç | Örnek (Titanic) ||
| :--- | :--- | :--- | :--- | :--- |
| **Aşama 1: Adayları Değerlendirme** | Ağaç, mevcut veri setinde tüm özellikleri ve olası tüm bölme noktalarını (split points) inceler. | Veriyi, mümkün olduğunca **saf (purer)** gruplara ayırmak (Bir grupta çoğunlukla "hayatta kalanlar," diğerinde çoğunlukla "hayatta kalmayanlar" olması). | 'Cinsiyet' özelliğine göre bölmek, 'Bilet Numarası'na göre bölmekten çok daha saf gruplar oluşturur. | 🧐🔍 |
| **Aşama 2: Bölmeyi Ölçme** | Her bir potansiyel bölmenin, sınıflar arasındaki karışıklığı ne kadar azalttığı ölçülür. | En yüksek saflığı (veya en yüksek bilgi kazancını) sağlayan bölmeyi seçmek. | Büyük ihtimalle ilk bölme için **Cinsiyet** seçilecektir, çünkü hayatta kalma oranlarını en keskin ayıran özelliktir. | 📏🎯 |
| **Aşama 3: Tekrarlama** | Ağaç tamamen büyüyene kadar veya önceden belirlenmiş bir durdurma koşuluna (max\_depth gibi) ulaşana kadar bu süreç tekrarlanır. | | | 🔄🌱 |

---

## 2. 🔢 "En İyi" Bölme Ölçütleri (Criteria)

Karar Ağacı algoritmaları, bölmelerin kalitesini ölçmek için genellikle iki ana matematiksel kriter kullanır:

| Kriter (İngilizce Terim) | Temel Kavram | Açıklama | Kullanım | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **Gini Saflık Ölçütü (Gini Impurity)** | Karışıklık/Hata Olasılığı | Gruptan rastgele seçilen bir örneğin, gruptaki dağılıma göre etiketlendiğinde **yanlış sınıflandırılma olasılığını** ölçer. | **`criterion="gini"`** (scikit-learn varsayılanı) | 🎲📉 |
| **Entropi / Bilgi Kazancı (Entropy / Information Gain)** | Belirsizlik (Uncertainty) | **Entropi**, bir gruptaki belirsizliği ölçer. Ağaç, **en yüksek bilgi kazancını** (belirsizlikteki en büyük azalmayı) sağlayan bölmeyi seçer. | **`criterion="entropy"`** | 💡⬇️ |

*Not: İki kriter de pratikte benzer sonuçlar verir ve amaçları aynıdır: Sınıfları mümkün olduğunca temiz ayırmak.*

---

## 3. 🥇 Özellik Önemi (Feature Importance)

Karar Ağaçları, tahminlere en çok katkıda bulunan özellikleri sıralayabilir.

| Kavram | Tanım | Örnek Durum (Titanic) ||
| :--- | :--- | :--- | :--- |
| **Hesaplama Yöntemi** | Özellik Önemi, o özelliğin toplam kriter (Gini veya Entropi) **azalmasına** ne kadar katkıda bulunduğuna göre hesaplanır. | **Title\_Mr** $(\sim 64\%)$ en önemli özelliktir, çünkü bu unvan hayatta kalma şansını en güçlü şekilde azaltmıştır. | 🏆📊 |
| **Sıralı Liste** | Özellikler, modelin karar verme sürecinde ne kadar etkili olduklarına göre sıralanır. | $\text{Pclass}$ $(\sim 14\%)$, $\text{FamilySize}$ $(\sim 9\%)$ ve $\text{Fare}$ $(\sim 7\%)$ da sosyal sınıf ve maliyet etkisini yansıtır. | 🥇🥈 |
| **Gizlenme Etkisi** | Bir özelliğin etkisi, daha güçlü bir korelasyona sahip **başka bir özellik** tarafından zaten yakalanmışsa, önemi düşük çıkabilir. | **Cinsiyet** özelliği 0 önem gösterebilir, çünkü etkisi zaten çok daha güçlü olan **Unvan (Title: Mr/Mrs/Miss)** özelliği tarafından yakalanmıştır. | 🤫🎭 |

---

## ⚠️ Model Türlerine Göre Önemi Karşılaştırma

Farklı model türleri "önemi" farklı şekilde ölçtüğü için, bu değerler **modeller arasında doğrudan karşılaştırılamaz**.

| Model | Önemi Ölçme Yöntemi | Sonuç |
| :--- | :--- | :--- |
| **Lojistik Regresyon** | **Katsayıların (Coefficients) Büyüklüğü** (ölçeklendirmeden sonra). | Büyük pozitif katsayı, hayatta kalma olasılığını artırır. **Cinsiyet** burada çok önemli görünebilir. |
| **Karar Ağaçları (Decision Trees)** | **Saflıktaki Azalma** (Impurity Reduction). | Özelliğin, veriyi ne kadar saf gruplara ayırdığına bakar. **Unvan** gibi bir özellik, **Cinsiyet**in etkisini kapsadığı için baskın çıkabilir. |

---

## 🧠 Ana Mantık ve İş Akışı Özeti

1.  **Hedef Belirleme:** Karar Ağacı, her adımda sınıflar arasındaki karışıklığı (Gini/Entropi) **en çok** azaltacak bölmeyi bulmayı hedefler.
2.  **Ölçüt Kullanımı:** Bölmenin kalitesini ölçmek için Gini Saflığı veya Entropi kullanılır.
3.  **Tekrarlanan Bölme:** Ağaç, en iyi bölmeyi seçer ve bu süreci ağacın dallarında tekrarlar (özyineleme).
4.  **Sonuç Çıkarma:** Eğitim bittikten sonra, ağaç hangi özelliklerin en çok "karışıklık azalmasına" neden olduğunu rapor ederek **özellik önemini** belirler.

Bu süreç, modelin hem tahmin yapmasını hem de bu tahminleri hangi özelliklere dayandırdığını açıklamasına olanak tanır.


---

# 🌲 Rastgele Ormanlar (Random Forests): Topluluk Gücü

<img width="504" height="336" alt="image" src="https://github.com/user-attachments/assets/5874273f-af65-4266-9972-dba04cff2cde" />


Rastgele Orman (Random Forest), aşırı uyuma (overfitting) eğilimli tek bir Karar Ağacının zayıflıklarını gidermek için tasarlanmış bir **topluluk (ensemble) modelidir**.

---

## 1. 🌳 Rastgele Orman Nedir ve Nasıl Çalışır?


| Kavram (İngilizce Terim) | Açıklama | Prensip ||
| :--- | :--- | :--- | :--- |
| **Model Tipi** | Bir **Topluluk Modeli (Ensemble Model)**'dir. Tek bir model yerine, yüzlerce modelin tahminlerini birleştirir. | Bilgi sahibi 100 farklı doktora danışarak tanı koymaya benzetilebilir; grup kararı genellikle tek bir uzmandan daha güvenilirdir. | 👥🩺 |
| **Ağaçların Eğitimi** | Yüzlerce Karar Ağacı rastgele ve bağımsız olarak eğitilir. | Her bir ağaç, verinin **rastgele bir alt kümesini** (random subset of data) ve özelliklerin **rastgele bir alt kümesini** (random subset of features) görür. | 🎲🌱 |
| **Nihai Tahmin** | Her ağaç kendi tahminini yapar. | **Sınıflandırma (Classification)** için **çoğunluk oyu (majority vote)**, Regresyon için ortalama alınır. | 🗳️✅ |

---

## 2. ➕➖ Tek Bir Ağaca Göre Avantajları

Rastgele Ormanlar, birden fazla ağacı birleştirerek varyansı (aşırı duyarlılığı) azaltır, böylece tek bir ağacın aksine daha iyi genelleme yapar.

| Avantaj (İngilizce Terim) | Açıklama | Etki ||
| :--- | :--- | :--- | :--- |
| **Daha Yüksek Doğruluk (More Accurate)** | Birden fazla ağacın tahminini birleştirdiği için hatalı tahmin yapma riski azalır ve aşırı uyum (overfitting) düşer. | Daha iyi genelleme performansı sağlar. | 🎯⬆️ |
| **Daha Sağlam (More Stable)** | Tek bir ağaç, eğitim verisindeki küçük değişikliklere çok hassastır. Orman ise çok daha **dayanıklı (robust)** ve kararlıdır. | Veri gürültüsüne karşı daha az hassastır. | 🛡️💪 |
| **Karmaşık Veriyle Uyum** | Çok sayıda özelliği (features) olan veri setlerinde bile iyi sonuç verir. | Verimli bir şekilde çalışır. | 🧩✨ |
| **Kutudan Çıktığı Gibi İyi Çalışma (Works Well Out-of-the-Box)** | Çoğu zaman, hiperparametre ayarı yapmaya gerek kalmadan yüksek performans gösteren ilk denenecek modellerdendir. | Hızlı başlangıç ve temel performans için ideal. | 📦👌 |
| **Dezavantaj** | **Daha Az Yorumlanabilirlik (Less Interpretability)** | Tek bir ağacın basit evet/hayır kurallarının aksine, yüzlerce ağacın oyunu anlamak zordur. | ❓🗣️ |

---

## 3. 🥇 Özellik Önemi (Feature Importance in Random Forest)

Rastgele Ormanlar, karar verme sürecine en çok katkıda bulunan özellikleri raporlar.

| Kavram | Açıklama | Rastgele Orman'ın Etkisi ||
| :--- | :--- | :--- | :--- |
| **Hesaplama** | Model, her bir özelliğin tüm ağaçlarda yaptığı ortalama karışıklık azalmasına (gini impurity reduction) göre önemini hesaplar. | Tüm ağaçlar farklı özellik kombinasyonları kullandığı için, önem skorları genellikle daha **dengeli** dağılır. | ⚖️📊 |
| **Dengeli Dağılım** | Önem, tek bir baskın özelliğe güçlü bir şekilde sapmaz. Birçok küçük özellik bile bir miktar ağırlık alır. | **Hiçbir özellik 0 önem taşımaz**, çünkü ormandaki birden fazla ağaç bu özellikleri farklı bölmelerde kullanmıştır. | 🌍🤝 |
| **Karşılaştırma (DT vs. RF)** | **Tekil Karar Ağacı (DT)**, genellikle tek bir güçlü özelliğe (Örn: Title\_Mr) aşırı derecede odaklanırken; **Rastgele Orman (RF)**, kararları birden fazla özellik arasında yayarak daha geniş bir resim yakalar. | Daha gerçekçi ve kapsamlı özellik önemi sunar. | 🆚🔄 |

---

## 🔑 Ana Çıkarımlar

1.  **Rastgele Ormanlar =** Karar Ağaçlarından oluşan bir topluluktur (ensemble).
2.  Tek bir ağaca kıyasla **doğruluğu artırır ve aşırı uyumu azaltır**.
3.  Tahminler **çoğunluk oyu** ile yapılır.
4.  Çoğu ML problemi için **ilk denenecek (go-to)** modeldir.

---
# 🫂 K-En Yakın Komşular (k-Nearest Neighbors - kNN)

**K-En Yakın Komşular (kNN)**, karmaşık kurallar öğrenmek yerine, bir veri noktasının "komşularına" bakarak tahmin yapan en basit ve sezgisel makine öğrenimi algoritmalarından biridir.

<img width="676" height="348" alt="image" src="https://github.com/user-attachments/assets/e9c0909f-2cb9-452c-96eb-543679000abf" />

# 🫂 K-En Yakın Komşular (kNN): Temel Amaç ve Çalışma Mantığı

K-En Yakın Komşular algoritmasının (kNN) tahmine dayalı temel felsefesi ve ikili (binary) sınıflandırma ile regresyon (regression) problemlerinde nasıl çalıştığı aşağıda özetlenmiştir.

---

## 1. 🧠 Temel Amaç ve Çalışma Mantığı

| Kavram (İngilizce Terim) | Amaç/Temel Fikir | İşleyiş Prensibi ||
| :--- | :--- | :--- | :--- |
| **Temel Fikir (Core Idea)** | Yeni bir veri noktasının etiketini, eğitim setindeki **en yakın $K$ komşusunun** etiketlerine dayanarak tahmin etmek. | Bir karar vermek için en güvendiğiniz, yani size en "yakın" olan arkadaş grubunuza danışmaya benzer. | 💡🤝 |
| **Sınıflandırma (Classification)** | $K$ komşu içinde en çok hangi sınıfın bulunduğunu belirlemek (**çoğunluk oyu**). | İkili sınıflandırıcılarda (2 sınıf olduğunda), beraberlikleri önlemek için **$K$ değerinin tek sayı (odd)** olması gerekir. | 🗳️✅ |
| **Regresyon (Regression)** | $K$ komşunun değerlerinin **ortalamasını** almak. | | 📉📈 |
| **Örnek Senaryo** | Titanic'te yeni bir yolcunun hayatta kalma durumunu tahmin etmek. | kNN, en benzer 5 yolcuyu bulur. Eğer 5 kişiden 3'ü hayatta kaldıysa, tahmin **Hayatta Kaldı** olur. | 🚢✔️ |

# ⚙️ K-En Yakın Komşular (kNN): Adım Adım İşleyiş Süreci

K-En Yakın Komşular algoritması, bir tahmin yapmak için özel bir eğitim aşamasından geçmez; tüm hesaplama tahmin anında (lazy learning) gerçekleşir.

---

## 2. ✨ Adım Adım İşleyiş Süreci

| Adım | İşlem | Önemli Notlar ||
| :--- | :--- | :--- | :--- |
| **1. $K$ Değerini Seçme** | Tahmin için bakılacak komşu sayısını belirleyin. | **Tek sayı (odd) $K$** değeri, ikili sınıflandırmada beraberlikleri önlemek için önerilir. | 🔢🎯 |
| **2. Mesafe Hesaplama** | Yeni nokta ile eğitim setindeki **tüm noktalar** arasındaki mesafeyi ölçün. | **Öklid (Euclidean)**, Manhattan veya Minkowski gibi çeşitli mesafe metrikleri (distance metrics) kullanılır. | 📏🗺️ |
| **3. Komşuları Bulma** | Hesaplanan mesafelere göre en yakın $K$ noktayı seçin. | Bu, büyük veri setlerinde kNN'i yavaşlatan temel adımdır. | 🔍🫂 |
| **4. Tahmin Yapma** | $K$ komşunun **çoğunluk oyuna** (sınıflandırma) veya **ortalama değerine** (regresyon) göre tahmini sonuçlandırın. | | 🗳️✅ |

<img width="685" height="297" alt="image" src="https://github.com/user-attachments/assets/a7c2c509-5065-4e9a-9d32-fbfd572481c1" />


# ⚖️ K-En Yakın Komşular (kNN) Algoritmasının Kritik Unsurları

kNN'in performansını ve genelleme yeteneğini belirleyen temel kararlar ve teknikler, algoritmanın basitliğine rağmen büyük önem taşır.

---

## 3. 🛡️ kNN'in Kritik Unsurları

| Unsur (İngilizce Terim) | Etki | Yöntem | Önemi ||
| :--- | :--- | :--- | :--- | :--- |
| **$K$ Seçimi (Choosing K)** | Modelin karmaşıklığını ve Yanlılık-Varyans dengesini belirler. | **Küçük $K$**: Yüksek Varyans (High Variance), gürültüye duyarlı. **Büyük $K$**: Yüksek Yanlılık (High Bias), yerel örüntüleri kaçırabilir. | En iyi $K$ değerini bulmak için **çapraz doğrulama (cross-validation)** kullanılır. | 🎯🔬 |
| **Özellik Ölçeklendirme (Feature Scaling)** | Mesafe hesaplamalarını doğrudan etkiler. | **Zorunludur!** Gelir (büyük aralık) gibi değişkenlerin Yaş (küçük aralık) gibi değişkenlere baskın gelmesini engeller. | Anlamlı ve adil mesafe hesaplamaları için hayati önem taşır. | 📏✔️ |
| **Mesafe Metrikleri (Distance Metrics)** | İki nokta arasındaki benzerliğin nasıl tanımlanacağını belirler. | **Öklid Mesafesi** (Euclidean Distance - düz çizgi) en yaygın olanıdır, ancak problem türüne göre farklı metrikler seçilebilir (Örn: Manhattan Mesafesi). | | 🛣️🔗 |

<img width="454" height="326" alt="image" src="https://github.com/user-attachments/assets/bdaeffb5-4d14-424b-9638-b84a19786a3d" />

# ➕➖ K-En Yakın Komşular (kNN): Avantajlar ve Sınırlamalar

K-En Yakın Komşular algoritması, basitliğine rağmen bazı güçlü avantajlara sahiptir, ancak büyük veri setlerinde ciddi sınırlamalarla karşılaşır.

---

## 4. 🚀 Avantajlar ve Sınırlamalar

| Kategori | Özellik (İngilizce Terim) | Açıklama ||
| :--- | :--- | :--- | :--- |
| **Avantaj** | Basitlik (Simplicity) | Öğrenmesi ve anlaşılması çok kolaydır. Genellikle ilk denenen temel (baseline) modellerden biridir. | 👶👍 |
| **Avantaj** | Eğitim Fazı Yok (No Training Phase) | Model, kural veya parametre öğrenmez; sadece veriyi depolar. Tüm hesaplama tahmin anında yapılır. | 💾🧠 |
| **Dezavantaj** | Yavaşlık (Slowness) | Büyük veri setlerinde tahmin yaparken her seferinde **tüm eğitim setindeki** tüm noktalara olan mesafeyi hesaplamak zorunda olduğu için yavaşlayabilir. | 🐢⏱️ |
| **Dezavantaj** | Gürültüye Hassasiyet (Sensitive to Noise) | Alakasız veya gürültülü (noisy) özelliklere karşı hassastır, çünkü tüm özellikler mesafe hesabını eşit derecede etkiler. | 👂📢 |

<img width="729" height="212" alt="image" src="https://github.com/user-attachments/assets/e68953d5-9f60-4819-999f-b21adf3d2d34" />

