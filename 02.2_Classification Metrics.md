# Classification Metrics

# ğŸ“‰ Model DeÄŸerlendirmesi: Bir Modelin Ä°yi OlduÄŸunu NasÄ±l AnlarÄ±z?

Model deÄŸerlendirmesi, bir makine Ã¶ÄŸrenimi modelinin gerÃ§ek dÃ¼nya verilerinde ne kadar iyi performans gÃ¶sterdiÄŸini anlamak iÃ§in kritik Ã¶neme sahiptir. YalnÄ±zca tahmin yapmasÄ± yeterli deÄŸildir; bu tahminlerin **kullanÄ±ÅŸlÄ±** ve **gÃ¼venilir** olmasÄ± gerekir.

---

## ğŸ“‹ Temel Kavramlar ve Metrikler Tablosu

| Konu/BaÅŸlÄ±k | AÃ§Ä±klama | GÃ¶rsel/Emoji |
| :--- | :--- | :--- |
| **DeÄŸerlendirmenin Ã–nemi** | Bir modelin her zaman tahmin yapabilmesine raÄŸmen, tÃ¼m tahminler kullanÄ±ÅŸlÄ± deÄŸildir. Ã–rneÄŸin, bir modelin hayatta kalma oranÄ±nÄ±n %62 olduÄŸu Titanic verisinde "herkes Ã¶ldÃ¼" demesi %62 doÄŸruluk saÄŸlar ancak **hayatta kalanlarÄ± asla bulamadÄ±ÄŸÄ± iÃ§in iÅŸe yaramaz** bir modeldir. Bu, doÄŸru metriklerin Ã¶nemini gÃ¶sterir. | ğŸš¢ğŸ¤·â€â™€ï¸ |
| **Veri BÃ¶lme: EÄŸitim vs. Test** | Modeli deÄŸerlendirmeden Ã¶nce, gÃ¶rmediÄŸi veriler Ã¼zerinde test edildiÄŸinden emin olmalÄ±yÄ±z. Veri seti ikiye ayrÄ±lÄ±r: <ul><li>**EÄŸitim Seti:** Modeli **Ã¶ÄŸretmek** iÃ§in kullanÄ±lÄ±r.</li><li>**Test Seti:** Modelin **yeni verilerdeki** performansÄ±nÄ± kontrol etmek iÃ§in kullanÄ±lÄ±r.</li></ul>AynÄ± veride test etmek, modelin cevaplarÄ± ezberlemesine ($\approx$ **AÅŸÄ±rÄ± Uyum/Overfitting**) yol aÃ§ar ve gerÃ§ek performansÄ± gÃ¶stermez. | ğŸ§ â¡ï¸ğŸ“ |
| **SÄ±nÄ±flandÄ±rma MetriÄŸi: DoÄŸruluk (Accuracy)** | En basit sÄ±nÄ±flandÄ±rma deÄŸerlendirme metriÄŸidir. Modelin **doÄŸru yaptÄ±ÄŸÄ± tahminlerin yÃ¼zdesidir.** <ul><li>**FormÃ¼l:** $\text{DoÄŸruluk} = \frac{\text{DoÄŸru Tahmin SayÄ±sÄ±}}{\text{Toplam Tahmin SayÄ±sÄ±}}$</li><li>**Ã–rnek:** 100 tahminden 85'i doÄŸruysa, DoÄŸruluk = %85.</li></ul> | âœ…ğŸ’¯ |
| **âš ï¸ DoÄŸruluk (Accuracy) ile Ä°lgili Sorunlar** | DoÄŸruluk iyi bir baÅŸlangÄ±Ã§ olsa da, birÃ§ok durumda **yanÄ±ltÄ±cÄ±** olabilir ve daha detaylÄ± araÃ§lar (Ã¶rn. KarÄ±ÅŸÄ±klÄ±k Matrisi) gerektirir: | ğŸš¨âŒ |
| **Dengesiz Veri (Imbalanced Data)** | Veri sÄ±nÄ±flarÄ± arasÄ±nda bÃ¼yÃ¼k fark varsa (Ã¶rn. dolandÄ±rÄ±cÄ±lÄ±k tespiti: %99 "dolandÄ±rÄ±cÄ±lÄ±k deÄŸil"), modelin her zaman "dolandÄ±rÄ±cÄ±lÄ±k deÄŸil" tahmin etmesi %99 doÄŸruluk verir, ancak **dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± asla yakalamadÄ±ÄŸÄ± iÃ§in iÅŸe yaramaz.** | âš–ï¸ğŸ“‰ |
| **FarklÄ± Hata Maliyetleri** | Hatalar her zaman eÅŸit derecede kÃ¶tÃ¼ deÄŸildir. TÄ±bbi teÅŸhiste, hasta birini saÄŸlÄ±klÄ± tahmin etmek (**yanlÄ±ÅŸ negatif**) **hayatÃ® tehlike** yaratabilirken, saÄŸlÄ±klÄ± birini hasta tahmin etmek (**yanlÄ±ÅŸ pozitif**) sadece rahatsÄ±zlÄ±k verir. DoÄŸruluk bu hatalar arasÄ±ndaki farkÄ± gÃ¶zetmez. | ğŸ©ºğŸ’” |
| **Modelin Nerede BaÅŸarÄ±sÄ±z OlduÄŸunu Gizlemesi** | DoÄŸruluk tek bir sayÄ± verir. Modelin yaptÄ±ÄŸÄ± hatalarÄ±n **tÃ¼rÃ¼nÃ¼** (Ã¶rn. Titanic'te hayatta kalanÄ± mÄ± kaÃ§Ä±rÄ±yor, yoksa Ã¶leni mi yanlÄ±ÅŸ tahmin ediyor?) gÃ¶stermez. | ğŸ”â“ |
| **SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± DeÄŸiÅŸikliklerine DuyarsÄ±zlÄ±k** | SÄ±nÄ±flar arasÄ±ndaki denge zamanla deÄŸiÅŸirse (Ã¶rn. dolandÄ±rÄ±cÄ±lÄ±k %1'den %10'a Ã§Ä±karsa), Ã¶nceden "doÄŸru" gÃ¶rÃ¼nen bir model aniden kÃ¶tÃ¼ performans gÃ¶sterebilir. DoÄŸruluk bu deÄŸiÅŸimi tek baÅŸÄ±na yeterince hÄ±zlÄ± bir ÅŸekilde uyarmayabilir. | ğŸ”„ğŸ“¢ |

# Confusion Matrix

<img width="567" height="330" alt="image" src="https://github.com/user-attachments/assets/e12e9ef5-0d47-466b-84d1-b92a347b8d9a" />

A **confusion matrix** is a simple table that shows how many predictions your model got right, and what kinds of errors it made.

# ğŸ“Š KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix) Nedir?

KarÄ±ÅŸÄ±klÄ±k Matrisi, bir sÄ±nÄ±flandÄ±rma modelinin yaptÄ±ÄŸÄ± doÄŸru tahminlerin sayÄ±sÄ±nÄ± ve **ne tÃ¼r hatalar** yaptÄ±ÄŸÄ±nÄ± gÃ¶steren basit ama gÃ¼Ã§lÃ¼ bir tablodur. Modelin performansÄ±na dair **tam bir resim** sunar.

---

## ğŸ§­ KarÄ±ÅŸÄ±klÄ±k Matrisinin YapÄ±sÄ± ve MantÄ±ÄŸÄ±

| Kavram | AÃ§Ä±klama | Ã–rnek Durum (Spam Tespiti) | SonuÃ§/Durum | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **DoÄŸru Pozitif (TP)** | Model, pozitif sÄ±nÄ±fÄ± **doÄŸru** tahmin etti. | Model, bir e-postayÄ± **SPAM** olarak tahmin etti ve e-posta **gerÃ§ekten SPAM'di**. | BaÅŸarÄ±, DoÄŸru Tespit | âœ…ğŸ¯ |
| **DoÄŸru Negatif (TN)** | Model, negatif sÄ±nÄ±fÄ± **doÄŸru** tahmin etti. | Model, bir e-postayÄ± **SPAM DEÄÄ°L** olarak tahmin etti ve e-posta **gerÃ§ekten SPAM DEÄÄ°LDÄ°**. | BaÅŸarÄ±, DoÄŸru Reddetme | âœ…ğŸ›¡ï¸ |
| **YanlÄ±ÅŸ Pozitif (FP)** | Model pozitif tahmin etti, ancak **gerÃ§ekte negatif'ti** ("YanlÄ±ÅŸ Alarm"). | Model, bir e-postayÄ± **SPAM** olarak tahmin etti ancak e-posta **gerÃ§ekte SPAM DEÄÄ°LDÄ°** (Ã–nemli bir e-postanÄ±n kaÃ§Ä±rÄ±lmasÄ±). | Hata (Tip I), YanlÄ±ÅŸ Alarm | ğŸ›‘ğŸ”” |
| **YanlÄ±ÅŸ Negatif (FN)** | Model negatif tahmin etti, ancak **gerÃ§ekte pozitif'ti** ("GÃ¶zden KaÃ§Ä±rma"). | Model, bir e-postayÄ± **SPAM DEÄÄ°L** olarak tahmin etti ancak e-posta **gerÃ§ekte SPAM'di** (Gereksiz e-postanÄ±n gelen kutusuna dÃ¼ÅŸmesi). | Hata (Tip II), GÃ¶zden KaÃ§Ä±rma | âŒğŸ™ˆ |

---

## âš™ï¸ KarÄ±ÅŸÄ±klÄ±k Matrisi NasÄ±l Ã‡alÄ±ÅŸÄ±r?

1. **Tahmin Ãœretme:** Modelinizden test verileri iÃ§in tahminler ($y_{tahmin}$) alÄ±rsÄ±nÄ±z.
2. **KarÅŸÄ±laÅŸtÄ±rma:** Bu tahminleri, verinin **gerÃ§ek etiketleri** ($y_{gerÃ§ek}$) ile tek tek karÅŸÄ±laÅŸtÄ±rÄ±rsÄ±nÄ±z.
3. **Kategorilendirme:** Her bir tahmin, gerÃ§ek etikete gÃ¶re TP, TN, FP veya FN kategorilerinden birine yerleÅŸtirilir.

Modelin yalnÄ±zca **doÄŸru mu yanlÄ±ÅŸ mÄ±** tahmin ettiÄŸine deÄŸil; **ne tÃ¼r bir hata** yaptÄ±ÄŸÄ±na (YanlÄ±ÅŸ Pozitif mi, YanlÄ±ÅŸ Negatif mi) odaklanÄ±lÄ±r.

### Ã–rnek Tablo DÃ¼zeni

KarÄ±ÅŸÄ±klÄ±k matrisinin geleneksel yapÄ±sÄ± (etiketlerin yerleÅŸimi farklÄ± kaynaklarda deÄŸiÅŸebilir, ancak mantÄ±k aynÄ± kalÄ±r):

| | **Tahmin Edilen Pozitif** | **Tahmin Edilen Negatif** |
| :--- | :--- | :--- |
| **GerÃ§ek Pozitif** | **DoÄŸru Pozitif (TP)** | **YanlÄ±ÅŸ Negatif (FN)** |
| **GerÃ§ek Negatif** | **YanlÄ±ÅŸ Pozitif (FP)** | **DoÄŸru Negatif (TN)** |

> **UnutmayÄ±n:** BazÄ± kaynaklar satÄ±rlarÄ± "GerÃ§ek" ve sÃ¼tunlarÄ± "Tahmin Edilen" olarak alÄ±rken, bazÄ±larÄ± tam tersini kullanÄ±r. Ã–nemli olan, her hÃ¼credeki tanÄ±mÄ±n (TP, TN, FP, FN) neyi temsil ettiÄŸini anlamaktÄ±r.
>
> # ğŸ” KarÄ±ÅŸÄ±klÄ±k Matrisi UygulamalarÄ±: DolandÄ±rÄ±cÄ±lÄ±k vs. Spam

KarÄ±ÅŸÄ±klÄ±k Matrisi, iki farklÄ± ikili sÄ±nÄ±flandÄ±rma probleminde (DolandÄ±rÄ±cÄ±lÄ±k Tespiti ve Spam SÄ±nÄ±flandÄ±rmasÄ±) modelin yaptÄ±ÄŸÄ± hatalarÄ±n tÃ¼rlerini ve Ã¶nem derecelerini anlamak iÃ§in kullanÄ±lÄ±r.

---

## ğŸ”¬ KarÅŸÄ±laÅŸtÄ±rmalÄ± Hata Analizi Tablosu

| Kavram | Tipi | 1. Ã–rnek: DolandÄ±rÄ±cÄ±lÄ±k Tespiti (Pozitif = DolandÄ±rÄ±cÄ±lÄ±k) | 2. Ã–rnek: Spam SÄ±nÄ±flandÄ±rmasÄ± (Pozitif = Spam) | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **DoÄŸru Pozitif (TP)** | âœ… DoÄŸru Tahmin | **GerÃ§ek DolandÄ±rÄ±cÄ±lÄ±k** doÄŸru ÅŸekilde **DOLANDIRICILIK** olarak iÅŸaretlendi. | **GerÃ§ek Spam** doÄŸru ÅŸekilde **SPAM** olarak iÅŸaretlendi. | ğŸ¯ğŸ’° |
| **DoÄŸru Negatif (TN)** | âœ… DoÄŸru Tahmin | **Normal Ä°ÅŸlem** doÄŸru ÅŸekilde **NORMAL** olarak tanÄ±mlandÄ±. | **GerÃ§ek E-posta** doÄŸru ÅŸekilde **SPAM DEÄÄ°L** olarak sÄ±nÄ±flandÄ±rÄ±ldÄ±. | ğŸ›¡ï¸ğŸ“§ |
| **YanlÄ±ÅŸ Pozitif (FP)** | âŒ Tip 1 Hata | **Normal Ä°ÅŸlem** yanlÄ±ÅŸlÄ±kla **DOLANDIRICILIK** olarak iÅŸaretlendi. (YanlÄ±ÅŸ Alarm). | **GerÃ§ek E-posta** yanlÄ±ÅŸlÄ±kla **SPAM** olarak iÅŸaretlendi. (KullanÄ±cÄ± iÃ§in can sÄ±kÄ±cÄ±). | ğŸ””ğŸ›‘ |
| **YanlÄ±ÅŸ Negatif (FN)** | âŒ Tip 2 Hata | **GerÃ§ek DolandÄ±rÄ±cÄ±lÄ±k** yanlÄ±ÅŸlÄ±kla **NORMAL** iÅŸlem olarak gÃ¶zden kaÃ§Ä±rÄ±ldÄ±. (KaÃ§Ä±rÄ±lan Vaka). | **GerÃ§ek Spam** yanlÄ±ÅŸlÄ±kla **SPAM DEÄÄ°L** olarak sÄ±nÄ±flandÄ±rÄ±ldÄ±. (Gelen kutusuna dÃ¼ÅŸen spam, **tehlikeli**). | ğŸš¨ğŸ™ˆ |

---

## âš–ï¸ Hata TÃ¼rlerinin Ã–nemi ve Ã–lÃ§eklendirme

### 1. DolandÄ±rÄ±cÄ±lÄ±k Tespiti BaÄŸlamÄ±

* **Pozitif SÄ±nÄ±f:** DolandÄ±rÄ±cÄ±lÄ±k (`Fraud`).
* **Ã–nem:** **GerÃ§ek dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± yakalamak (TP)**, yanlÄ±ÅŸ alarm vermekten (FP) daha Ã¶nemlidir.
* **FN Maliyeti:** Modelin gerÃ§ek dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± kaÃ§Ä±rmasÄ± bÃ¼yÃ¼k finansal kayÄ±plara yol aÃ§abilir.

### 2. Spam SÄ±nÄ±flandÄ±rmasÄ± BaÄŸlamÄ±

* **Pozitif SÄ±nÄ±f:** Spam.
* **FP Maliyeti:** GerÃ§ek bir e-postanÄ±n spam kutusuna dÃ¼ÅŸmesi (**FP**), kullanÄ±cÄ±nÄ±n Ã¶nemli bilgileri kaÃ§Ä±rmasÄ±na neden olur (Can sÄ±kÄ±cÄ±).
* **FN Maliyeti:** Bir spam e-postanÄ±n gelen kutusuna dÃ¼ÅŸmesi (**FN**), kullanÄ±cÄ±yÄ± potansiyel tehlikeye (kimlik avÄ±, virÃ¼s) maruz bÄ±rakÄ±r (Tehlikeli).

### Sonraki AdÄ±mlar

KarÄ±ÅŸÄ±klÄ±k Matrisi, doÄŸru ve yanlÄ±ÅŸ tahminlerin **mutlak sayÄ±larÄ±nÄ±** gÃ¶sterir. Bu, haftalÄ±k bazda kaÃ§ e-postanÄ±n yanlÄ±ÅŸlÄ±kla spam'e gÃ¶nderildiÄŸi gibi Ã¶lÃ§ek hakkÄ±nda fikir edinmek iÃ§in kullanÄ±ÅŸlÄ±dÄ±r.

Ancak, modelleri karÅŸÄ±laÅŸtÄ±rmak veya zaman iÃ§indeki performanslarÄ±nÄ± izlemek iÃ§in **mutlak sayÄ±lar yerine gÃ¶receli metrikler** gereklidir. Bu kalite metrikleri (DoÄŸruluk, DuyarlÄ±lÄ±k/Recall, Kesinlik/Precision, F1 Skoru) doÄŸrudan KarÄ±ÅŸÄ±klÄ±k Matrisi'nden tÃ¼retilebilir.

---
# ğŸŒŸ KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix) Neden KullanÄ±ÅŸlÄ±dÄ±r?

DoÄŸruluk (Accuracy) tek bir sayÄ± verirken, KarÄ±ÅŸÄ±klÄ±k Matrisi, modelin performansÄ±na dair Ã§ok daha derin ve eyleme geÃ§irilebilir bir bakÄ±ÅŸ aÃ§Ä±sÄ± sunar. Modelin **ne tÃ¼r hatalar yaptÄ±ÄŸÄ±nÄ±** ve hangi sÄ±nÄ±fta daha baÅŸarÄ±lÄ± olduÄŸunu detaylandÄ±rÄ±r.

---

## ğŸ”‘ KarÄ±ÅŸÄ±klÄ±k Matrisinin SaÄŸladÄ±ÄŸÄ± Temel Avantajlar Tablosu

| SaÄŸladÄ±ÄŸÄ± Bilgi | AÃ§Ä±klama | DoÄŸruluk'tan (Accuracy) FarkÄ± | Emoji |
| :--- | :--- | :--- | :--- |
| **Hata TÃ¼rlerini AyÄ±rt Etme** | Modelin yaptÄ±ÄŸÄ± hatalarÄ±n tÃ¼rÃ¼nÃ¼ gÃ¶sterir: **YanlÄ±ÅŸ Pozitif (FP)** (YanlÄ±ÅŸ Alarm) mÄ± daha fazla, yoksa **YanlÄ±ÅŸ Negatif (FN)** (GÃ¶zden KaÃ§Ä±rma) mÄ±? Bu, probleme gÃ¶re hangi hatanÄ±n maliyetinin daha yÃ¼ksek olduÄŸunu anlamamÄ±zÄ± saÄŸlar. | DoÄŸruluk, tÃ¼m yanlÄ±ÅŸ tahminleri tek bir 'hata' olarak sayar. | ğŸš¨ğŸ” |
| **SÄ±nÄ±f BazÄ±nda Performans** | Modelin belirli bir sÄ±nÄ±fÄ± (Ã¶rneÄŸin, Titanic'te hayatta kalanlar) bulmakta mÄ± yoksa diÄŸer sÄ±nÄ±fÄ± (hayatta kalmayanlar) bulmakta mÄ± daha iyi olduÄŸunu netleÅŸtirir. | DoÄŸruluk, modelin sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±na olan hassasiyetini gizler. | ğŸ“ŠğŸ¯ |
| **GeliÅŸmiÅŸ Metriklere Temel** | DoÄŸrudan KarÄ±ÅŸÄ±klÄ±k Matrisi'nden **Kesinlik (Precision)**, **DuyarlÄ±lÄ±k (Recall)** ve **F1 Skoru** gibi daha gÃ¼Ã§lÃ¼ ve dengesiz veri setlerinde dahi anlamlÄ± olan metrikler tÃ¼retilebilir. | DoÄŸruluk, bu karmaÅŸÄ±k metriklerin bileÅŸenlerini saÄŸlamaz. | â•ğŸ“ |
| **Ã–lÃ§ek Hissi** | HatalarÄ±n ve doÄŸru tahminlerin **mutlak sayÄ±larÄ±nÄ±** gÃ¶stererek, problem Ã¶lÃ§eÄŸi hakkÄ±nda fikir verir. (*Ã–rn: "GeÃ§en hafta 500 gerÃ§ek dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± kaÃ§Ä±rdÄ±k (FN)."*) | DoÄŸruluk sadece yÃ¼zde verir, mutlak sayÄ±larÄ± gÃ¶stermez. | ğŸ”¢ğŸ“ |

---

## ğŸ’¡ Ã–rnek KullanÄ±m Durumu: Titanic

| Durum | KarÄ±ÅŸÄ±klÄ±k Matrisi NasÄ±l YardÄ±mcÄ± Olur? |
| :--- | :--- |
| **AmaÃ§:** Hayatta kalanlarÄ± bulmak kritik Ã¶neme sahiptir. | Matris, modelin kaÃ§ tane gerÃ§ek hayatta kalanÄ± kaÃ§Ä±rdÄ±ÄŸÄ±nÄ± (**FN**) ve kaÃ§ tane hayatta kalmayanÄ± yanlÄ±ÅŸlÄ±kla hayatta kaldÄ± diye tahmin ettiÄŸini (**FP**) gÃ¶sterir. |
| **Analiz:** Modeliniz yÃ¼ksek bir **FN** sayÄ±sÄ±na sahipse (Ã§ok sayÄ±da hayatta kalanÄ± kaÃ§Ä±rÄ±yorsa), bu, **DuyarlÄ±lÄ±k (Recall)** metriÄŸinin dÃ¼ÅŸÃ¼k olacaÄŸÄ± anlamÄ±na gelir. Bu bilgiyle modeli iyileÅŸtirmeye odaklanabilirsiniz. |

**SonuÃ§:** KarÄ±ÅŸÄ±klÄ±k Matrisi, sadece **"ne kadar doÄŸru"** sorusunu deÄŸil, aynÄ± zamanda **"ne tÃ¼r hatalar yapÄ±yor ve hangi sÄ±nÄ±flarda baÅŸarÄ±lÄ±?"** sorusunu da yanÄ±tlayarak model deÄŸerlendirmesini bir sonraki seviyeye taÅŸÄ±r.





# ğŸ”¬ KarÄ±ÅŸÄ±klÄ±k Matrisi'nin (Confusion Matrix) Matematiksel KÃ¶keni

KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix), doÄŸrudan belirli bir olasÄ±lÄ±k baÅŸlÄ±ÄŸÄ±ndan esinlenmek yerine, **sÄ±nÄ±flandÄ±rma performansÄ±nÄ± Ã¶lÃ§me** ihtiyacÄ±ndan doÄŸmuÅŸtur. Ancak, temel mantÄ±ÄŸÄ± istatistik ve karar teorisindeki kÃ¶klÃ¼ kavramlarla yakÄ±ndan iliÅŸkilidir.

---

## 1. ğŸ¥‡ Ana Ä°liÅŸkili BaÅŸlÄ±k: Hipotez Testi ve Hata TÃ¼rleri

KarÄ±ÅŸÄ±klÄ±k Matrisi'nin temelindeki matematiksel ve istatistiksel mantÄ±k, en gÃ¼Ã§lÃ¼ ÅŸekilde **Hipotez Testi** ve bu testlerde ortaya Ã§Ä±kan hata tÃ¼rleri ile iliÅŸkilidir.

| KarÄ±ÅŸÄ±klÄ±k Matrisi KavramÄ± | Hipotez Testi KarÅŸÄ±lÄ±ÄŸÄ± | Ä°statistiksel GÃ¶sterim | AÃ§Ä±klama | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **YanlÄ±ÅŸ Pozitif (FP)** | **Tip I Hata (False Alarm)** | Alfa ($\alpha$) | BoÅŸ hipotezin ($H_0$) **doÄŸru olduÄŸu halde** reddedilmesi. (*Ã–rnek: Model, normal bir iÅŸlemi dolandÄ±rÄ±cÄ±lÄ±k diye reddetti.*) | ğŸš¨âŒ |
| **YanlÄ±ÅŸ Negatif (FN)** | **Tip II Hata (Missed Case)** | Beta ($\beta$) | BoÅŸ hipotezin ($H_0$) **yanlÄ±ÅŸ olduÄŸu halde** reddedilememesi. (*Ã–rnek: Model, gerÃ§ek dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± normal iÅŸlem diye gÃ¶zden kaÃ§Ä±rdÄ±.*) | ğŸ™ˆâš ï¸ |

**SonuÃ§:** KarÄ±ÅŸÄ±klÄ±k Matrisi, sÄ±nÄ±flandÄ±rma problemini, **hata maliyetlerinin** deÄŸerlendirildiÄŸi bir **Hipotez Testi** Ã§erÃ§evesine oturtan somut bir uygulamadÄ±r.

---

## 2. ğŸ“š Esin KaynaÄŸÄ± Olabilecek DiÄŸer Temel Alanlar

KarÄ±ÅŸÄ±klÄ±k Matrisi'nin geliÅŸtirilmesi ve yaygÄ±nlaÅŸmasÄ±, genel olarak ÅŸu disiplinlerde kÃ¶k salmÄ±ÅŸtÄ±r:

| Alan/Kavram | AÃ§Ä±klama | Emoji |
| :--- | :--- | :--- |
| **Karar Teorisi** | Bir kararÄ±n (pozitif/negatif tahmin) hem doÄŸru hem de yanlÄ±ÅŸ sonuÃ§larÄ±nÄ±n **maliyetini ve faydasÄ±nÄ±** deÄŸerlendirir. Matris, bu kararlarÄ±n sonuÃ§larÄ±nÄ± kategorize etmemizi saÄŸlar. | ğŸ§ âš–ï¸ |
| **Ä°kili SÄ±nÄ±flandÄ±rma (Binary Classification)** | Matris, iki farklÄ± sÄ±nÄ±fÄ± (Ã¶rneÄŸin Spam/DeÄŸil, DolandÄ±rÄ±cÄ±lÄ±k/DeÄŸil) ayÄ±rt etmeye Ã§alÄ±ÅŸan sistemlerin performansÄ±nÄ± Ã¶lÃ§mek iÃ§in geliÅŸtirilmiÅŸ **standart bir araÃ§tÄ±r**. | ğŸ·ï¸0ï¸âƒ£1ï¸âƒ£ |
| **Desen TanÄ±ma (Pattern Recognition)** | Ã–zellikle 1900'lÃ¼ yÄ±llarÄ±n ortalarÄ±ndan itibaren desen tanÄ±ma algoritmalarÄ± geliÅŸirken, bu algoritmalarÄ±n doÄŸruluÄŸunu **detaylÄ± ve kategorize edilmiÅŸ** bir ÅŸekilde Ã¶lÃ§me ihtiyacÄ±yla popÃ¼lerlik kazanmÄ±ÅŸtÄ±r. | ğŸ–¼ï¸ğŸ§ |
| **Ã–lÃ§Ã¼m Teorisi (Measurement Theory)** | Veri biliminde model performansÄ±nÄ±n gÃ¼venilir ve tutarlÄ± bir ÅŸekilde Ã¶lÃ§Ã¼lmesini saÄŸlar. Matris, gÃ¶receli metrikler (Kesinlik, DuyarlÄ±lÄ±k vb.) tÃ¼retmek iÃ§in temel oluÅŸturur. | ğŸ“ğŸ“ˆ |

---

## â­ Ã–zet

KarÄ±ÅŸÄ±klÄ±k Matrisi, makine Ã¶ÄŸreniminde kritik bir deÄŸerlendirme aracÄ±dÄ±r. **Matematiksel kÃ¶keni** en gÃ¼Ã§lÃ¼ ÅŸekilde **Ä°statistik ve Hipotez Testi'ndeki Tip I ve Tip II Hata** kavramlarÄ±na dayanÄ±r. Matris, bu soyut hata kavramlarÄ±nÄ±, sÄ±nÄ±flandÄ±rma sonuÃ§larÄ±nÄ±n **sayÄ±labilir** ve **anlaÅŸÄ±labilir** bir tablo yapÄ±sÄ±yla somutlaÅŸtÄ±rÄ±r.

---


# ğŸ“ˆ Model DeÄŸerlendirme: DuyarlÄ±lÄ±k (Recall), Kesinlik (Precision) ve F1 Skoru

KarÄ±ÅŸÄ±klÄ±k Matrisi'ni anladÄ±ktan sonra, modelin performansÄ±nÄ± tek bir sayÄ±dan (DoÄŸruluk) daha derinlemesine analiz etmemizi saÄŸlayan temel sÄ±nÄ±flandÄ±rma metriklerini hesaplayabiliriz. Bu metrikler, bazÄ± hatalarÄ±n diÄŸerlerinden daha maliyetli olduÄŸu durumlarda hayati Ã¶nem taÅŸÄ±r.

---

## 1. ğŸ” DoÄŸruluÄŸu Yeniden TanÄ±mlama (Accuracy Review)

DoÄŸruluk, modelin toplam tahminler iÃ§inde doÄŸru yaptÄ±ÄŸÄ± tahminlerin yÃ¼zdesiydi. KarÄ±ÅŸÄ±klÄ±k Matrisi terimleriyle DoÄŸruluk:

$$\text{DoÄŸruluk (Accuracy)} = \frac{\text{DoÄŸru Pozitif (TP)} + \text{DoÄŸru Negatif (TN)}}{\text{TP} + \text{TN} + \text{YanlÄ±ÅŸ Pozitif (FP)} + \text{YanlÄ±ÅŸ Negatif (FN)}}$$

| Metrik | AnlamÄ± | KÄ±sÄ±tlÄ±lÄ±ÄŸÄ± | Emoji |
| :--- | :--- | :--- | :--- |
| **DoÄŸruluk (Accuracy)** | Modelin **genel olarak** ne kadar sÄ±k doÄŸru tahmin yaptÄ±ÄŸÄ±. | Hata tÃ¼rleri (FP vs. FN) arasÄ±ndaki farkÄ± gÃ¶rmezden gelir ve **dengesiz veri setlerinde** yanÄ±ltÄ±cÄ± olabilir. | âš–ï¸â“ |

---

## 2. ğŸ¯ DuyarlÄ±lÄ±k (Recall) ve Kesinlik (Precision)

Bu metrikler, modelin pozitif sÄ±nÄ±fÄ± ne kadar iyi ele aldÄ±ÄŸÄ±nÄ± farklÄ± aÃ§Ä±lardan deÄŸerlendirir. Spam sÄ±nÄ±flandÄ±rma Ã¶rneÄŸini ($Pozitif = Spam$) kullanacaÄŸÄ±z.

### 2.1. DuyarlÄ±lÄ±k (Recall) - GerÃ§ek Pozitiflerin OranÄ±

| Kavram | AÃ§Ä±klama | FormÃ¼l | Spam Ã–rneÄŸindeki Odak ||
| :--- | :--- | :--- | :--- | :--- |
| **DuyarlÄ±lÄ±k (Recall)** | **GerÃ§ekte pozitif olan vakalarÄ±n** ne kadarÄ±nÄ± modelin **doÄŸru yakaladÄ±ÄŸÄ±nÄ±** Ã¶lÃ§er. AynÄ± zamanda *Hassasiyet (Sensitivity)* olarak da bilinir. | $$\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$$ | Modelin **gerÃ§ek spam e-postalarÄ± ne kadar baÅŸarÄ±yla SPAM olarak iÅŸaretlediÄŸi** (HiÃ§ spam kaÃ§Ä±rÄ±yor muyuz?). **YÃ¼ksek Recall**, **az FN** (gÃ¶zden kaÃ§Ä±rma) anlamÄ±na gelir. | ğŸ£âœ… |
| **Ne Zaman Ã–nemli?** | **YanlÄ±ÅŸ Negatif (FN)** maliyetinin Ã§ok yÃ¼ksek olduÄŸu durumlar (Ã–rn: TÄ±bbi teÅŸhis - hasta birini saÄŸlÄ±klÄ± sanmak, DolandÄ±rÄ±cÄ±lÄ±k tespiti - gerÃ§ek dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± kaÃ§Ä±rmak). | - | - | ğŸš¨ |

### 2.2. Kesinlik (Precision) - Tahminlerin GÃ¼venirliÄŸi

| Kavram | AÃ§Ä±klama | FormÃ¼l | Spam Ã–rneÄŸindeki Odak ||
| :--- | :--- | :--- | :--- | :--- |
| **Kesinlik (Precision)** | Modelin **pozitif olarak tahmin ettiÄŸi vakalarÄ±n** ne kadarÄ±nÄ±n **gerÃ§ekten pozitif** olduÄŸunu Ã¶lÃ§er. | $$\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$$ | Modelin **SPAM olarak iÅŸaretlediÄŸi** e-postalarÄ±n ne kadarÄ±nÄ±n **gerÃ§ekten spam olduÄŸu** (YanlÄ±ÅŸ alarm Ã§alÄ±yor muyuz?). **YÃ¼ksek Precision**, **az FP** (yanlÄ±ÅŸ alarm) anlamÄ±na gelir. | ğŸ›¡ï¸ğŸ‘ |
| **Ne Zaman Ã–nemli?** | **YanlÄ±ÅŸ Pozitif (FP)** maliyetinin Ã§ok yÃ¼ksek olduÄŸu durumlar (Ã–rn: Yasal iÅŸlem baÅŸlatma - masum birini suÃ§lamak, Spam Filtresi - Ã¶nemli bir e-postayÄ± spam klasÃ¶rÃ¼ne gÃ¶ndermek). | - | - | ğŸ›‘ |

---

## 3. âš–ï¸ F1 Skoru - Denge ve Uyum

DuyarlÄ±lÄ±k ve Kesinlik genellikle **ters orantÄ±lÄ±** Ã§alÄ±ÅŸÄ±r. Birini artÄ±rmak, diÄŸerini dÃ¼ÅŸÃ¼rebilir. Her iki metriÄŸin de Ã¶nemli olduÄŸu durumlarda, **F1 Skoru** kullanÄ±lÄ±r.

| Kavram | AÃ§Ä±klama | FormÃ¼l | Odak ||
| :--- | :--- | :--- | :--- | :--- |
| **F1 Skoru** | **Kesinlik ve DuyarlÄ±lÄ±k'Ä±n harmonik ortalamasÄ±dÄ±r**. Her iki metriÄŸi de dikkate alan **tek bir dengeleyici metrik** saÄŸlar. | $$\text{F1 Skoru} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$ | Modelin hem **gÃ¶zden kaÃ§Ä±rma (FN)** hem de **yanlÄ±ÅŸ alarm (FP)** hatalarÄ±nÄ± aynÄ± anda minimize ederek **dengeli** performans gÃ¶stermesini ister. | ğŸ¤ğŸ’¯ |
| **Ne Zaman Ã–nemli?** | SÄ±nÄ±flandÄ±rma performansÄ±nda hem **FN** hem de **FP** hatalarÄ±nÄ±n maliyetinin yÃ¼ksek ve her iki metriÄŸin de optimize edilmesinin istendiÄŸi durumlar. | - | - | âœ¨ |

---

# ğŸ—ï¸ Model DeÄŸerlendirme: Kilit Ã‡Ä±karÄ±mlar ve Metrikler

Bir sÄ±nÄ±flandÄ±rma modelinin performansÄ±nÄ± anlamak iÃ§in tek baÅŸÄ±na DoÄŸruluk (Accuracy) yeterli deÄŸildir. AÅŸaÄŸÄ±daki temel metrikler ve araÃ§lar, modelin hatalarÄ±nÄ± ve gerÃ§ek dÃ¼nya uygulamasÄ±ndaki gÃ¼cÃ¼nÃ¼ detaylÄ±ca analiz etmemizi saÄŸlar.

---

## ğŸ“‹ Temel Metrikler ve KullanÄ±m AlanlarÄ± Tablosu

| Metrik/Kavram | AÃ§Ä±klamasÄ± | FormÃ¼l (KarÄ±ÅŸÄ±klÄ±k Matrisi Terimleriyle) | KullanÄ±m AlanÄ± ve Ã–nemi | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **KarÄ±ÅŸÄ±klÄ±k Matrisi** | Modelin yaptÄ±ÄŸÄ± doÄŸru pozitif (TP), yanlÄ±ÅŸ pozitif (FP), doÄŸru negatif (TN) ve yanlÄ±ÅŸ negatif (FN) sayÄ±larÄ±nÄ±n gÃ¶sterildiÄŸi temel tablo. Modelin hatalarÄ±nÄ±n **tÃ¼rÃ¼nÃ¼ ve nerede meydana geldiÄŸini** gÃ¶sterir. | $\text{TP, TN, FP, FN SayÄ±larÄ±}$ | TÃ¼m metriklerin temelini oluÅŸturur. Modelin **YanlÄ±ÅŸ Alarm (FP)** mÄ± yoksa **GÃ¶zden KaÃ§Ä±rma (FN)** mÄ± yaptÄ±ÄŸÄ±nÄ± netleÅŸtirir. | ğŸ“ŠğŸ‘€ |
| **DoÄŸruluk (Accuracy)** | Modelin toplam tahminler iÃ§inde **doÄŸru yaptÄ±ÄŸÄ± tahminlerin yÃ¼zdesi**. Ä°yi bir baÅŸlangÄ±Ã§tÄ±r, ancak modelin sadece genel baÅŸarÄ±sÄ±nÄ± gÃ¶sterir. | $\frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$ | **Genel Performans** iÃ§in kullanÄ±lÄ±r. **Dengesiz veri** setlerinde tek baÅŸÄ±na yeterli ve yanÄ±ltÄ±cÄ± deÄŸildir. | âœ…âš–ï¸ |
| **Kesinlik (Precision)** | Modelin **pozitif olarak tahmin ettiÄŸi** durumlarÄ±n ne kadarÄ±nÄ±n **gerÃ§ekte pozitif** olduÄŸunu Ã¶lÃ§er. Tahminlerin gÃ¼venilirliÄŸini gÃ¶sterir. | $\frac{\text{TP}}{\text{TP} + \text{FP}}$ | **YanlÄ±ÅŸ Pozitif (FP)** maliyetinin yÃ¼ksek olduÄŸu durumlar Ã¶nemlidir. *Ã–rnek: Spam tespiti* (GerÃ§ek bir e-postanÄ±n spam kutusuna gitmemesi iÃ§in). | ğŸ›¡ï¸ğŸ‘ |
| **DuyarlÄ±lÄ±k (Recall)** | **GerÃ§ekte pozitif olan** durumlarÄ±n ne kadarÄ±nÄ± modelin **doÄŸru olarak tanÄ±mladÄ±ÄŸÄ±nÄ±** Ã¶lÃ§er. GÃ¶zden kaÃ§Ä±rma oranÄ±nÄ± gÃ¶sterir. (*Hassasiyet* olarak da bilinir.) | $\frac{\text{TP}}{\text{TP} + \text{FN}}$ | **YanlÄ±ÅŸ Negatif (FN)** maliyetinin yÃ¼ksek olduÄŸu durumlar Ã¶nemlidir. *Ã–rnek: DolandÄ±rÄ±cÄ±lÄ±k tespiti* (GerÃ§ek dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± kaÃ§Ä±rmamak iÃ§in). | ğŸ£ğŸš¨ |
| **F1 Skoru** | Kesinlik ve DuyarlÄ±lÄ±k'Ä±n **harmonik ortalamasÄ±dÄ±r**. Her iki metriÄŸi de dikkate alan tek bir dengeleyici metrik sunar. | $2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ | Modelin hem **yanlÄ±ÅŸ alarmÄ± hem de gÃ¶zden kaÃ§Ä±rmayÄ± minimize ederek** dengeli performans gÃ¶stermesi istendiÄŸi zaman kullanÄ±lÄ±r. Dengesiz veri setlerinde faydalÄ±dÄ±r. | ğŸ¤âœ¨ |

---

## ğŸ¯ Problemin TÃ¼rÃ¼ne GÃ¶re Metrik SeÃ§imi

FarklÄ± iÅŸ problemleri, farklÄ± hata tÃ¼rlerinin daha maliyetli olduÄŸu anlamÄ±na gelir. Bu nedenle, kritik metrik problemin odaÄŸÄ±na gÃ¶re deÄŸiÅŸir:

| Problem TÃ¼rÃ¼ | Kritik Hata TÃ¼rÃ¼ | Neden Kritik? | Ã–nemli Metrik |
| :--- | :--- | :--- | :--- |
| **DolandÄ±rÄ±cÄ±lÄ±k Tespiti** | **YanlÄ±ÅŸ Negatif (FN)** | GerÃ§ek bir dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± kaÃ§Ä±rmak (FN) bÃ¼yÃ¼k finansal kayÄ±plara neden olur. | **DuyarlÄ±lÄ±k (Recall)** olabildiÄŸince yÃ¼ksek tutulmalÄ±dÄ±r. |
| **Spam Tespiti** | **YanlÄ±ÅŸ Pozitif (FP)** | Ã–nemli bir e-postayÄ± yanlÄ±ÅŸlÄ±kla spam olarak iÅŸaretlemek (FP), kullanÄ±cÄ±nÄ±n iÅŸlerini aksatÄ±r. | **Kesinlik (Precision)** olabildiÄŸince yÃ¼ksek tutulmalÄ±dÄ±r. |
| **HastalÄ±k TeÅŸhisi** | **YanlÄ±ÅŸ Negatif (FN)** | Hasta birini saÄŸlÄ±klÄ± olarak teÅŸhis etmek (FN), hayati tehlikeye yol aÃ§abilir. | **DuyarlÄ±lÄ±k (Recall)** hayati Ã¶nem taÅŸÄ±r. |
| **E-Ticaret ÃœrÃ¼n Tavsiyesi**| **YanlÄ±ÅŸ Pozitif (FP)** | AlakasÄ±z bir Ã¼rÃ¼nÃ¼ tavsiye etmek (FP) kullanÄ±cÄ± deneyimini dÃ¼ÅŸÃ¼rÃ¼r, ancak bir hatanÄ±n maliyeti dÃ¼ÅŸÃ¼ktÃ¼r. | **Kesinlik (Precision)** genellikle daha Ã¶nemlidir. |

---
---

# ğŸ¤– Makine Ã–ÄŸrenimi SÄ±nÄ±flandÄ±rma AlgoritmalarÄ± (ML Classification Algorithms)

<img width="848" height="441" alt="image" src="https://github.com/user-attachments/assets/aaa0b49c-48e1-4ee2-8c5a-562ec05d2d23" />

[Medium](https://ai.plainenglish.io/different-types-of-machine-learning-algorithms-28974016e108)

<img width="841" height="604" alt="image" src="https://github.com/user-attachments/assets/08e6989c-f19a-41ca-9272-87f35d5141b8" />

[TDS](https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501/)


* Åimdiye kadar ilk sÄ±nÄ±flandÄ±rma modelimiz olan **Lojistik Regresyon**'u gÃ¶rdÃ¼k. SÄ±nÄ±flandÄ±rma algoritmalarÄ±, verilen bilgilere (Ã¶zelliklere) dayanarak **kategorileri (sÄ±nÄ±flarÄ±)** tahmin etmemize yardÄ±mcÄ± olur. Bu tahminler ikili (iki kategori) veya Ã§oklu sÄ±nÄ±f (ikiden fazla kategori) olabilir.

---

## ğŸ’¡ Neden Birden Fazla Algoritma Ã–ÄŸrenmeliyiz?

Veri biliminde tek bir "en iyi" algoritma yoktur. FarklÄ± algoritmalar, farklÄ± veri yapÄ±larÄ±na ve iÅŸ gereksinimlerine daha iyi uyum saÄŸlar.

| Sebep | AÃ§Ä±klama | Emoji |
| :--- | :--- | :--- |
| **FarklÄ± Veri, FarklÄ± AraÃ§** | BazÄ± modeller sayÄ±sal Ã¶zelliklerle daha iyi Ã§alÄ±ÅŸÄ±rken, diÄŸerleri karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼leri veya kategorik verileri daha etkili bir ÅŸekilde ele alÄ±r. | ğŸ› ï¸ğŸ§© |
| **DoÄŸruluk ve Performans** | Lojistik regresyonun kaÃ§Ä±rabileceÄŸi karmaÅŸÄ±k iliÅŸkileri ve Ã¶rÃ¼ntÃ¼leri daha esnek modeller yakalayabilir. | ğŸ¯ğŸš€ |
| **Yorumlanabilirlik vs. KarmaÅŸÄ±klÄ±k** | **Karar AÄŸaÃ§larÄ±** gibi bazÄ± modeller teknik olmayan kiÅŸilere kolayca aÃ§Ä±klanabilirken, **Yapay Sinir AÄŸlarÄ±** gibi diÄŸerleri "kara kutu" gibidir. | ğŸ—£ï¸â“ |
| **GerÃ§ek DÃ¼nya UygulamalarÄ±** | Uygulamada, veri bilimciler genellikle birden fazla modeli dener ve iÅŸ problemine en uygun olanÄ± seÃ§er. | ğŸŒğŸ§ª |

---

## ğŸŒ³ YaygÄ±n SÄ±nÄ±flandÄ±rma AlgoritmalarÄ±

| Algoritma | Ã‡alÄ±ÅŸma Prensibi | Temel Ã–zellikler | KullanÄ±m AlanÄ± Ã–rneÄŸi ||
| :--- | :--- | :--- | :--- | :--- |
| **Karar AÄŸaÃ§larÄ± (Decision Trees)** | Veriyi kurallara dayalÄ± dallara ayÄ±rarak tahmin yapar. | YorumlamasÄ± kolaydÄ±r, ancak kontrol edilmezse **aÅŸÄ±rÄ± uyuma (overfitting)** eÄŸilimlidir. | MÃ¼ÅŸteri risk analizi (Kurallar net gÃ¶rÃ¼lebilir). | ğŸŒ³â¡ï¸ |
| **Rastgele Ormanlar (Random Forests)** | BirÃ§ok karar aÄŸacÄ±nÄ±n (ensemble) tahminlerini birleÅŸtirir. | Tek bir aÄŸaca gÃ¶re daha doÄŸru ve daha saÄŸlamdÄ±r (daha az aÅŸÄ±rÄ± uyum). | Finansal dolandÄ±rÄ±cÄ±lÄ±k tespiti. | ğŸŒ²ğŸŒ²ğŸŒ² |
| **k-En YakÄ±n KomÅŸu (kNN)** | Bir veri noktasÄ±nÄ±, en yakÄ±nÄ±ndaki $k$ sayÄ±da komÅŸunun Ã§oÄŸunluk sÄ±nÄ±fÄ±na gÃ¶re sÄ±nÄ±flandÄ±rÄ±r. | Basit bir mantÄ±ÄŸÄ± vardÄ±r, ancak bÃ¼yÃ¼k veri setlerinde tahmin yapmasÄ± yavaÅŸ olabilir. | Tavsiye sistemleri. | ğŸ‘¥â±ï¸ |
| **Destek VektÃ¶r Makineleri (SVMs)** | SÄ±nÄ±flar arasÄ±nda en iyi ayÄ±rma sÄ±nÄ±rÄ±nÄ± ("hiper dÃ¼zlem") bulur. | YÃ¼ksek boyutlu verilerde gÃ¼Ã§lÃ¼dÃ¼r, ancak yorumlanmasÄ± zordur. | Biyoinformatik ve gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma. | âœ¨ğŸ“ |
| **NaÃ¯ve Bayes** | OlasÄ±lÄ±ÄŸa ve Bayes teoremine dayanÄ±r. Ã–zelliklerin birbirinden baÄŸÄ±msÄ±z olduÄŸunu varsayar. | Metin sÄ±nÄ±flandÄ±rmada (spam filtreleri gibi) ÅŸaÅŸÄ±rtÄ±cÄ± derecede iyi Ã§alÄ±ÅŸÄ±r. HÄ±zlÄ±dÄ±r. | E-posta spam filtreleme. | ğŸ²ğŸ“§ |
| **Yapay Sinir AÄŸlarÄ± (Neural Networks)** | Ä°nsan beyninden esinlenilmiÅŸtir; katmanlar halinde karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼leri Ã¶ÄŸrenir. | Ã‡ok karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼leri Ã¶ÄŸrenebilir, ancak bÃ¼yÃ¼k veri setleri ve yÃ¼ksek hesaplama gÃ¼cÃ¼ gerektirir. | GÃ¶rÃ¼ntÃ¼ tanÄ±ma, doÄŸal dil iÅŸleme. | ğŸ§ âš¡ |

---
# âš–ï¸ YanlÄ±lÄ±k-Varyans DeÄŸiÅŸ TokuÅŸu (Bias-Variance Tradeoff)

YanlÄ±lÄ±k-Varyans DeÄŸiÅŸ TokuÅŸu, bir modelin karmaÅŸÄ±klÄ±ÄŸÄ± ile yeni verilere genelleme yeteneÄŸi arasÄ±ndaki temel Ã§eliÅŸkiyi ifade eden, makine Ã¶ÄŸreniminin en Ã¶nemli konseptlerinden biridir.

---

## 1. ğŸ” Temel Kavramlar

 <img width="357" height="316" alt="image" src="https://github.com/user-attachments/assets/38643a68-6ef9-4fe1-934f-bf431edee4a1" /
 
| Kavram | TanÄ±m (Ä°ngilizce Terim) | Model Durumu | Ã–rnek ||
| :--- | :--- | :--- | :--- | :--- |
| **YanlÄ±lÄ±k (Bias)** | Modeldeki yanlÄ±ÅŸ varsayÄ±mlardan kaynaklanan hata. Modelin veri karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yakalayamayacak kadar **basit** olmasÄ±. | **Eksik Uyum (Underfitting)** | Titanic hayatta kalma oranÄ±nÄ± tahmin etmek iÃ§in sadece dÃ¼z bir Ã§izgi (Linear Regression) kullanmak. Model, temel iliÅŸkileri gÃ¶z ardÄ± eder. | ğŸ‘¶âŒ |
| **Varyans (Variance)** | Modelin, eÄŸitim verisindeki kÃ¼Ã§Ã¼k deÄŸiÅŸikliklere veya gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± **aÅŸÄ±rÄ± duyarlÄ±** olmasÄ±ndan kaynaklanan hata. | **AÅŸÄ±rÄ± Uyum (Overfitting)** | DerinliÄŸi sÄ±nÄ±rsÄ±z bir Karar AÄŸacÄ±nÄ±n eÄŸitim setindeki her bir yolcuyu ezberlemesi (memorizing) ve test verisinde baÅŸarÄ±sÄ±z olmasÄ±. | ğŸ¥µğŸ§  |

---

## 2. ğŸ¯ DeÄŸiÅŸ TokuÅŸ (Tradeoff) ve Hedef

<img width="726" height="259" alt="image" src="https://github.com/user-attachments/assets/ee0a30c9-3dd4-4a53-808c-b083a317ad1d" />

YanlÄ±lÄ±k ve Varyans genellikle birbirinin tersi yÃ¶nde Ã§alÄ±ÅŸÄ±r. Birini azaltmak, genellikle diÄŸerini artÄ±rÄ±r.

| Model Tipi | Ã–zellikler | Hata Dengesi | SonuÃ§ |
| :--- | :--- | :--- | :--- |
| **Basit Model** | Lojistik Regresyon, SÄ±ÄŸ Karar AÄŸaÃ§larÄ± | **YÃ¼ksek YanlÄ±lÄ±k ($\uparrow$ Bias), DÃ¼ÅŸÃ¼k Varyans ($\downarrow$ Variance)** | Veriyi yeterince Ã¶ÄŸrenemez. (Eksik Uyum) |
| **KarmaÅŸÄ±k Model** | Derin Karar AÄŸaÃ§larÄ±, AÅŸÄ±rÄ± Uyumlu Yapay Sinir AÄŸlarÄ± | **DÃ¼ÅŸÃ¼k YanlÄ±lÄ±k ($\downarrow$ Bias), YÃ¼ksek Varyans ($\uparrow$ Variance)** | EÄŸitim verisini ezberler, genelleme yapamaz. (AÅŸÄ±rÄ± Uyum) |
| **Ä°deal Model** | **"TatlÄ± Nokta" (Sweet Spot)** | **DÃ¼ÅŸÃ¼k YanlÄ±lÄ±k, DÃ¼ÅŸÃ¼k Varyans** | Verinin temel Ã¶rÃ¼ntÃ¼lerini yakalar ve yeni verilere iyi genelleme yapar. |

### GÃ¶rsel Sezgi

Modelin KarmaÅŸÄ±klÄ±k DÃ¼zeyine GÃ¶re BaÅŸarÄ± DurumlarÄ±:

| Durum (Genelleme) | EÄŸitim DoÄŸruluÄŸu (Training Accuracy) | Test/DoÄŸrulama DoÄŸruluÄŸu (Test/Validation Accuracy) |
| :--- | :--- | :--- |
| **Eksik Uyum (Underfitting)** | DÃ¼ÅŸÃ¼k | DÃ¼ÅŸÃ¼k |
| **AÅŸÄ±rÄ± Uyum (Overfitting)** | YÃ¼ksek | DÃ¼ÅŸÃ¼k |
| **Ä°deal Uyum (Just Right)** | Yeterince YÃ¼ksek | Yeterince YÃ¼ksek ve birbirine YakÄ±n |

## 3. ğŸ”‘ Ã–zet ve AmaÃ§

 <img width="659" height="390" alt="image" src="https://github.com/user-attachments/assets/60565a18-ee53-4cfe-80f6-fffc48506591" />
 
* **YanlÄ±lÄ±k (Bias):** Modelin **Ã§ok basit** olmasÄ±ndan (Underfitting) kaynaklanan hatadÄ±r.
* **Varyans (Variance):** Modelin **aÅŸÄ±rÄ± duyarlÄ±** olmasÄ±ndan (Overfitting) kaynaklanan hatadÄ±r.

**AmaÃ§**, en dÃ¼ÅŸÃ¼k **eÄŸitim hatasÄ±nÄ±** almak deÄŸil, YanlÄ±lÄ±k ve VaryansÄ±n dengelendiÄŸi, yani en dÃ¼ÅŸÃ¼k **doÄŸrulama/test hatasÄ±nÄ±n** alÄ±ndÄ±ÄŸÄ± **tatlÄ± noktayÄ±** bulmaktÄ±r. Modelin iyi genelleme yapmasÄ± (generalization) budur.



# ğŸ“ˆ Model KarmaÅŸÄ±klÄ±ÄŸÄ± ve Hata Ä°liÅŸkisi (Bias-Variance Tradeoff)

<img width="642" height="346" alt="image" src="https://github.com/user-attachments/assets/516c2ce7-b77b-47dc-9a75-85587e0f931d" />

Model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n (Model Complexity) eÄŸitim (training) ve doÄŸrulama/test (validation/test) hatalarÄ± Ã¼zerindeki etkisini incelemek, makine Ã¶ÄŸreniminde **genelleme (generalization)** yeteneÄŸini anlamak iÃ§in hayati Ã¶nem taÅŸÄ±r.

---

## ğŸ“‰ Hata EÄŸrileri ve AnlamlarÄ±

| EÄŸri | Kavram (Ä°ngilizce Terim) | YÃ¶nelim | AÃ§Ä±klama ||
| :--- | :--- | :--- | :--- | :--- |
| ğŸŸ¦ **Mavi Ã‡izgi** | EÄŸitim HatasÄ± (Training Error) | **Daima DÃ¼ÅŸer** | Model karmaÅŸÄ±klaÅŸtÄ±kÃ§a, eÄŸitim verisini **ezberleme** yeteneÄŸi artar. Bu nedenle, eÄŸitim hatasÄ± sÃ¼rekli olarak azalÄ±r, hatta sÄ±fÄ±ra yaklaÅŸabilir. | ğŸ“šğŸ“‰ |
| ğŸŸ© **YeÅŸil Ã‡izgi** | DoÄŸrulama/Test HatasÄ± (Validation/Test Error) | **Ã–nce DÃ¼ÅŸer, Sonra YÃ¼kselir** | Model, baÅŸta daha iyi Ã¶ÄŸrendiÄŸi iÃ§in hata dÃ¼ÅŸer. Ancak model **Ã§ok karmaÅŸÄ±klaÅŸtÄ±ÄŸÄ±nda**, genelleme yeteneÄŸini kaybeder ve **ezberlediÄŸi** veriden farklÄ± verilerde hata oranÄ± tekrar **yÃ¼kselir** (AÅŸÄ±rÄ± Uyum). | â¬†ï¸â¬‡ï¸ |

---

## ğŸ¯ BÃ¶lgeler ve Model DurumlarÄ±

Model karmaÅŸÄ±klÄ±ÄŸÄ±na gÃ¶re hatalarÄ±n kesiÅŸimi ve ayrÄ±ÅŸmasÄ±, modelin Ã¼Ã§ temel durumunu tanÄ±mlar:

| BÃ¶lge | Durum (Ä°ngilizce Terim) | KarmaÅŸÄ±klÄ±k DÃ¼zeyi | Hata Durumu | Ã–rnek ve SonuÃ§ ||
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Sol** | YÃ¼ksek YanlÄ±lÄ±k (High Bias) veya **Eksik Uyum (Underfitting)** | **Ã‡ok Basit** | Hem EÄŸitim HatasÄ± hem de DoÄŸrulama HatasÄ± **YÃ¼ksek**dir. | Model, verideki temel Ã¶rÃ¼ntÃ¼leri bile yakalayamaz. (*Ã–rn: Titanic verisini tek bir dÃ¼z Ã§izgiyle tahmin etmeye Ã§alÄ±ÅŸmak.*) | ğŸ‘¶âŒ |
| **Orta** | **Optimal BÃ¶lge (Optimal Zone)** veya **Ä°yi Uyum (Good Fit)** | **Tam AyarÄ±nda** | EÄŸitim HatasÄ± **DÃ¼ÅŸÃ¼k** ve DoÄŸrulama HatasÄ± da **DÃ¼ÅŸÃ¼ktÃ¼r**. | Model, veriyi yeterince Ã¶ÄŸrenmiÅŸ ve yeni verilere iyi genelleme yapabiliyordur. **Modellerimizi bu bÃ¶lgede isteriz.** | ğŸ†âœ¨ |
| **SaÄŸ** | YÃ¼ksek Varyans (High Variance) veya **AÅŸÄ±rÄ± Uyum (Overfitting)** | **Ã‡ok KarmaÅŸÄ±k** | EÄŸitim HatasÄ± **Ã‡ok DÃ¼ÅŸÃ¼k** iken, DoÄŸrulama HatasÄ± **YÃ¼ksek**tir. | Model, eÄŸitim verisindeki gÃ¼rÃ¼ltÃ¼yÃ¼ ve tesadÃ¼fi Ã¶rÃ¼ntÃ¼leri ezberlemiÅŸtir. (*Ã–rn: Her yolcunun Ã¶zelliÄŸini ezberleyen derin bir karar aÄŸacÄ±.*) | ğŸ¥µğŸ§  |

---

## ğŸ›‘ Neden Ã–nemlidir?

Model oluÅŸtururken amacÄ±mÄ±z, **genelleme bÃ¶lgesi** (generalization zone) adÄ± verilen orta bÃ¶lgeyi bulmaktÄ±r.

* **Eksik Uyumdan KaÃ§Ä±nmak:** Modelin Ã§ok basit olmasÄ±ndan ve dÃ¼ÅŸÃ¼k performanstan (poor performance) kaÃ§Ä±nmalÄ±yÄ±z.
* **AÅŸÄ±rÄ± Uyumdan KaÃ§Ä±nmak:** Modelin Ã§ok karmaÅŸÄ±k olmasÄ±ndan ve yeni verilerde kÃ¶tÃ¼ genelleme yapmasÄ±ndan (poor generalization) kaÃ§Ä±nmalÄ±yÄ±z.

---


# ğŸŒ³ Karar AÄŸacÄ± (Decision Tree) SÄ±nÄ±flandÄ±rma AlgoritmasÄ±

<img width="681" height="434" alt="image" src="https://github.com/user-attachments/assets/deb619f5-86df-4980-8bb6-55dd573cb0f0" />

[scikitlearn](https://scikit-learn.org/stable/modules/tree.html)

Karar AÄŸaÃ§larÄ±, en basit ve en sezgisel makine Ã¶ÄŸrenimi modellerinden biridir. Bir dizi evet/hayÄ±r sorusunu yanÄ±tlayarak nihai bir karara ulaÅŸma sÃ¼recini taklit eder.

---

## 1. âš™ï¸ Ã‡alÄ±ÅŸma Prensibi

| Kavram | AÃ§Ä±klama | Ã–rnek ||
| :--- | :--- | :--- | :--- |
| **Prensip** | Model, girdi Ã¶zelliklerine (input features) dayalÄ± "sorular" sorarak veriyi giderek daha kÃ¼Ã§Ã¼k gruplara ayÄ±rÄ±r (bÃ¶ler). | Hayvan sÄ±nÄ±flandÄ±rmasÄ±nda: "TÃ¼yleri var mÄ±?" $\to$ Evet ise kuÅŸ yolu. $\to$ "YÃ¼zÃ¼yor mu?" $\to$ Evet ise Ã–rdek. | â“â¬‡ï¸ |
| **YapÄ±** | Her soru bir **dalÄ± (branch)** temsil eder ve nihai karar, aÄŸacÄ±n ucundaki **yaprakta (leaf)** alÄ±nÄ±r. | Model, her bir bÃ¶lmede sÄ±nÄ±f saflÄ±ÄŸÄ±nÄ± (purity) artÄ±rmayÄ± (yani karÄ±ÅŸÄ±klÄ±ÄŸÄ± azaltmayÄ±) hedefler. | ğŸŒ¿ğŸ·ï¸ |
| **KullanÄ±m** | Hem sayÄ±sal (numeric) hem de kategorik (categorical) veri tipleriyle Ã§alÄ±ÅŸabilir. | Cinsiyet (Kategorik) $\to$ YaÅŸ (SayÄ±sal) $\to$ BitiÅŸ. | ğŸ”¢ğŸ”  |

---

## 2. â•â– Avantajlar ve Dezavantajlar

| Kategori | Ã–zellik (Ä°ngilizce Terim) | AÃ§Ä±klama ||
| :--- | :--- | :--- | :--- |
| **Avantaj** | Kolay Yorumlanabilirlik (Easy to Interpret) | Kararlar, basit evet/hayÄ±r kurallarÄ± dizisi olarak aÃ§Ä±kÃ§a gÃ¶rÃ¼lebilir ve teknik olmayan kiÅŸilere anlatÄ±labilir. | ğŸ—£ï¸ğŸ‘ |
| **Avantaj** | DoÄŸrusal Olmayan Ä°liÅŸkiler (Non-linear Relationships) | Verideki doÄŸrusal olmayan (non-linear) ve karmaÅŸÄ±k iliÅŸkileri kolayca yakalayabilir. | ã€°ï¸ğŸ’¡ |
| **Dezavantaj** | AÅŸÄ±rÄ± Uyuma EÄŸilim (Prone to Overfitting) | Model **Ã§ok karmaÅŸÄ±klaÅŸtÄ±ÄŸÄ±nda**, eÄŸitim verisindeki gÃ¼rÃ¼ltÃ¼yÃ¼ (noise) veya alakasÄ±z detaylarÄ± ezberler; bu da yeni verilerde **dÃ¼ÅŸÃ¼k performansa** yol aÃ§ar. | ğŸ¥µğŸ“‰ |
| **Dezavantaj** | KararsÄ±zlÄ±k (Instability) | EÄŸitim verisindeki kÃ¼Ã§Ã¼k deÄŸiÅŸiklikler bile, aÄŸacÄ±n tÃ¼m yapÄ±sÄ±nÄ± bÃ¼yÃ¼k Ã¶lÃ§Ã¼de deÄŸiÅŸtirebilir. | ğŸ¤ğŸ“‰ |
| **Dezavantaj** | Eksik Uyum (Underfitting) | AÄŸaÃ§ Ã§ok basit bÄ±rakÄ±lÄ±rsa (Ã§ok az bÃ¶lme yapÄ±lÄ±rsa), verideki gerÃ§ek Ã¶rÃ¼ntÃ¼leri yakalayamaz. | ğŸ‘¶âŒ |

---

## 3. ğŸ›‘ AÅŸÄ±rÄ± Uyumdan Korunma YollarÄ±

Karar AÄŸaÃ§larÄ±nÄ±n en bÃ¼yÃ¼k zayÄ±flÄ±ÄŸÄ± olan aÅŸÄ±rÄ± uyumu (overfitting) Ã¶nlemek iÃ§in kullanÄ±lan baÅŸlÄ±ca teknikler:

| Teknik | TanÄ±m (Ä°ngilizce Terim) | Uygulama YÃ¶ntemi | SonuÃ§ ||
| :--- | :--- | :--- | :--- | :--- |
| **Ã–n Budama (Pre-pruning)** | AÄŸacÄ±n bÃ¼yÃ¼mesini **erken aÅŸamada** durdurmak. | AÄŸacÄ±n maksimum derinliÄŸine (`max_depth`) veya bir bÃ¶lme iÃ§in gereken minimum Ã¶rnek sayÄ±sÄ±na (`min_samples_split`) limit koymak. | AÄŸacÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± sÄ±nÄ±rlar. | âœ‚ï¸ğŸŒ³ |
| **Geri Budama (Post-pruning)** | AÄŸaÃ§ tamamen bÃ¼yÃ¼tÃ¼ldÃ¼kten sonra, fazla gÃ¼rÃ¼ltÃ¼yÃ¼ yakalayan dallarÄ± **kesip atmak**. | DoÄŸrulama (validation) verisindeki performansÄ± dÃ¼ÅŸÃ¼rmeyen dallarÄ± kaldÄ±rmak. | KarmaÅŸÄ±klÄ±ÄŸÄ± azaltÄ±r ve genellemeyi artÄ±rÄ±r. | ğŸ”ªğŸƒ |
| **Topluluk YÃ¶ntemleri (Ensemble Methods)** | Tek bir aÄŸaÃ§ yerine birÃ§ok aÄŸacÄ± kullanmak. | **Rastgele Ormanlar (Random Forests)** gibi yÃ¶ntemler, birÃ§ok aÄŸacÄ±n tahminini alarak varyansÄ± azaltÄ±r ve Ã§ok daha saÄŸlam sonuÃ§lar verir. | Daha yÃ¼ksek doÄŸruluk ve saÄŸlamlÄ±k saÄŸlar. | ğŸŒ²ğŸŒ²ğŸŒ² |

 <img width="650" height="348" alt="image" src="https://github.com/user-attachments/assets/208e8d1b-a061-45f0-b843-e258b9c3b621" />

 # ğŸŒ³ Karar AÄŸaÃ§larÄ±: Ã–zellik SeÃ§imi ve Ã–nemi (Feature Selection & Importance)

Karar AÄŸaÃ§larÄ± (Decision Trees) eÄŸitilirken, modelin her adÄ±mda hangi Ã¶zelliÄŸe gÃ¶re bÃ¶lme yapacaÄŸÄ±na karar vermesi gerekir. Algoritma bu kararÄ±, **sÄ±nÄ±flar arasÄ±nda en iyi ayrÄ±mÄ± (best separation)** saÄŸlayan Ã¶zelliÄŸi hesaplayarak verir.

---

## 1. âš™ï¸ BÃ¶lme MekanizmasÄ± ve AmacÄ±

| AÅŸama | SÃ¼reÃ§ (Ä°ÅŸleyiÅŸ MantÄ±ÄŸÄ±) | AmaÃ§ | Ã–rnek (Titanic) ||
| :--- | :--- | :--- | :--- | :--- |
| **AÅŸama 1: AdaylarÄ± DeÄŸerlendirme** | AÄŸaÃ§, mevcut veri setinde tÃ¼m Ã¶zellikleri ve olasÄ± tÃ¼m bÃ¶lme noktalarÄ±nÄ± (split points) inceler. | Veriyi, mÃ¼mkÃ¼n olduÄŸunca **saf (purer)** gruplara ayÄ±rmak (Bir grupta Ã§oÄŸunlukla "hayatta kalanlar," diÄŸerinde Ã§oÄŸunlukla "hayatta kalmayanlar" olmasÄ±). | 'Cinsiyet' Ã¶zelliÄŸine gÃ¶re bÃ¶lmek, 'Bilet NumarasÄ±'na gÃ¶re bÃ¶lmekten Ã§ok daha saf gruplar oluÅŸturur. | ğŸ§ğŸ” |
| **AÅŸama 2: BÃ¶lmeyi Ã–lÃ§me** | Her bir potansiyel bÃ¶lmenin, sÄ±nÄ±flar arasÄ±ndaki karÄ±ÅŸÄ±klÄ±ÄŸÄ± ne kadar azalttÄ±ÄŸÄ± Ã¶lÃ§Ã¼lÃ¼r. | En yÃ¼ksek saflÄ±ÄŸÄ± (veya en yÃ¼ksek bilgi kazancÄ±nÄ±) saÄŸlayan bÃ¶lmeyi seÃ§mek. | BÃ¼yÃ¼k ihtimalle ilk bÃ¶lme iÃ§in **Cinsiyet** seÃ§ilecektir, Ã§Ã¼nkÃ¼ hayatta kalma oranlarÄ±nÄ± en keskin ayÄ±ran Ã¶zelliktir. | ğŸ“ğŸ¯ |
| **AÅŸama 3: Tekrarlama** | AÄŸaÃ§ tamamen bÃ¼yÃ¼yene kadar veya Ã¶nceden belirlenmiÅŸ bir durdurma koÅŸuluna (max\_depth gibi) ulaÅŸana kadar bu sÃ¼reÃ§ tekrarlanÄ±r. | | | ğŸ”„ğŸŒ± |

---

## 2. ğŸ”¢ "En Ä°yi" BÃ¶lme Ã–lÃ§Ã¼tleri (Criteria)

Karar AÄŸacÄ± algoritmalarÄ±, bÃ¶lmelerin kalitesini Ã¶lÃ§mek iÃ§in genellikle iki ana matematiksel kriter kullanÄ±r:

| Kriter (Ä°ngilizce Terim) | Temel Kavram | AÃ§Ä±klama | KullanÄ±m | Emoji |
| :--- | :--- | :--- | :--- | :--- |
| **Gini SaflÄ±k Ã–lÃ§Ã¼tÃ¼ (Gini Impurity)** | KarÄ±ÅŸÄ±klÄ±k/Hata OlasÄ±lÄ±ÄŸÄ± | Gruptan rastgele seÃ§ilen bir Ã¶rneÄŸin, gruptaki daÄŸÄ±lÄ±ma gÃ¶re etiketlendiÄŸinde **yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lma olasÄ±lÄ±ÄŸÄ±nÄ±** Ã¶lÃ§er. | **`criterion="gini"`** (scikit-learn varsayÄ±lanÄ±) | ğŸ²ğŸ“‰ |
| **Entropi / Bilgi KazancÄ± (Entropy / Information Gain)** | Belirsizlik (Uncertainty) | **Entropi**, bir gruptaki belirsizliÄŸi Ã¶lÃ§er. AÄŸaÃ§, **en yÃ¼ksek bilgi kazancÄ±nÄ±** (belirsizlikteki en bÃ¼yÃ¼k azalmayÄ±) saÄŸlayan bÃ¶lmeyi seÃ§er. | **`criterion="entropy"`** | ğŸ’¡â¬‡ï¸ |

*Not: Ä°ki kriter de pratikte benzer sonuÃ§lar verir ve amaÃ§larÄ± aynÄ±dÄ±r: SÄ±nÄ±flarÄ± mÃ¼mkÃ¼n olduÄŸunca temiz ayÄ±rmak.*

---

## 3. ğŸ¥‡ Ã–zellik Ã–nemi (Feature Importance)

Karar AÄŸaÃ§larÄ±, tahminlere en Ã§ok katkÄ±da bulunan Ã¶zellikleri sÄ±ralayabilir.

| Kavram | TanÄ±m | Ã–rnek Durum (Titanic) ||
| :--- | :--- | :--- | :--- |
| **Hesaplama YÃ¶ntemi** | Ã–zellik Ã–nemi, o Ã¶zelliÄŸin toplam kriter (Gini veya Entropi) **azalmasÄ±na** ne kadar katkÄ±da bulunduÄŸuna gÃ¶re hesaplanÄ±r. | **Title\_Mr** $(\sim 64\%)$ en Ã¶nemli Ã¶zelliktir, Ã§Ã¼nkÃ¼ bu unvan hayatta kalma ÅŸansÄ±nÄ± en gÃ¼Ã§lÃ¼ ÅŸekilde azaltmÄ±ÅŸtÄ±r. | ğŸ†ğŸ“Š |
| **SÄ±ralÄ± Liste** | Ã–zellikler, modelin karar verme sÃ¼recinde ne kadar etkili olduklarÄ±na gÃ¶re sÄ±ralanÄ±r. | $\text{Pclass}$ $(\sim 14\%)$, $\text{FamilySize}$ $(\sim 9\%)$ ve $\text{Fare}$ $(\sim 7\%)$ da sosyal sÄ±nÄ±f ve maliyet etkisini yansÄ±tÄ±r. | ğŸ¥‡ğŸ¥ˆ |
| **Gizlenme Etkisi** | Bir Ã¶zelliÄŸin etkisi, daha gÃ¼Ã§lÃ¼ bir korelasyona sahip **baÅŸka bir Ã¶zellik** tarafÄ±ndan zaten yakalanmÄ±ÅŸsa, Ã¶nemi dÃ¼ÅŸÃ¼k Ã§Ä±kabilir. | **Cinsiyet** Ã¶zelliÄŸi 0 Ã¶nem gÃ¶sterebilir, Ã§Ã¼nkÃ¼ etkisi zaten Ã§ok daha gÃ¼Ã§lÃ¼ olan **Unvan (Title: Mr/Mrs/Miss)** Ã¶zelliÄŸi tarafÄ±ndan yakalanmÄ±ÅŸtÄ±r. | ğŸ¤«ğŸ­ |

---

## âš ï¸ Model TÃ¼rlerine GÃ¶re Ã–nemi KarÅŸÄ±laÅŸtÄ±rma

FarklÄ± model tÃ¼rleri "Ã¶nemi" farklÄ± ÅŸekilde Ã¶lÃ§tÃ¼ÄŸÃ¼ iÃ§in, bu deÄŸerler **modeller arasÄ±nda doÄŸrudan karÅŸÄ±laÅŸtÄ±rÄ±lamaz**.

| Model | Ã–nemi Ã–lÃ§me YÃ¶ntemi | SonuÃ§ |
| :--- | :--- | :--- |
| **Lojistik Regresyon** | **KatsayÄ±larÄ±n (Coefficients) BÃ¼yÃ¼klÃ¼ÄŸÃ¼** (Ã¶lÃ§eklendirmeden sonra). | BÃ¼yÃ¼k pozitif katsayÄ±, hayatta kalma olasÄ±lÄ±ÄŸÄ±nÄ± artÄ±rÄ±r. **Cinsiyet** burada Ã§ok Ã¶nemli gÃ¶rÃ¼nebilir. |
| **Karar AÄŸaÃ§larÄ± (Decision Trees)** | **SaflÄ±ktaki Azalma** (Impurity Reduction). | Ã–zelliÄŸin, veriyi ne kadar saf gruplara ayÄ±rdÄ±ÄŸÄ±na bakar. **Unvan** gibi bir Ã¶zellik, **Cinsiyet**in etkisini kapsadÄ±ÄŸÄ± iÃ§in baskÄ±n Ã§Ä±kabilir. |

---

## ğŸ§  Ana MantÄ±k ve Ä°ÅŸ AkÄ±ÅŸÄ± Ã–zeti

1.  **Hedef Belirleme:** Karar AÄŸacÄ±, her adÄ±mda sÄ±nÄ±flar arasÄ±ndaki karÄ±ÅŸÄ±klÄ±ÄŸÄ± (Gini/Entropi) **en Ã§ok** azaltacak bÃ¶lmeyi bulmayÄ± hedefler.
2.  **Ã–lÃ§Ã¼t KullanÄ±mÄ±:** BÃ¶lmenin kalitesini Ã¶lÃ§mek iÃ§in Gini SaflÄ±ÄŸÄ± veya Entropi kullanÄ±lÄ±r.
3.  **Tekrarlanan BÃ¶lme:** AÄŸaÃ§, en iyi bÃ¶lmeyi seÃ§er ve bu sÃ¼reci aÄŸacÄ±n dallarÄ±nda tekrarlar (Ã¶zyineleme).
4.  **SonuÃ§ Ã‡Ä±karma:** EÄŸitim bittikten sonra, aÄŸaÃ§ hangi Ã¶zelliklerin en Ã§ok "karÄ±ÅŸÄ±klÄ±k azalmasÄ±na" neden olduÄŸunu rapor ederek **Ã¶zellik Ã¶nemini** belirler.

Bu sÃ¼reÃ§, modelin hem tahmin yapmasÄ±nÄ± hem de bu tahminleri hangi Ã¶zelliklere dayandÄ±rdÄ±ÄŸÄ±nÄ± aÃ§Ä±klamasÄ±na olanak tanÄ±r.


---

# ğŸŒ² Rastgele Ormanlar (Random Forests): Topluluk GÃ¼cÃ¼

<img width="504" height="336" alt="image" src="https://github.com/user-attachments/assets/5874273f-af65-4266-9972-dba04cff2cde" />


Rastgele Orman (Random Forest), aÅŸÄ±rÄ± uyuma (overfitting) eÄŸilimli tek bir Karar AÄŸacÄ±nÄ±n zayÄ±flÄ±klarÄ±nÄ± gidermek iÃ§in tasarlanmÄ±ÅŸ bir **topluluk (ensemble) modelidir**.

---

## 1. ğŸŒ³ Rastgele Orman Nedir ve NasÄ±l Ã‡alÄ±ÅŸÄ±r?


| Kavram (Ä°ngilizce Terim) | AÃ§Ä±klama | Prensip ||
| :--- | :--- | :--- | :--- |
| **Model Tipi** | Bir **Topluluk Modeli (Ensemble Model)**'dir. Tek bir model yerine, yÃ¼zlerce modelin tahminlerini birleÅŸtirir. | Bilgi sahibi 100 farklÄ± doktora danÄ±ÅŸarak tanÄ± koymaya benzetilebilir; grup kararÄ± genellikle tek bir uzmandan daha gÃ¼venilirdir. | ğŸ‘¥ğŸ©º |
| **AÄŸaÃ§larÄ±n EÄŸitimi** | YÃ¼zlerce Karar AÄŸacÄ± rastgele ve baÄŸÄ±msÄ±z olarak eÄŸitilir. | Her bir aÄŸaÃ§, verinin **rastgele bir alt kÃ¼mesini** (random subset of data) ve Ã¶zelliklerin **rastgele bir alt kÃ¼mesini** (random subset of features) gÃ¶rÃ¼r. | ğŸ²ğŸŒ± |
| **Nihai Tahmin** | Her aÄŸaÃ§ kendi tahminini yapar. | **SÄ±nÄ±flandÄ±rma (Classification)** iÃ§in **Ã§oÄŸunluk oyu (majority vote)**, Regresyon iÃ§in ortalama alÄ±nÄ±r. | ğŸ—³ï¸âœ… |

---

## 2. â•â– Tek Bir AÄŸaca GÃ¶re AvantajlarÄ±

Rastgele Ormanlar, birden fazla aÄŸacÄ± birleÅŸtirerek varyansÄ± (aÅŸÄ±rÄ± duyarlÄ±lÄ±ÄŸÄ±) azaltÄ±r, bÃ¶ylece tek bir aÄŸacÄ±n aksine daha iyi genelleme yapar.

| Avantaj (Ä°ngilizce Terim) | AÃ§Ä±klama | Etki ||
| :--- | :--- | :--- | :--- |
| **Daha YÃ¼ksek DoÄŸruluk (More Accurate)** | Birden fazla aÄŸacÄ±n tahminini birleÅŸtirdiÄŸi iÃ§in hatalÄ± tahmin yapma riski azalÄ±r ve aÅŸÄ±rÄ± uyum (overfitting) dÃ¼ÅŸer. | Daha iyi genelleme performansÄ± saÄŸlar. | ğŸ¯â¬†ï¸ |
| **Daha SaÄŸlam (More Stable)** | Tek bir aÄŸaÃ§, eÄŸitim verisindeki kÃ¼Ã§Ã¼k deÄŸiÅŸikliklere Ã§ok hassastÄ±r. Orman ise Ã§ok daha **dayanÄ±klÄ± (robust)** ve kararlÄ±dÄ±r. | Veri gÃ¼rÃ¼ltÃ¼sÃ¼ne karÅŸÄ± daha az hassastÄ±r. | ğŸ›¡ï¸ğŸ’ª |
| **KarmaÅŸÄ±k Veriyle Uyum** | Ã‡ok sayÄ±da Ã¶zelliÄŸi (features) olan veri setlerinde bile iyi sonuÃ§ verir. | Verimli bir ÅŸekilde Ã§alÄ±ÅŸÄ±r. | ğŸ§©âœ¨ |
| **Kutudan Ã‡Ä±ktÄ±ÄŸÄ± Gibi Ä°yi Ã‡alÄ±ÅŸma (Works Well Out-of-the-Box)** | Ã‡oÄŸu zaman, hiperparametre ayarÄ± yapmaya gerek kalmadan yÃ¼ksek performans gÃ¶steren ilk denenecek modellerdendir. | HÄ±zlÄ± baÅŸlangÄ±Ã§ ve temel performans iÃ§in ideal. | ğŸ“¦ğŸ‘Œ |
| **Dezavantaj** | **Daha Az Yorumlanabilirlik (Less Interpretability)** | Tek bir aÄŸacÄ±n basit evet/hayÄ±r kurallarÄ±nÄ±n aksine, yÃ¼zlerce aÄŸacÄ±n oyunu anlamak zordur. | â“ğŸ—£ï¸ |

---

## 3. ğŸ¥‡ Ã–zellik Ã–nemi (Feature Importance in Random Forest)

Rastgele Ormanlar, karar verme sÃ¼recine en Ã§ok katkÄ±da bulunan Ã¶zellikleri raporlar.

| Kavram | AÃ§Ä±klama | Rastgele Orman'Ä±n Etkisi ||
| :--- | :--- | :--- | :--- |
| **Hesaplama** | Model, her bir Ã¶zelliÄŸin tÃ¼m aÄŸaÃ§larda yaptÄ±ÄŸÄ± ortalama karÄ±ÅŸÄ±klÄ±k azalmasÄ±na (gini impurity reduction) gÃ¶re Ã¶nemini hesaplar. | TÃ¼m aÄŸaÃ§lar farklÄ± Ã¶zellik kombinasyonlarÄ± kullandÄ±ÄŸÄ± iÃ§in, Ã¶nem skorlarÄ± genellikle daha **dengeli** daÄŸÄ±lÄ±r. | âš–ï¸ğŸ“Š |
| **Dengeli DaÄŸÄ±lÄ±m** | Ã–nem, tek bir baskÄ±n Ã¶zelliÄŸe gÃ¼Ã§lÃ¼ bir ÅŸekilde sapmaz. BirÃ§ok kÃ¼Ã§Ã¼k Ã¶zellik bile bir miktar aÄŸÄ±rlÄ±k alÄ±r. | **HiÃ§bir Ã¶zellik 0 Ã¶nem taÅŸÄ±maz**, Ã§Ã¼nkÃ¼ ormandaki birden fazla aÄŸaÃ§ bu Ã¶zellikleri farklÄ± bÃ¶lmelerde kullanmÄ±ÅŸtÄ±r. | ğŸŒğŸ¤ |
| **KarÅŸÄ±laÅŸtÄ±rma (DT vs. RF)** | **Tekil Karar AÄŸacÄ± (DT)**, genellikle tek bir gÃ¼Ã§lÃ¼ Ã¶zelliÄŸe (Ã–rn: Title\_Mr) aÅŸÄ±rÄ± derecede odaklanÄ±rken; **Rastgele Orman (RF)**, kararlarÄ± birden fazla Ã¶zellik arasÄ±nda yayarak daha geniÅŸ bir resim yakalar. | Daha gerÃ§ekÃ§i ve kapsamlÄ± Ã¶zellik Ã¶nemi sunar. | ğŸ†šğŸ”„ |

---

## ğŸ”‘ Ana Ã‡Ä±karÄ±mlar

1.  **Rastgele Ormanlar =** Karar AÄŸaÃ§larÄ±ndan oluÅŸan bir topluluktur (ensemble).
2.  Tek bir aÄŸaca kÄ±yasla **doÄŸruluÄŸu artÄ±rÄ±r ve aÅŸÄ±rÄ± uyumu azaltÄ±r**.
3.  Tahminler **Ã§oÄŸunluk oyu** ile yapÄ±lÄ±r.
4.  Ã‡oÄŸu ML problemi iÃ§in **ilk denenecek (go-to)** modeldir.

---
# ğŸ«‚ K-En YakÄ±n KomÅŸular (k-Nearest Neighbors - kNN)

**K-En YakÄ±n KomÅŸular (kNN)**, karmaÅŸÄ±k kurallar Ã¶ÄŸrenmek yerine, bir veri noktasÄ±nÄ±n "komÅŸularÄ±na" bakarak tahmin yapan en basit ve sezgisel makine Ã¶ÄŸrenimi algoritmalarÄ±ndan biridir.

<img width="676" height="348" alt="image" src="https://github.com/user-attachments/assets/e9c0909f-2cb9-452c-96eb-543679000abf" />

# ğŸ«‚ K-En YakÄ±n KomÅŸular (kNN): Temel AmaÃ§ ve Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±

K-En YakÄ±n KomÅŸular algoritmasÄ±nÄ±n (kNN) tahmine dayalÄ± temel felsefesi ve ikili (binary) sÄ±nÄ±flandÄ±rma ile regresyon (regression) problemlerinde nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ± aÅŸaÄŸÄ±da Ã¶zetlenmiÅŸtir.

---

## 1. ğŸ§  Temel AmaÃ§ ve Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±

| Kavram (Ä°ngilizce Terim) | AmaÃ§/Temel Fikir | Ä°ÅŸleyiÅŸ Prensibi ||
| :--- | :--- | :--- | :--- |
| **Temel Fikir (Core Idea)** | Yeni bir veri noktasÄ±nÄ±n etiketini, eÄŸitim setindeki **en yakÄ±n $K$ komÅŸusunun** etiketlerine dayanarak tahmin etmek. | Bir karar vermek iÃ§in en gÃ¼vendiÄŸiniz, yani size en "yakÄ±n" olan arkadaÅŸ grubunuza danÄ±ÅŸmaya benzer. | ğŸ’¡ğŸ¤ |
| **SÄ±nÄ±flandÄ±rma (Classification)** | $K$ komÅŸu iÃ§inde en Ã§ok hangi sÄ±nÄ±fÄ±n bulunduÄŸunu belirlemek (**Ã§oÄŸunluk oyu**). | Ä°kili sÄ±nÄ±flandÄ±rÄ±cÄ±larda (2 sÄ±nÄ±f olduÄŸunda), beraberlikleri Ã¶nlemek iÃ§in **$K$ deÄŸerinin tek sayÄ± (odd)** olmasÄ± gerekir. | ğŸ—³ï¸âœ… |
| **Regresyon (Regression)** | $K$ komÅŸunun deÄŸerlerinin **ortalamasÄ±nÄ±** almak. | | ğŸ“‰ğŸ“ˆ |
| **Ã–rnek Senaryo** | Titanic'te yeni bir yolcunun hayatta kalma durumunu tahmin etmek. | kNN, en benzer 5 yolcuyu bulur. EÄŸer 5 kiÅŸiden 3'Ã¼ hayatta kaldÄ±ysa, tahmin **Hayatta KaldÄ±** olur. | ğŸš¢âœ”ï¸ |

# âš™ï¸ K-En YakÄ±n KomÅŸular (kNN): AdÄ±m AdÄ±m Ä°ÅŸleyiÅŸ SÃ¼reci

K-En YakÄ±n KomÅŸular algoritmasÄ±, bir tahmin yapmak iÃ§in Ã¶zel bir eÄŸitim aÅŸamasÄ±ndan geÃ§mez; tÃ¼m hesaplama tahmin anÄ±nda (lazy learning) gerÃ§ekleÅŸir.

---

## 2. âœ¨ AdÄ±m AdÄ±m Ä°ÅŸleyiÅŸ SÃ¼reci

| AdÄ±m | Ä°ÅŸlem | Ã–nemli Notlar ||
| :--- | :--- | :--- | :--- |
| **1. $K$ DeÄŸerini SeÃ§me** | Tahmin iÃ§in bakÄ±lacak komÅŸu sayÄ±sÄ±nÄ± belirleyin. | **Tek sayÄ± (odd) $K$** deÄŸeri, ikili sÄ±nÄ±flandÄ±rmada beraberlikleri Ã¶nlemek iÃ§in Ã¶nerilir. | ğŸ”¢ğŸ¯ |
| **2. Mesafe Hesaplama** | Yeni nokta ile eÄŸitim setindeki **tÃ¼m noktalar** arasÄ±ndaki mesafeyi Ã¶lÃ§Ã¼n. | **Ã–klid (Euclidean)**, Manhattan veya Minkowski gibi Ã§eÅŸitli mesafe metrikleri (distance metrics) kullanÄ±lÄ±r. | ğŸ“ğŸ—ºï¸ |
| **3. KomÅŸularÄ± Bulma** | Hesaplanan mesafelere gÃ¶re en yakÄ±n $K$ noktayÄ± seÃ§in. | Bu, bÃ¼yÃ¼k veri setlerinde kNN'i yavaÅŸlatan temel adÄ±mdÄ±r. | ğŸ”ğŸ«‚ |
| **4. Tahmin Yapma** | $K$ komÅŸunun **Ã§oÄŸunluk oyuna** (sÄ±nÄ±flandÄ±rma) veya **ortalama deÄŸerine** (regresyon) gÃ¶re tahmini sonuÃ§landÄ±rÄ±n. | | ğŸ—³ï¸âœ… |

<img width="685" height="297" alt="image" src="https://github.com/user-attachments/assets/a7c2c509-5065-4e9a-9d32-fbfd572481c1" />


# âš–ï¸ K-En YakÄ±n KomÅŸular (kNN) AlgoritmasÄ±nÄ±n Kritik UnsurlarÄ±

kNN'in performansÄ±nÄ± ve genelleme yeteneÄŸini belirleyen temel kararlar ve teknikler, algoritmanÄ±n basitliÄŸine raÄŸmen bÃ¼yÃ¼k Ã¶nem taÅŸÄ±r.

---

## 3. ğŸ›¡ï¸ kNN'in Kritik UnsurlarÄ±

| Unsur (Ä°ngilizce Terim) | Etki | YÃ¶ntem | Ã–nemi ||
| :--- | :--- | :--- | :--- | :--- |
| **$K$ SeÃ§imi (Choosing K)** | Modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± ve YanlÄ±lÄ±k-Varyans dengesini belirler. | **KÃ¼Ã§Ã¼k $K$**: YÃ¼ksek Varyans (High Variance), gÃ¼rÃ¼ltÃ¼ye duyarlÄ±. **BÃ¼yÃ¼k $K$**: YÃ¼ksek YanlÄ±lÄ±k (High Bias), yerel Ã¶rÃ¼ntÃ¼leri kaÃ§Ä±rabilir. | En iyi $K$ deÄŸerini bulmak iÃ§in **Ã§apraz doÄŸrulama (cross-validation)** kullanÄ±lÄ±r. | ğŸ¯ğŸ”¬ |
| **Ã–zellik Ã–lÃ§eklendirme (Feature Scaling)** | Mesafe hesaplamalarÄ±nÄ± doÄŸrudan etkiler. | **Zorunludur!** Gelir (bÃ¼yÃ¼k aralÄ±k) gibi deÄŸiÅŸkenlerin YaÅŸ (kÃ¼Ã§Ã¼k aralÄ±k) gibi deÄŸiÅŸkenlere baskÄ±n gelmesini engeller. | AnlamlÄ± ve adil mesafe hesaplamalarÄ± iÃ§in hayati Ã¶nem taÅŸÄ±r. | ğŸ“âœ”ï¸ |
| **Mesafe Metrikleri (Distance Metrics)** | Ä°ki nokta arasÄ±ndaki benzerliÄŸin nasÄ±l tanÄ±mlanacaÄŸÄ±nÄ± belirler. | **Ã–klid Mesafesi** (Euclidean Distance - dÃ¼z Ã§izgi) en yaygÄ±n olanÄ±dÄ±r, ancak problem tÃ¼rÃ¼ne gÃ¶re farklÄ± metrikler seÃ§ilebilir (Ã–rn: Manhattan Mesafesi). | | ğŸ›£ï¸ğŸ”— |

<img width="454" height="326" alt="image" src="https://github.com/user-attachments/assets/bdaeffb5-4d14-424b-9638-b84a19786a3d" />

# â•â– K-En YakÄ±n KomÅŸular (kNN): Avantajlar ve SÄ±nÄ±rlamalar

K-En YakÄ±n KomÅŸular algoritmasÄ±, basitliÄŸine raÄŸmen bazÄ± gÃ¼Ã§lÃ¼ avantajlara sahiptir, ancak bÃ¼yÃ¼k veri setlerinde ciddi sÄ±nÄ±rlamalarla karÅŸÄ±laÅŸÄ±r.

---

## 4. ğŸš€ Avantajlar ve SÄ±nÄ±rlamalar

| Kategori | Ã–zellik (Ä°ngilizce Terim) | AÃ§Ä±klama ||
| :--- | :--- | :--- | :--- |
| **Avantaj** | Basitlik (Simplicity) | Ã–ÄŸrenmesi ve anlaÅŸÄ±lmasÄ± Ã§ok kolaydÄ±r. Genellikle ilk denenen temel (baseline) modellerden biridir. | ğŸ‘¶ğŸ‘ |
| **Avantaj** | EÄŸitim FazÄ± Yok (No Training Phase) | Model, kural veya parametre Ã¶ÄŸrenmez; sadece veriyi depolar. TÃ¼m hesaplama tahmin anÄ±nda yapÄ±lÄ±r. | ğŸ’¾ğŸ§  |
| **Dezavantaj** | YavaÅŸlÄ±k (Slowness) | BÃ¼yÃ¼k veri setlerinde tahmin yaparken her seferinde **tÃ¼m eÄŸitim setindeki** tÃ¼m noktalara olan mesafeyi hesaplamak zorunda olduÄŸu iÃ§in yavaÅŸlayabilir. | ğŸ¢â±ï¸ |
| **Dezavantaj** | GÃ¼rÃ¼ltÃ¼ye Hassasiyet (Sensitive to Noise) | AlakasÄ±z veya gÃ¼rÃ¼ltÃ¼lÃ¼ (noisy) Ã¶zelliklere karÅŸÄ± hassastÄ±r, Ã§Ã¼nkÃ¼ tÃ¼m Ã¶zellikler mesafe hesabÄ±nÄ± eÅŸit derecede etkiler. | ğŸ‘‚ğŸ“¢ |

<img width="729" height="212" alt="image" src="https://github.com/user-attachments/assets/e68953d5-9f60-4819-999f-b21adf3d2d34" />

