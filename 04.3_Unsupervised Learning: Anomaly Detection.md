# 🔎 Anomaly Detection: An Unsupervised Learning Perspective


<img width="644" height="346" alt="image" src="https://github.com/user-attachments/assets/084ec529-ed61-48e3-a491-043c2885d544" />


Anomaly Detection is the process of identifying data points that significantly **deviate (sapma)** from the expected standard pattern within a **dataset (veri kümesi)**. These unusual observations are called **anomalies (anormallikler)** or **outliers (aykırı değerler)**.

---

## 1. Types of Anomalies

| Anomaly Type | Description | Example Context |
| :--- | :--- | :--- |
| **Point Anomalies** | Individual data points significantly different from the majority. | A single, extremely large transaction. |
| **Contextual Anomalies** | Anomalous only within a specific **context (bağlam)** (e.g., time, location). | High server load at 3 AM when traffic is typically low. |
| **Collective Anomalies** | A group of data points that are anomalous as a collection, but normal individually. | A sequence of small, coordinated transactions indicating fraud. |

---

## 2. Importance and Distinction

The value in this field lies in finding the exceptions, making it crucial for: **Fraud Detection (Dolandırıcılık Tespiti)**, **Cybersecurity (Siber Güvenlik)**, and **Preventive Maintenance (Önleyici Bakım)**.

### Anomaly Detection vs. Supervised Learning

Anomaly Detection is generally an **Unsupervised Learning (Denetimsiz Öğrenme)** problem because:

* Anomalies are **rare (nadir)** and **unlabeled (etiketsiz)**.
* The algorithm learns the characteristics of **"normal behavior" (normal davranış)** and flags anything that deviates from this learned norm.

---

## 3. Techniques for Anomaly Detection

| Technique | Mechanism | Key Advantage |
| :--- | :--- | :--- |
| **Statistical Methods** | Assume data follows a **distribution (dağılım)**; anomalies are far from the **mean (ortalama)** (e.g., $\pm 3$ **Standard Deviations**). | Simple and fast. |
| **Clustering-Based** | Use K-Means or DBSCAN. Anomalies are points **far from cluster centers** or not belonging to any dense region. | Effective when normal data forms clear groups. |
| **Isolation Forest** | Randomly splits data to isolate points. Anomalies are isolated faster (shorter path). | Robust and scalable **Machine Learning (Makine Öğrenmesi)** approach. |
| **One-Class SVM** | Learns a tight **boundary (sınır)** around the **normal data**. Points outside the boundary are anomalies. | Powerful for complex, non-linear boundaries. |

---

## 4. Key Challenges

* **Imbalanced Data (Dengesiz Veri):** Anomalies are rare compared to normal cases.
* **Evolving Behavior (Gelişen Davranış):** The definition of "normal" can change (**Concept Drift**).
* **False Alarms (Yanlış Alarmlar):** Minimizing **False Positives** (yanlış pozitifler) is critical for system reliability.
* **Interpretability (Yorumlanabilirlik):** Explaining *why* a data point was flagged is necessary for action.

---

# TÜRKCE

---
# 🔎 Anomali Tespiti Açıklaması

**Anomali Tespiti (Anomaly Detection)**, bir **veri kümesindeki (dataset)** beklenen standart düzenden önemli ölçüde sapan veri noktalarını belirlemeye odaklanan, veri biliminde kritik bir görevdir. Bu sıra dışı gözlemler **anomaliler (anomalies)** veya **aykırı değerler (outliers)** olarak bilinir. Anomaliler genellikle sistem arızaları, finansal dolandırıcılık veya tıbbi durumlar gibi nadir fakat oldukça önemli sonuçları olan olayları temsil eder.

---

## Anomali Türleri

Anomaliler, bağlamlarına göre tipik olarak üç ana kategoriye ayrılır:

* **Nokta Anormallikleri (Point Anomalies):** Verinin büyük çoğunluğundan köklü bir şekilde farklı olan tekil veri noktalarıdır. Örneğin, günlük işlemlerin nadiren 500 Doları aştığı bir veri kümesinde, 50.000 Dolarlık tek bir banka işlemi net bir nokta anomalisidir.
* **Bağlamsal Anormallikler (Contextual Anomalies):** Bir veri noktası, yalnızca belirli bir **bağlam (context)** içinde anormal kabul edilir. Örneğin, saatte 1.000 isabet alan bir web sitesi gündüz saatlerinde normal olabilir, ancak gece 3'te meydana gelirse bağlamsal bir anomali haline gelir.
* **Toplu Anormallikler (Collective Anomalies):** Bireysel olarak normal görünebilen ancak bir grup olarak anormal olan ilgili veri noktalarının bir koleksiyonudur. Örneğin, bir hesabın bakiyesini toplu olarak boşaltan küçük, koordineli bir dizi işlem, zaman serisi verilerinde toplu bir anomaliyi temsil eder.

---

## Anomali Tespiti Neden Kritik?

Bu alanın önemi, **değerin çoğunlukla istisnalarda yattığı, çoğunlukta değil (the value often lies in the exceptions, not the majority)** gerçeğinden kaynaklanır. Başlıca uygulama alanları şunlardır:

* **Dolandırıcılık Tespiti (Fraud Detection):** Kredi kartı, sigorta veya bankacılık işlemlerindeki şüpheli paternleri belirleme.
* **Siber Güvenlik (Cybersecurity):** Olağandışı ağ trafiğini, yetkisiz erişim girişimlerini veya kötü amaçlı yazılım etkinliğini tespit etme.
* **Önleyici Bakım (Preventive Maintenance):** Potansiyel bir ekipman arızasına işaret eden sensör verilerindeki (örneğin, endüstriyel IoT cihazlarında veya araçlarda) sapmaları tespit etme.

---

## Denetimli Öğrenmeden Farkı

Anomali Tespiti, ağırlıklı olarak bir **Denetimsiz Öğrenme (Unsupervised Learning)** problemi olarak kabul edilir:

* Standart **Sınıflandırmada (Classification)**, dengeli, **etiketli (labeled)** veriye sahipsiniz (örneğin, binlerce spam e-postası ve binlerce normal e-posta).
* Anomali tespitinde ise anomaliler **nadir (rare)** ve genellikle **etiketsiz (unlabeled)**'dir. Olası her türlü dolandırıcılık veya sistem arızasının etiketli örneklerini elde etmek genellikle imkansız veya çok pahalıdır.

Bu nedenle, algoritma anomali örneklerinden öğrenmez; bunun yerine **"normal davranışın" (normal behavior)** özelliklerini öğrenir ve bu öğrenilen normdan önemli ölçüde **sapan (deviates)** herhangi bir gözlemi işaretler.

# 🛠️ Temel Anomali Tespiti Teknikleri

"Normal" davranışı modellemek ve anomalileri tespit etmek için çeşitli metodolojik yaklaşımlar mevcuttur:

| Teknik Kategori | Açıklama | Temel Varsayım |
| :--- | :--- | :--- |
| **İstatistiksel Yöntemler (Statistical Methods)** | Verinin belirli bir **dağılımı (distribution)** takip ettiğini varsayar, genellikle Gaussian (normal) dağılım. Bir eşiğin (örn., **3 Standart Sapma - 3 Standard Deviations**) dışına düşen noktalar işaretlenir. | Veri, varsayılan olasılık dağılımına uymalıdır. |
| **Kümeleme Tabanlı Metotlar (Clustering-Based Methods)** | Kümeleme algoritmaları (K-Means veya DBSCAN gibi) kullanılır. **Anomaliler, herhangi bir küme merkezinden uzakta** olan veya herhangi bir yoğun bölgeye ait olmayan noktalardır. | Normal verinin doğal olarak kompakt, iyi ayrılmış kümeler oluşturması. |
| **Makine Öğrenmesi Yöntemleri (Machine Learning Methods)** | Normal verinin şeklini öğrenmek için özelleşmiş modeller eğitilir. | Yüksek derecede esnektir, ancak model karmaşıklığına bağlıdır. |
| **Isolation Forest (İzolasyon Ormanı) 🌲** | Gözlemleri **izole etmek** için veriyi rastgele böler. Anomaliler, seyrek oldukları için daha hızlı izole edilir (daha kısa yol uzunluğu). | Anomaliler azdır ve verinin çoğunluğundan farklıdır. |
| **One-Class SVM (Tek Sınıflı Destek Vektör Makinesi) 📈** | **Tüm normal veri noktalarını kapsayan** sıkı bir **sınır (boundary)** öğrenir. Bu sınırın dışına düşen herhangi bir nokta anomali olarak işaretlenir. | Normal verinin, özellik uzayında bitişik bir bölgeyi kaplaması. |


# ⚙️ Anomali Tespiti: Temel Makine Öğrenmesi Algoritmaları

Anomali tespitinde (Anomaly Detection) yaygın olarak kullanılan ve farklı mantıklarla çalışan iki güçlü algoritmayı inceleyelim: **Isolation Forest** ve **Local Outlier Factor (LOF)**.

---

## 🌲 1. Isolation Forest (İzolasyon Ormanı)

Isolation Forest, özellikle anomalileri tespit etmek amacıyla oluşturulmuş **ağaç tabanlı (tree-based)** bir algoritmadır.

### Temel Çalışma Prensibi

Isolation Forest, veri noktalarını **özyinelemeli bölme (recursive partitioning)** yoluyla izole ederek anomalileri yakalar. Bir noktayı izole etmek için ne kadar az bölme (split) gerekirse, o noktanın anomali olma olasılığı o kadar yüksektir.

👉 **Çalışma Adımları:**

1.  Rastgele bir **özellik (feature)** ve rastgele bir **bölme noktası (split point)** seçilir.
2.  Veri, sürekli olarak daha küçük gruplara ayrılır.
3.  **Anomaliler** (diğerlerinden uzakta, nadir noktalar), hızlı bir şekilde izole edilirler; bu da onların daha az bölmeye ihtiyaç duyduğu anlamına gelir.
4.  Algoritma çok sayıda ağaç (forest) inşa eder ve sonuçları ortalamasını alır. **Daha kısa yollara (shorter paths)** sahip noktalar anomali olarak işaretlenir.

> 
> Bir düşünün: Bir ormanın kenarındaki tek bir ağacı bulmak, ormanın ortasındaki kalabalık bir ağaç grubundan rastgele bir ağacı bulmaktan çok daha kolaydır. Anomaliler de verinin "kenarındaki" ağaçlardır.

### ⚙️ Anahtar Parametreler

Bu parametreler, algoritmanın çalışma şeklini doğrudan etkiler:

| Parametre | Açıklama |
| :--- | :--- |
| **n\_estimators** | Ormandaki ağaç sayısı. (Genellikle 100-500 arası seçilir). |
| **max\_samples** | Her ağacı eğitmek için kullanılan veri noktası sayısı (Örnekleme boyutu). |
| **contamination** | Veri setinde beklenen aykırı değerlerin oranı (%0.1 veya %0.05 gibi). Algoritmanın işaretleyeceği anomali sayısını belirler. |
| **max\_features** | Her bölme için dikkate alınan özellik sayısı. |

### ✅ Neden Isolation Forest Kullanılmalı?

* **Hızlı ve Ölçeklenebilir:** Büyük ve yüksek boyutlu verilerle bile iyi çalışır.
* **Dağılım Varsayımı Yok:** Verinin belirli bir istatistiksel dağılımı (örneğin normal dağılım) takip ettiğini varsaymaz.

---

## 📍 2. Local Outlier Factor (LOF)

**LOF (Yerel Aykırı Faktör)**, **yoğunluk tabanlı (density-based)** bir yöntemdir. Bir alanın ne kadar kalabalık olduğuna bakar ve o alana "uymayan" noktaları tespit eder.

### Temel Çalışma Prensibi

LOF, bir noktanın kendi yerel yoğunluğunu (local density), komşularının yerel yoğunlukları ile karşılaştırarak çalışır.

👉 **Çalışma Adımları:**

1.  Her nokta için, en yakın komşularına (nearest neighbors) dayalı olarak **yerel yoğunluğu** hesaplanır.
2.  Noktanın yoğunluğu, komşularının yoğunluklarıyla karşılaştırılır.
3.  Eğer bir nokta, komşularına göre **çok daha az yoğunsa** (yani komşularından daha izole bir bölgedeyse), **LOF değeri yüksek çıkar** ve bu nokta anomali olarak işaretlenir.

> 
> **Örnek:** Veri setinde yoğun bir kümenin kenarında yer alan bir nokta, küresel olarak normal görünebilir (çünkü genel olarak veriye yakındır), ancak hemen yanındaki komşularına kıyasla daha seyrek bir konumdadır. LOF, bu tür **yerel anomalileri** yakalamakta mükemmeldir.

### ✅ Neden LOF Kullanılmalı?

* **Yerel Anomali Tespiti:** Yalnızca belirli bir mahallede (komşulukta) sıra dışı olan **bağlamsal anomalileri (contextual anomalies)** yakalamak için idealdir.
* **Bağlam Yakalama:** Global yöntemlerin gözden kaçırabileceği yerel yoğunluk farklılıklarını yakalar.

---

## ⚖️ Karşılaştırma ve Özet

| Özellik | Isolation Forest 🌲 | Local Outlier Factor (LOF) 📍 |
| :--- | :--- | :--- |
| **Temel Mekanizma** | **İzolasyon (Ağaç Tabanlı)**. Rastgele bölmelerle hızlı izolasyon. | **Yerel Yoğunluk Karşılaştırması**. Noktanın yoğunluğunu komşularıyla kıyaslama. |
| **Anomali Tipi** | **Global Aykırı Değerler** (Veri yığınının uzağındaki noktalar). | **Yerel/Bağlamsal Aykırı Değerler** (Komşularına göre seyrek olan noktalar). |
| **Hız/Ölçeklenebilirlik** | **Çok Hızlı ve Ölçeklenebilir** (Büyük veri setleri için uygundur). | **Daha Yavaş** (Komşu mesafesi hesaplaması gerektirir). |
| **Parametreler** | `n_estimators`, `contamination`, `max_samples`. | **k** (Komşu sayısı, `n_neighbors`), `contamination`. |

### ☝🏽 Ana Çıkarımlar

* **Isolation Forest:** Veri setinin çoğunluğundan uzakta oturan **global aykırı değerleri** hızlı ve verimli bir şekilde bulur.
* **LOF:** **Yerel/bağlamsal anomalileri** (komşularına bağlı olan) bulmakta güçlüdür.

Bu iki yöntem birbirini tamamlar ve farklı senaryolarda kullanışlıdır: Örneğin, siber güvenlikte **Isolation Forest** global siber saldırıları yakalarken, **LOF** bir kullanıcının yerel olarak sıra dışı görünen küçük davranış değişikliklerini işaretleyebilir.

---

