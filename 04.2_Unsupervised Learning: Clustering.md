# Unsupervised Learning: Clustering

# Types of Clustering Algorithms ğŸ§©

There are several fundamental approaches to grouping data in unsupervised learning:

### 1. K-Means Clustering âš™ï¸
* **Principle:** A prototype-based, partitioned clustering technique. It aims to partition $N$ observations into $K$ clusters in which each observation belongs to the cluster with the nearest mean (cluster centroid).
* **Key Feature:** Requires the user to define the number of clusters ($K$) beforehand.

### 2. Hierarchical Clustering ğŸŒ³
* **Principle:** Creates a tree-like hierarchy of clusters, known as a dendrogram. It can be **Agglomerative** (starting with single points and merging) or **Divisive** (starting with one big cluster and splitting).
* **Key Feature:** Does not require the number of clusters to be specified initially; the number of clusters is chosen by cutting the dendrogram at a desired level.

### 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise) ğŸ’¡
* **Principle:** Clusters are defined as areas of higher density than the remainder of the dataset. It can find arbitrarily shaped clusters and is robust to noise (outliers).
* **Key Feature:** Does not require a fixed number of clusters and is excellent at identifying outliers (points that do not belong to any cluster).


----

# TÃœRKCE

# KÃ¼meleme AlgoritmasÄ± TÃ¼rleri ğŸ§©

KÃ¼meleme (Clustering) yapmak iÃ§in kullanÄ±lan birkaÃ§ temel yaklaÅŸÄ±m vardÄ±r:

### ğŸŒŸ K-Ortalamalar KÃ¼meleme (K-Means Clustering)
* **Temel YapÄ±:** Veriyi, Ã¶nceden belirlenen $k$ (kÃ¼me sayÄ±sÄ±) adet merkeze (centroid) gÃ¶re gruplandÄ±rÄ±r. Her veri noktasÄ±, kendisine en yakÄ±n olan merkezin kÃ¼mesine atanÄ±r.
* **KullanÄ±m:** HÄ±zlÄ± ve basit olmasÄ± nedeniyle bÃ¼yÃ¼k veri setlerinde yaygÄ±n olarak kullanÄ±lÄ±r.

### ğŸŒ³ HiyerarÅŸik KÃ¼meleme (Hierarchical Clustering)
* **Temel YapÄ±:** KÃ¼meleme hiyerarÅŸik bir aÄŸaÃ§ yapÄ±sÄ± (dendrogram) oluÅŸturarak yapÄ±lÄ±r. Ä°ki ana yaklaÅŸÄ±mÄ± vardÄ±r: birleÅŸtirici (agglomerative - alttan yukarÄ±) veya bÃ¶lÃ¼cÃ¼ (divisive - Ã¼stten aÅŸaÄŸÄ±).
* **KullanÄ±m:** KÃ¼me sayÄ±sÄ±nÄ±n Ã¶nceden bilinmediÄŸi ve kÃ¼me hiyerarÅŸisinin Ã¶nemli olduÄŸu durumlar iÃ§in idealdir.

### ğŸ“ GÃ¼rÃ¼ltÃ¼lÃ¼ Uygulamalar iÃ§in YoÄŸunluk TabanlÄ± Mekansal KÃ¼meleme (DBSCAN - Density-Based Spatial Clustering of Applications with Noise)
* **Temel YapÄ±:** Veri noktalarÄ±nÄ±, yÃ¼ksek yoÄŸunluklu bÃ¶lgeler oluÅŸturarak gruplandÄ±rÄ±r. DÃ¼ÅŸÃ¼k yoÄŸunluklu bÃ¶lgelerdeki noktalarÄ± "gÃ¼rÃ¼ltÃ¼" veya "aykÄ±rÄ± deÄŸer" (outlier) olarak iÅŸaretler.
* **KullanÄ±m:** KÃ¼me ÅŸekillerinin dÃ¼zensiz olduÄŸu ve gÃ¼rÃ¼ltÃ¼lÃ¼ verilerin bulunduÄŸu durumlar iÃ§in Ã§ok etkilidir.



# KÃ¼meleme Nedir? (Clustering) ğŸ§©

KÃ¼meleme, denetimsiz Ã¶ÄŸrenmedeki en Ã¶nemli tekniklerden biridir.

Temel olarak, benzer veri noktalarÄ±nÄ± gruplara ayÄ±rmakla ilgilidir â€” bu gruplarÄ±n (etiketlerin) ne olduÄŸu size **sÃ¶ylenmeden**.

---

## KÃ¼meleme Nedir?

ğŸ‘‰ Bir kutunun Ã¼zerinde resmi olmayan bir yapboz yÄ±ÄŸÄ±nÄ±na sahip olduÄŸunuzu hayal edin.

KÃ¼meleme, parÃ§alarÄ± otomatik olarak benzer gÃ¶rÃ¼nen gruplara ayÄ±rmaya benzer, bÃ¶ylece onlarÄ± anlamlandÄ±rabilirsiniz.

* HiÃ§bir etiket verilmez â€” algoritma gruplarÄ± **kendi baÅŸÄ±na** keÅŸfeder.
* AynÄ± kÃ¼me iÃ§indeki veri noktalarÄ±, diÄŸer kÃ¼melerdeki noktalara gÃ¶re birbirine **daha fazla benzerdir**.

---

## KÃ¼meleme, SÄ±nÄ±flandÄ±rmadan NasÄ±l FarklÄ±dÄ±r? ğŸ¤”

<img width="761" height="379" alt="image" src="https://github.com/user-attachments/assets/9297ce01-d3b7-4e3c-89e3-dfc6722fe01a" />

[Picture](https://techdifferences.com/difference-between-classification-and-clustering.html)

Ä°lk bakÄ±ÅŸta, kÃ¼meleme, sÄ±nÄ±flandÄ±rmaya benzer gelebilir; her ikisi de veriyi gruplara ayÄ±rmayÄ± iÃ§erir. Ancak:

* **SÄ±nÄ±flandÄ±rma:** GruplarÄ± **Ã¶nceden biliriz** ve modelin onlarÄ± tahmin etmesini isteriz (Denetimli Ã–ÄŸrenme).
* **KÃ¼meleme:** GruplarÄ± **bilmeyiz** ve algoritmanÄ±n onlarÄ± keÅŸfetmesini isteriz (Denetimsiz Ã–ÄŸrenme).

### Ã–rnek 1: Grup KeÅŸfi vs. Tahmin ğŸ•ğŸ¦ˆ

| KÃ¼meleme (KeÅŸif) ğŸ—ºï¸ | SÄ±nÄ±flandÄ±rma (Tahmin) ğŸ¯ |
| :--- | :--- |
| Algoritma etiketleri (kedi, kÃ¶pek, balÄ±k, kÃ¶pek balÄ±ÄŸÄ±) bilmez. Sadece benzer ÅŸeyleri Ã¶zelliklerine gÃ¶re gruplar. | Burada etiketleri zaten biliyoruz ("Kedi = SÄ±nÄ±f 1", "KÃ¶pek = SÄ±nÄ±f 2", vb.). Model bu etiketlerden Ã¶ÄŸrenir ve yeni veri iÃ§in doÄŸru olanÄ± tahmin eder. |
| ğŸ‘‰ **Ã–rnek:** Kediyi ve kÃ¶peÄŸi bir araya (belki ikisi de karada yÃ¼rÃ¼yor), balÄ±ÄŸÄ± ve kÃ¶pek balÄ±ÄŸÄ±nÄ± bir araya (ikisi de yÃ¼zÃ¼yor) yerleÅŸtirir. | ğŸ‘‰ **Ã–rnek:** Modele yeni bir kÃ¶pek balÄ±ÄŸÄ± gÃ¶sterirsek, onu "SÄ±nÄ±f 4: KÃ¶pek BalÄ±ÄŸÄ±" olarak atayacaktÄ±r. |

### Ã–rnek 2: SÄ±nÄ±r KeÅŸfi vs. SÄ±nÄ±r Ã–ÄŸrenimi ğŸ”´ğŸ”µ

| KÃ¼meleme (Veri BenzerliÄŸine Odaklanma) âœ¨ | SÄ±nÄ±flandÄ±rma (SÄ±nÄ±r Ã‡izgisine Odaklanma) ğŸ“ |
| :--- | :--- |
| Etiket yoktur. Algoritma, yalnÄ±zca **benzerliÄŸe** dayanarak yakÄ±ndaki noktalarÄ± kÃ¼melere (KÃ¼me 1, KÃ¼me 2) ayÄ±rÄ±r. | Gruplar zaten etiketlenmiÅŸtir (SÄ±nÄ±f 1, SÄ±nÄ±f 2). Modelin gÃ¶revi, sÄ±nÄ±flarÄ± ayÄ±ran bir **sÄ±nÄ±r Ã§izgisi** Ã¶ÄŸrenmektir. |
| ğŸ‘‰ **Ã–rnek:** YalnÄ±zca bazÄ± noktalarÄ±n birbirine yakÄ±n olduÄŸunu "fark eder" ve onlarÄ± tek bir grup olarak ele alÄ±r. | ğŸ‘‰ **Ã–rnek:** Yeni bir nokta Ã§izginin Ã¼stÃ¼ne dÃ¼ÅŸerse, SÄ±nÄ±f 2'ye aittir. AltÄ±na dÃ¼ÅŸerse, SÄ±nÄ±f 1'e aittir. |


# KÃ¼meleme Ä°Ã§in Temel TanÄ±mlar ğŸ”‘

Belirli algoritmalara dalmadan Ã¶nce, kÃ¼melemenin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamanÄ±za yardÄ±mcÄ± olacak birkaÃ§ temel kavramÄ± tanÄ±mlayalÄ±m:

### ğŸŒ KÃ¼me (Cluster)

<img width="1092" height="421" alt="image" src="https://github.com/user-attachments/assets/2c819659-0004-4137-bfcb-c4975457b8a0" />

[Picture](https://dev.to/anurag629/centroid-based-clustering-a-powerful-machine-learning-technique-for-partitioning-datasets-41im)

* **TanÄ±m:** Birbirine **benzer** olan veri noktalarÄ±nÄ±n oluÅŸturduÄŸu bir gruptur.
* **Ã–nemi:** Her kÃ¼me, veri iÃ§indeki **ayrÄ±k bir grubu** veya **segmenti** temsil eder. Ã–rneÄŸin, mÃ¼ÅŸteri kÃ¼melemesinde her kÃ¼me, farklÄ± bir mÃ¼ÅŸteri tipine karÅŸÄ±lÄ±k gelir.

### ğŸ¯ Merkez NoktasÄ± (Centroid)

<img width="682" height="251" alt="image" src="https://github.com/user-attachments/assets/1fcce4cf-6260-44e3-a7d2-cf3fddcd1120" />

* **TanÄ±m:** Bir kÃ¼me iÃ§indeki tÃ¼m veri noktalarÄ±nÄ±n "ortalama" konumunu temsil eden **merkezi noktadÄ±r**.
* **Ã–nemi:** KÃ¼menin konumunu ve sÄ±nÄ±rlarÄ±nÄ± tanÄ±mlamak iÃ§in referans noktasÄ± gÃ¶revi gÃ¶rÃ¼r. Ã–zellikle **K-Ortalamalar (K-Means)** gibi algoritmalar bu merkez noktalarÄ±nÄ± kullanarak kÃ¼melemeyi gerÃ§ekleÅŸtirir.


### ğŸ“ Mesafe MetriÄŸi (Distance Metric)

<img width="514" height="604" alt="image" src="https://github.com/user-attachments/assets/45073d12-ea5a-40c8-9305-148631274de7" />

* **TanÄ±m:** Ä°ki noktanÄ±n birbirine ne kadar uzak olduÄŸunu Ã¶lÃ§mek iÃ§in kullanÄ±lan bir yÃ¶ntemdir.
* **YaygÄ±n Metrikler:**
    * **Ã–klid Mesafesi (Euclidean distance):** Ä°ki nokta arasÄ±ndaki dÃ¼z Ã§izgi mesafesidir (uzayÄ±n iki noktasÄ± arasÄ±ndaki en kÄ±sa mesafe).
    * **Manhattan Mesafesi (Manhattan distance):** Ä°ki nokta arasÄ±ndaki mesafenin, bir Ä±zgaranÄ±n eksenleri boyunca Ã¶lÃ§Ã¼len toplamÄ± (ÅŸehir bloklarÄ± arasÄ±nda yÃ¼rÃ¼meye benzer).

### â¬‡ï¸ Eylemsizlik (Inertia)
* **TanÄ±m:** KÃ¼melemede, eylemsizlik (inertia), veri noktalarÄ±nÄ±n ait olduklarÄ± kÃ¼melere ne kadar iyi uyduÄŸunu Ã¶lÃ§er.
* **Ã–nemi:** **Daha dÃ¼ÅŸÃ¼k eylemsizlik**, kÃ¼melerin daha **kompakt** olduÄŸu ve noktalarÄ±n kendi merkez noktalarÄ±na (**centroid**) daha yakÄ±n olduÄŸu anlamÄ±na gelir. BaÅŸka bir deyiÅŸle, dÃ¼ÅŸÃ¼k eylemsizlik daha iyi bir kÃ¼meleme kalitesine iÅŸaret eder.




