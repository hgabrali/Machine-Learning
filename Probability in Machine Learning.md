# ğŸ§  Makine Ã–ÄŸrenimi'nin OlasÄ±lÄ±k Temelleri (Probability Foundations of Machine Learning)

Makine Ã¶ÄŸrenimi, bÃ¼yÃ¼k Ã¶lÃ§Ã¼de bilinmeyen bir sonucun, elimizdeki verilere dayanarak ortaya Ã§Ä±kma **olasÄ±lÄ±ÄŸÄ±nÄ± hesaplama** sanatÄ±dÄ±r. Temelde ML, bir olasÄ±lÄ±k hesaplama makinesi olarak iÅŸlev gÃ¶rÃ¼r.

---

## 1. KoÅŸullu OlasÄ±lÄ±k (Conditional Probability) ğŸ“Š

Makine Ã¶ÄŸrenimindeki en yaygÄ±n kullanÄ±m alanÄ±, bir ÅŸeyin olasÄ±lÄ±ÄŸÄ±nÄ± **baÅŸka faktÃ¶rler (features)** verildiÄŸinde hesaplamaktÄ±r.

| Uygulama (Application) | Hesaplanan KoÅŸullu OlasÄ±lÄ±k | AÃ§Ä±klama (Explanation) |
| :--- | :--- | :--- |
| **Spam Tespiti** (Spam Detection) ğŸ“§ | P(Spam \| Kelimeler, AlÄ±cÄ±lar, ...) | Bir e-postanÄ±n **istenmeyen posta (spam)** olma olasÄ±lÄ±ÄŸÄ±, e-postadaki **kelimeler (words)** ve diÄŸer **Ã¶zellikler (features)** verildiÄŸinde. |
| **Duygu Analizi** (Sentiment Analysis) ğŸ˜Š | P(Mutlu \| Metindeki Kelimeler) | Bir metnin **mutlu (happy)** olma olasÄ±lÄ±ÄŸÄ±, iÃ§erdiÄŸi **kelimeler (words)** verildiÄŸinde. |
| **GÃ¶rÃ¼ntÃ¼ TanÄ±ma** (Image Recognition) ğŸ“¸ | P(Kedi \| Pikseller) | Bir resimde **kedi (cat)** olma olasÄ±lÄ±ÄŸÄ±, resimdeki **pikseller (pixels)** verildiÄŸinde. |

**Teknik TanÄ±m:** KoÅŸullu olasÄ±lÄ±k, **P(A \| B)** formÃ¼lÃ¼ ile ifade edilir ve "**B olayÄ± gerÃ§ekleÅŸtiÄŸinde A olayÄ±nÄ±n gerÃ§ekleÅŸme olasÄ±lÄ±ÄŸÄ±**" anlamÄ±na gelir. Makine Ã¶ÄŸrenimi **sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±nÄ±n (classifiers)** yaptÄ±ÄŸÄ± temel iÅŸ budur.

---

## 2. SÃ¼pervizyonlu Ã–ÄŸrenme ve KoÅŸullu OlasÄ±lÄ±k (Supervised Learning and Conditional Probability)

Metinde bahsedilen Spam Tespiti, Duygu Analizi ve GÃ¶rÃ¼ntÃ¼ TanÄ±ma Ã¶rnekleri **SÃ¼pervizyonlu Ã–ÄŸrenme (Supervised Learning)** alanÄ±na aittir.

* Bu alanda, model **etiketli veri (labeled data)** kullanÄ±larak eÄŸitilir ve sorulara cevap arar.
* **AmaÃ§:** Verilen girdi iÃ§in doÄŸru **etiketi (label)** tahmin etmektir.
* **Ã–rnekler:** Resim kedi mi? CÃ¼mle olumlu mu? E-posta spam mi?

---

## 3. Bayes Teoremi ve ArtÃ§Ä± OlasÄ±lÄ±k (Bayes' Theorem and Posterior Probability) ğŸ²

Bayes Teoremi, bir **sÄ±nÄ±flandÄ±rÄ±cÄ± (classifier)** oluÅŸturarak bir ÅŸeyin olasÄ±lÄ±ÄŸÄ±nÄ± baÅŸka bir ÅŸey verildiÄŸinde hesaplamanÄ±zÄ± saÄŸlayan matematiksel bir mekanizma sunar.

$$\mathbf{P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}}$$

OlasÄ±lÄ±ÄŸÄ±n hesaplanmasÄ±nda **Bayes Teoremi'nin** nasÄ±l kullanÄ±ldÄ±ÄŸÄ± aÃ§Ä±klanmÄ±ÅŸtÄ±r:

1.  **Ã–nsel OlasÄ±lÄ±k (Prior Probability):** BaÅŸlangÄ±Ã§ olasÄ±lÄ±ÄŸÄ±dÄ±r (Ã–rn: TÃ¼m e-postalar iÃ§inde spam oranÄ±, P(Spam)).
2.  **KanÄ±t (Evidence) veya Olay (Event):** Yeni bir bilginin ortaya Ã§Ä±kmasÄ± (Ã–rn: E-postada "lottery" kelimesinin geÃ§mesi).
3.  **ArtÃ§Ä± OlasÄ±lÄ±k (Posterior Probability):** Ã–nsel olasÄ±lÄ±ÄŸÄ±n yeni bilgiyle gÃ¼ncellenmiÅŸ halidir (Ã–rn: P(Spam \| Lottery)).

---

## 4. Jeneratif Modeller ve Saf OlasÄ±lÄ±k (Generative Models and Pure Probability) âœ¨

Metin, koÅŸullu olasÄ±lÄ±ÄŸÄ±n yanÄ± sÄ±ra **saf olasÄ±lÄ±klarÄ±n (pure probabilities)** kullanÄ±ldÄ±ÄŸÄ± bÃ¼yÃ¼k bir ML alanÄ±nÄ± daha tanÄ±tÄ±r: **Jeneratif Makine Ã–ÄŸrenimi (Generative Machine Learning)**. Bu, **GÃ¶zetimsiz Ã–ÄŸrenme (Unsupervised Learning)** alanÄ±nÄ±n bir parÃ§asÄ±dÄ±r.

* **AmaÃ§:** Modelin, var olan veriye benzeyen **yeni iÃ§erik** (gÃ¶rÃ¼ntÃ¼, metin, ses) Ã¼retmesini saÄŸlamaktÄ±r.
* **Ä°ÅŸleyiÅŸ:** Burada amaÃ§, koÅŸullu olasÄ±lÄ±k hesaplamak yerine, yeni Ã¼retilen verinin gerÃ§ekÃ§i olma olasÄ±lÄ±ÄŸÄ±nÄ± **maksimize etmektir (maximize probability)**.
    * **GÃ¶rÃ¼ntÃ¼ Ãœretimi (Image Generation - Ã–rn: StyleGAN):** Model, rastgele piksellerin insan yÃ¼zÃ¼ oluÅŸturma olasÄ±lÄ±ÄŸÄ±nÄ± **maksimize etmeye** Ã§alÄ±ÅŸÄ±r.
    * **Metin Ãœretimi (Text Generation):** Model, rastgele kelimelerin anlamlÄ± ve baÄŸlamÄ±na uygun bir metin oluÅŸturma olasÄ±lÄ±ÄŸÄ±nÄ± **maksimize etmeye** Ã§alÄ±ÅŸÄ±r.
 
    * # ğŸ’¡ Makine Ã–ÄŸrenmesinde Bayes Teoremi ve Ä°lgili Konular

Bayes Teoremi, makine Ã¶ÄŸrenmesinde **olasÄ±lÄ±ksal sÄ±nÄ±flandÄ±rma** algoritmalarÄ±nÄ±n temelini oluÅŸturur. Ã–zellikle **NaÃ¯ve Bayes SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±** gibi yaygÄ±n algoritmalarÄ± anlamak iÃ§in bu kavramlara derinlemesine hakim olmak kritiktir.

---

## ğŸ“ Bayes Teoremi'nin FormÃ¼lÃ¼ ve BileÅŸenleri

Bayes Teoremi, bir olayÄ±n gerÃ§ekleÅŸme olasÄ±lÄ±ÄŸÄ±nÄ±, Ã¶nceden bilinen koÅŸullu ve marjinal olasÄ±lÄ±klarÄ± kullanarak hesaplar.

$$\huge P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

| Terim | AdÄ± | AÃ§Ä±klama (Makine Ã–ÄŸrenmesi) |
| :--- | :--- | :--- |
| **P(A|B)** | **Sonsal OlasÄ±lÄ±k (Posterior)** | Verilen veri (B) ile Ã¶rneÄŸin belli bir sÄ±nÄ±fa (A) ait olma olasÄ±lÄ±ÄŸÄ±. (Hedefimiz budur!) |
| **P(B|A)** | **Olabilirlik (Likelihood)** | Verilen sÄ±nÄ±f (A) iÃ§in verinin (B) gÃ¶zlemlenme olasÄ±lÄ±ÄŸÄ±. |
| **P(A)** | **Ã–nsel OlasÄ±lÄ±k (Prior)** | B olayÄ± hakkÄ±nda hiÃ§bir bilgi olmadan A sÄ±nÄ±fÄ±nÄ±n genel olasÄ±lÄ±ÄŸÄ±. |
| **P(B)** | **KanÄ±t (Evidence)** | Sonsal olasÄ±lÄ±ÄŸÄ± normalize eden sabittir. |

## ğŸ¤– Naive Bayes SÄ±nÄ±flandÄ±rÄ±cÄ± Ã‡eÅŸitleri ve KarÅŸÄ±laÅŸtÄ±rmasÄ±

Naive Bayes, **Ã¶zelliklerin birbirinden baÄŸÄ±msÄ±z olduÄŸu** (saf varsayÄ±m) varsayÄ±mÄ±na dayanÄ±r ve basitliÄŸi ile Ã¶ne Ã§Ä±kar.

| Algoritma AdÄ± | Temel Ã–zellik VarsayÄ±mÄ± | Uygulama AlanÄ± | Ã–rnek Veri Tipi | AvantajlarÄ± |
| :--- | :--- | :--- | :--- | :--- |
| **Gaussian Naive Bayes** | Ã–zellikler **Normal (Gauss) daÄŸÄ±lÄ±mÄ±na** (Normal/Gaussian Distribution) uyar. | SÃ¼rekli sayÄ±sal verilerin olduÄŸu sÄ±nÄ±flandÄ±rma problemleri. | Boy, kilo, sÄ±caklÄ±k gibi sÃ¼rekli deÄŸerler. | HÄ±zlÄ± ve kÃ¼Ã§Ã¼k veri kÃ¼melerinde baÅŸarÄ±lÄ±dÄ±r. |
| **Multinomial Naive Bayes** | Ã–zellikler **Multinomial daÄŸÄ±lÄ±mÄ±na** (Multinomial Distribution) uyar (sayÄ±m verileri). | Metin sÄ±nÄ±flandÄ±rma (spam, duygu analizi). | Bir belgedeki kelimelerin frekansÄ± (sayÄ±mÄ±). | Metin verilerinde en baÅŸarÄ±lÄ± Ã§eÅŸitlerdendir. |
| **Bernoulli Naive Bayes** | Ã–zellikler **Bernoulli daÄŸÄ±lÄ±mÄ±na** (Bernoulli Distribution) uyar (ikili/Boolean). | Belge varlÄ±ÄŸÄ±/yokluÄŸu, ikili Ã¶zelliklerin olduÄŸu sÄ±nÄ±flandÄ±rmalar. | Kelimenin bir belgede bulunup bulunmamasÄ± (1/0). | Ä°kili Ã¶zellik setleri iÃ§in etkilidir. |

---

## ğŸ§  Bilinmesi Gereken Kritik Ek Konular

Bayes algoritmalarÄ±nÄ± etkili kullanmak iÃ§in anlaÅŸÄ±lmasÄ± gereken temel kavramlar:

### 1. KoÅŸullu BaÄŸÄ±msÄ±zlÄ±k VarsayÄ±mÄ± (Conditional Independence)
* **AÃ§Ä±klama:** NaÃ¯ve Bayes'in "saf" kÄ±smÄ± buradan gelir. Hedef sÄ±nÄ±f verildiÄŸinde, girdilerin (Ã¶zelliklerin) birbirlerinden baÄŸÄ±msÄ±z olduÄŸu varsayÄ±lÄ±r. Bu, hesaplama karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r.
* **Matematiksel Ä°fade:** $P(x_1, x_2, \dots, x_n | C) = \prod_{i=1}^{n} P(x_i | C)$

### 2. SÄ±fÄ±r Frekans Problemi ve Ã‡Ã¶zÃ¼mÃ¼
* **Problem:** EÄŸitim verisinde hiÃ§ gÃ¶rÃ¼lmeyen bir Ã¶zellik-sÄ±nÄ±f kombinasyonu test verisinde ortaya Ã§Ä±karsa, ilgili **Olabilirlik** ($P(B|A)$) sÄ±fÄ±r olur. Bu durumda, sonuÃ§ **Sonsal OlasÄ±lÄ±k** da sÄ±fÄ±rlanÄ±r.
* **Ã‡Ã¶zÃ¼m:** **Laplace YumuÅŸatmasÄ± (Laplace Smoothing)** kullanÄ±lÄ±r. TÃ¼m sayÄ±mlara kÃ¼Ã§Ã¼k bir pozitif deÄŸer ($\alpha$, genellikle 1) eklenerek sÄ±fÄ±r olasÄ±lÄ±klar engellenir.

### 3. Maksimum Sonsal OlasÄ±lÄ±k (Maximum A Posteriori - MAP) Karar KuralÄ±

* **AÃ§Ä±klama:** SÄ±nÄ±flandÄ±rma yaparken NaÃ¯ve Bayes, olasÄ± tÃ¼m sÄ±nÄ±flar ($C_k$) arasÄ±ndan **en yÃ¼ksek sonsal olasÄ±lÄ±ÄŸa** sahip olan sÄ±nÄ±fÄ± seÃ§er. Bu, modelin tahmin mekanizmasÄ±dÄ±r.


### 4. Bayes AÄŸlarÄ± (Bayesian Networks) ğŸŒ
* **AÃ§Ä±klama:** NaÃ¯ve Bayes'in baÄŸÄ±msÄ±zlÄ±k varsayÄ±mÄ±nÄ±n Ã¶tesine geÃ§en, Ã¶zellikler arasÄ±ndaki **baÄŸÄ±mlÄ±lÄ±klarÄ±** modelleyebilen daha geliÅŸmiÅŸ olasÄ±lÄ±ksal grafik modellerdir.
* **Ã–nemi:** Ã–zellikler arasÄ±ndaki nedensel iliÅŸkileri (YÃ¶nlendirilmiÅŸ Asiklik Grafikler - DAG) kullanarak daha doÄŸru, ancak daha karmaÅŸÄ±k Ã§Ä±karÄ±mlar saÄŸlar.

---

## âœ‰ï¸ Ã–rnek Uygulama: E-posta Spam Tespiti (Multinomial NB)

**AmaÃ§:** "Ãœcretsiz para" e-postasÄ±nÄ± sÄ±nÄ±flandÄ±rmak.

### 1. Ã–nsel OlasÄ±lÄ±klar (Prior)

| SÄ±nÄ±f | SayÄ±m | $P(C)$ |
| :--- | :--- | :--- |
| Spam | 3 | $3/5 = 0.6$ |
| Ham | 2 | $2/5 = 0.4$ |

### 2. Olabilirlikler (Likelihood) - Laplace YumuÅŸatmasÄ± UygulanmÄ±ÅŸ

KullanÄ±lan kelimeler: "Ãœcretsiz" ve "Para".

* $P(\text{Ãœcretsiz}|\text{Spam}) = 3/17$
* $P(\text{Para}|\text{Spam}) = 2/17$

* $P(\text{Ãœcretsiz}|\text{Ham}) = 1/14$
* $P(\text{Para}|\text{Ham}) = 1/14$

### 3. Sonsal OlasÄ±lÄ±k HesabÄ±

MAP kuralÄ±nÄ± uygulayarak:

* **Spam PuanÄ±:** $P(\text{Spam}|D) \propto P(\text{Ãœcretsiz}|\text{Spam}) \cdot P(\text{Para}|\text{Spam}) \cdot P(\text{Spam})$
    * Spam PuanÄ± $\propto (3/17) \cdot (2/17) \cdot 0.6 \approx 0.0124$

* **Ham PuanÄ±:** $P(\text{Ham}|D) \propto P(\text{Ãœcretsiz}|\text{Ham}) \cdot P(\text{Para}|\text{Ham}) \cdot P(\text{Ham})$
    * Ham PuanÄ± $\propto (1/14) \cdot (1/14) \cdot 0.4 \approx 0.0020$

**SonuÃ§:** $0.0124 > 0.0020$ olduÄŸu iÃ§in model, e-postayÄ± **SPAM** olarak sÄ±nÄ±flandÄ±rÄ±r. âœ…

---
---

<img width="930" height="347" alt="image" src="https://github.com/user-attachments/assets/ebf529b1-ea70-4f52-b2cc-874a6a8607f4" />

## â“ OlasÄ±lÄ±k Problemi Ã‡Ã¶zÃ¼mÃ¼: Yetersiz Bilgi

Bu, **BirleÅŸim OlasÄ±lÄ±ÄŸÄ± (Probability of Union)** hesaplama problemidir. Temel kural, iki olayÄ±n **kesiÅŸiminin ($P(A \text{ ve } B)$)** bilinmesini gerektirir.

### ğŸ’Š Deney Verileri

* **Toplam Hasta SayÄ±sÄ±:** 100
* **BaÅŸ AÄŸrÄ±sÄ± YaÅŸayanlar (Headache - H):** 50
* **AteÅŸ YaÅŸayanlar (Fever - F):** 50

**OlasÄ±lÄ±klar (Prior):**
* $P(H) = \frac{50}{100} = 0.5$
* $P(F) = \frac{50}{100} = 0.5$

### ğŸ¯ Ä°stenen OlasÄ±lÄ±k

Doktorlar, bir hastanÄ±n **BaÅŸ AÄŸrÄ±sÄ± VEYA AteÅŸ** yaÅŸama olasÄ±lÄ±ÄŸÄ±nÄ±, yani $\mathbf{P(H \cup F)}$'i bulmak istiyor.

### ğŸ“ OlasÄ±lÄ±klarÄ±n BirleÅŸim KuralÄ± (The Addition Rule)

Genel kural ÅŸudur:
$$\mathbf{P(A \text{ veya } B)} = P(A) + P(B) - P(A \text{ ve } B)$$

Bu kuralÄ± uygulamak iÃ§in $\mathbf{P(\text{BaÅŸ AÄŸrÄ±sÄ± ve AteÅŸ})}$ terimine ihtiyacÄ±mÄ±z var. Bu, aynÄ± anda hem baÅŸ aÄŸrÄ±sÄ± hem de ateÅŸ yaÅŸayan hastalarÄ±n oranÄ±nÄ± ifade eder. Soruda bu **kesiÅŸim olasÄ±lÄ±ÄŸÄ±** (yani kaÃ§ hastanÄ±n Ã§ifte semptom yaÅŸadÄ±ÄŸÄ±) **verilmemiÅŸtir**.

### âŒ GeÃ§ersiz VarsayÄ±mlarÄ±n Ä°ncelenmesi

| VarsayÄ±m | Kural | Neden GeÃ§ersiz? |
| :--- | :--- | :--- |
| **AyrÄ±k Olaylar** (Mutually Exclusive) | $P(A \text{ veya } B) = P(A) + P(B) = 1$ | HiÃ§bir hastanÄ±n iki semptomu birden yaÅŸamadÄ±ÄŸÄ± varsayÄ±lÄ±r. Soruda bu bilgi **yoktur**. |
| **BaÄŸÄ±msÄ±z Olaylar** (Independent) | $P(A \text{ ve } B) = P(A) \cdot P(B) = 0.25$ | TÄ±bbi semptomlar genellikle **baÄŸÄ±mlÄ±dÄ±r**. Ä°laÃ§, semptomlardan birini tetikleyebilir veya engelleyebilir. Bu varsayÄ±mÄ±n doÄŸru olduÄŸu **garanti edilemez**. |

### ğŸ›‘ SonuÃ§

$\mathbf{P(\text{H ve F})}$ deÄŸeri (kesiÅŸim) bilinmediÄŸi sÃ¼rece, **BirleÅŸim OlasÄ±lÄ±ÄŸÄ±** doÄŸru bir ÅŸekilde hesaplanamaz.

* **Ek Bilgi Gereksinimi:** KaÃ§ hasta **sadece** baÅŸ aÄŸrÄ±sÄ±, kaÃ§ hasta **sadece** ateÅŸ ve kaÃ§ hasta **hem** baÅŸ aÄŸrÄ±sÄ± **hem de** ateÅŸ yaÅŸadÄ±?

**DoÄŸru Ä°fade:**
> **Not enough information is given to calculate $P(\text{fever or headache})$.**
> (BaÅŸ aÄŸrÄ±sÄ± veya ateÅŸ olasÄ±lÄ±ÄŸÄ±nÄ± hesaplamak iÃ§in yeterli bilgi verilmemiÅŸtir.)
>
> ## ğŸ“Œ AÃ§Ä±klamanÄ±n Ã–zeti: Neden Yetersiz Bilgi?

AÃ§Ä±klama, temel olasÄ±lÄ±k kurallarÄ±ndan yola Ã§Ä±karak ÅŸunlarÄ± sÃ¶ylÃ¼yor:

1.  **Olaylar OrtaktÄ±r (Joint Events) ğŸ¤:** Problem metninde, iki olayÄ±n (**baÅŸ aÄŸrÄ±sÄ±** ve **ateÅŸ**) **ayrÄ±k (disjoint)** olduÄŸu, yani aynÄ± anda gerÃ§ekleÅŸemeyeceÄŸi sÃ¶ylenmiyor. DolayÄ±sÄ±yla, bazÄ± kiÅŸilerin **hem baÅŸ aÄŸrÄ±sÄ± hem de ateÅŸ** yaÅŸama ihtimali vardÄ±r. Bu tÃ¼r Ã§akÄ±ÅŸan olaylara **ortak olaylar (joint events)** denir.

2.  **KesiÅŸim Bilinmeli â“:** Ä°ki olayÄ±n birleÅŸim olasÄ±lÄ±ÄŸÄ±nÄ± ($P(A \text{ veya } B)$) hesaplamak iÃ§in genel **Toplama KuralÄ± (Addition Rule)**'nÄ± kullanmak zorunludur:
    $$\mathbf{P(A \text{ veya } B)} = P(A) + P(B) - P(A \text{ ve } B)$$

3.  **SonuÃ§ ğŸ›‘:** Bu nedenle, $P(\text{ateÅŸ veya baÅŸ aÄŸrÄ±sÄ±})$ olasÄ±lÄ±ÄŸÄ±nÄ± bulmak iÃ§in, olaylarÄ±n kesiÅŸim olasÄ±lÄ±ÄŸÄ± olan **$P(\text{ateÅŸ VE baÅŸ aÄŸrÄ±sÄ±})$** deÄŸerini **bilmeniz gerekir**. Bu bilgi problem metninde verilmediÄŸi iÃ§in, olasÄ±lÄ±k hesaplanamaz.

---

<img width="870" height="357" alt="image" src="https://github.com/user-attachments/assets/f76afc36-6297-45df-9f2a-011289ddd967" />


## ğŸ KoÅŸullu OlasÄ±lÄ±k Ã‡Ã¶zÃ¼mÃ¼: YazÄ±lÄ±m Testi

Bu problem, **Bayes Teoremi'nin temelini oluÅŸturan** bir **KoÅŸullu OlasÄ±lÄ±k (Conditional Probability)** problemidir. Bir kullanÄ±cÄ±nÄ±n hata deneyimlediÄŸi bilgisi **verildiÄŸinde**, Versiyon B'yi test etme olasÄ±lÄ±ÄŸÄ±nÄ± bulmayÄ± amaÃ§lar.

### ğŸ“ 1. Olay TanÄ±mlarÄ± ve FormÃ¼l

* **B:** KullanÄ±cÄ±nÄ±n **Versiyon B**'yi test etmesi.
* **H:** KullanÄ±cÄ±nÄ±n **Hata (Bug)** deneyimlemesi.

Aranan olasÄ±lÄ±k: $P(B|H)$ (Hata deneyimlediÄŸine gÃ¶re, Versiyon B'yi test etme olasÄ±lÄ±ÄŸÄ±).

$$\mathbf{P(B|H)} = \frac{P(B \cap H)}{P(H)}$$

### ğŸ“Š 2. Verilerin Ã–zetlenmesi

Toplam kullanÄ±cÄ± sayÄ±sÄ±: $4000 + 5000 = \mathbf{9000}$

| Kategori | DeÄŸer | Olay SayÄ±sÄ± (N) | OlasÄ±lÄ±k (P) |
| :--- | :--- | :--- | :--- |
| **Versiyon B KullanÄ±cÄ±larÄ±** | 5000 | $N(B)$ | $P(B) = 5000/9000$ |
| **Toplam Hata Deneyimleyenler** | 3000 | $N(H)$ | $P(H) = 3000/9000$ |
| **Versiyon B ve Hata KesiÅŸimi** | 1500 | $N(B \cap H)$ | $P(B \cap H) = 1500/9000$ |

### ğŸ§  3. Hesaplama (KullanÄ±cÄ± SayÄ±larÄ±yla)

OlasÄ±lÄ±klar yerine, hesaplamanÄ±n daha basit olmasÄ± iÃ§in doÄŸrudan **kullanÄ±cÄ± sayÄ±larÄ±nÄ±** kullanabiliriz, Ã§Ã¼nkÃ¼ payda ($N(\text{Toplam})$) sadeleÅŸecektir:

$$\mathbf{P(B|H)} = \frac{N(\text{B ve H})}{N(H)} = \frac{\text{Versiyon B ile hata deneyimleyenler}}{\text{Toplam hata deneyimleyenler}}$$

$$P(B|H) = \frac{1500}{3000}$$

$$P(B|H) = \frac{1}{2} = \mathbf{0.5}$$

---

### âœ… SonuÃ§

Bir kullanÄ±cÄ±nÄ±n **hata deneyimlediÄŸi** bilgisi verildiÄŸinde, bu kullanÄ±cÄ±nÄ±n **Versiyon B**'yi test etmiÅŸ olma olasÄ±lÄ±ÄŸÄ± $\mathbf{1/2}$ (**%50**) olarak bulunur.


---

<img width="966" height="326" alt="image" src="https://github.com/user-attachments/assets/c8262fec-89f0-4c5b-ac2f-3c45b1eb903f" />

# ğŸ”¬ Bayes Teoremi UygulamasÄ±: TÄ±bbi Test Analizi

Bu, bir kiÅŸinin test sonucu pozitif Ã§Ä±ktÄ±ÄŸÄ±nda **gerÃ§ekte hasta olma olasÄ±lÄ±ÄŸÄ±nÄ± (Sonsal OlasÄ±lÄ±k)** hesaplayan klasik bir Bayes Teoremi problemidir.

### ğŸ¯ Aranan OlasÄ±lÄ±k

Ä°stenen olasÄ±lÄ±k, testin pozitif Ã§Ä±ktÄ±ÄŸÄ± bilgisi **verildiÄŸinde** kiÅŸinin hasta olma olasÄ±lÄ±ÄŸÄ±dÄ±r: $\mathbf{P(\text{hasta} | \text{test poz.})}$.

**Bayes Teoremi FormÃ¼lÃ¼:**
$$P(\text{hasta} | \text{test poz.}) = \frac{P(\text{test poz.} | \text{hasta}) \cdot P(\text{hasta})}{P(\text{test poz.})}$$

---

### 1. Parametrelerin TanÄ±mlanmasÄ± ve GiriÅŸ Verileri

| Veri | TanÄ±m | DeÄŸer |
| :--- | :--- | :--- |
| **Ã–nsel OlasÄ±lÄ±k** | $P(\text{hasta})$ (HastalÄ±k yaygÄ±nlÄ±ÄŸÄ±) | $1\% = \mathbf{0.01}$ |
| **Olabilirlik (True Positive)** | $P(\text{test poz.} | \text{hasta})$ (Hasta iken testin pozitif Ã§Ä±kmasÄ±) | $95\% = \mathbf{0.95}$ |
| **True Negative** | $P(\text{test neg.} | \text{saÄŸlÄ±klÄ±})$ (SaÄŸlÄ±klÄ± iken testin negatif Ã§Ä±kmasÄ±) | $90\% = \mathbf{0.90}$ |

---

### 2. Eksik OlasÄ±lÄ±klarÄ±n HesaplanmasÄ± (TÃ¼mleyen KuralÄ±)

Bayes formÃ¼lÃ¼nÃ¼ tamamlamak iÃ§in gerekli deÄŸerler:

#### A) SaÄŸlÄ±klÄ± Olma OlasÄ±lÄ±ÄŸÄ± ($P(\text{saÄŸlÄ±klÄ±})$)
$$P(\text{saÄŸlÄ±klÄ±}) = 1 - P(\text{hasta}) = 1 - 0.01 = \mathbf{0.99}$$

#### B) YanlÄ±ÅŸ Pozitif OlasÄ±lÄ±ÄŸÄ± ($P(\text{test poz.} | \text{saÄŸlÄ±klÄ±})$)
SaÄŸlÄ±klÄ± bir kiÅŸide testin pozitif Ã§Ä±kma olasÄ±lÄ±ÄŸÄ± (False Positive):
$$P(\text{test poz.} | \text{saÄŸlÄ±klÄ±}) = 1 - P(\text{test neg.} | \text{saÄŸlÄ±klÄ±}) = 1 - 0.90 = \mathbf{0.10}$$

---

### 3. KanÄ±tÄ±n HesaplanmasÄ± ($P(\text{test poz.})$)

KanÄ±t (payda), hem doÄŸru pozitifler hem de yanlÄ±ÅŸ pozitifler dahil olmak Ã¼zere **tÃ¼m pozitif test sonuÃ§larÄ±nÄ±n** toplam olasÄ±lÄ±ÄŸÄ±dÄ±r (Toplam OlasÄ±lÄ±k KuralÄ±):

$$P(\text{test poz.}) = \big(P(\text{test poz.} | \text{hasta}) \cdot P(\text{hasta})\big) + \big(P(\text{test poz.} | \text{saÄŸlÄ±klÄ±}) \cdot P(\text{saÄŸlÄ±klÄ±})\big)$$

$$P(\text{test poz.}) = (0.95 \cdot 0.01) + (0.10 \cdot 0.99)$$$$P(\text{test poz.}) = 0.0095 + 0.0990$$$$\mathbf{P(\text{test poz.})} = \mathbf{0.1085}$$

---

### 4. Sonsal OlasÄ±lÄ±ÄŸÄ±n HesaplanmasÄ± (Final)

TÃ¼m deÄŸerleri Bayes Teoremi formÃ¼lÃ¼ne yerleÅŸtirelim:

$$P(\text{hasta} | \text{test poz.}) = \frac{0.0095}{0.1085}$$

$$P(\text{hasta} | \text{test poz.}) \approx \mathbf{0.08755}$$

### âœ… Nihai SonuÃ§ ve Yorum

Test sonucu pozitif Ã§Ä±kan bir kiÅŸinin **gerÃ§ekten hasta olma olasÄ±lÄ±ÄŸÄ±** yaklaÅŸÄ±k olarak **%8.76**'dÄ±r ($\mathbf{0.0876}$).

Bu dÃ¼ÅŸÃ¼k sonuÃ§ ÅŸaÅŸÄ±rtÄ±cÄ±dÄ±r ve temel olarak ÅŸundan kaynaklanÄ±r:
> **HastalÄ±k nadirdir.** PopÃ¼lasyonun sadece %1'i hastadÄ±r. Test oldukÃ§a doÄŸru olsa da, Ã§ok sayÄ±da saÄŸlÄ±klÄ± insanÄ±n yanlÄ±ÅŸ pozitif ($0.10 \cdot 0.99 = 0.0990$) sonuÃ§ vermesi, doÄŸru pozitif sonuÃ§lardan ($0.95 \cdot 0.01 = 0.0095$) sayÄ±ca Ã§ok daha fazladÄ±r.
> 

---
---

<img width="966" height="582" alt="image" src="https://github.com/user-attachments/assets/a5111561-ea89-40d6-80df-f1ed8bdea4b9" />

# ğŸ² Binom DaÄŸÄ±lÄ±mÄ± (Binomial Distribution) Problemi Ã‡Ã¶zÃ¼mÃ¼

Bu problem, sabit sayÄ±da denemeden (20 zar atÄ±ÅŸÄ±), belirli sayÄ±da (7 kez) baÅŸarÄ± elde etme olasÄ±lÄ±ÄŸÄ±nÄ± hesapladÄ±ÄŸÄ±mÄ±z klasik bir **Binom DaÄŸÄ±lÄ±mÄ±** Ã¶rneÄŸidir.

### ğŸ“ Binom DaÄŸÄ±lÄ±mÄ± FormÃ¼lÃ¼

$n$ denemeden $k$ kez baÅŸarÄ± elde etme olasÄ±lÄ±ÄŸÄ±:

$$P(X=k) = C(n, k) \cdot p^k \cdot (1-p)^{n-k}$$

---

### 1. Problemin Parametreleri

| Parametre | TanÄ±m | DeÄŸer |
| :--- | :--- | :--- |
| **$n$** (Deneme SayÄ±sÄ±) | Zar atÄ±ÅŸÄ± sayÄ±sÄ± | $\mathbf{20}$ |
| **$k$** (Ä°stenen BaÅŸarÄ±) | "4" gelme sayÄ±sÄ± | $\mathbf{7}$ |
| **$p$** (BaÅŸarÄ± OlasÄ±lÄ±ÄŸÄ±) | Bir atÄ±ÅŸta '4' gelme olasÄ±lÄ±ÄŸÄ± | $\mathbf{1/6}$ |
| **$1-p$** (BaÅŸarÄ±sÄ±zlÄ±k OlasÄ±lÄ±ÄŸÄ±) | '4' dÄ±ÅŸÄ±nda bir sayÄ± gelme olasÄ±lÄ±ÄŸÄ± | $1 - 1/6 = \mathbf{5/6}$ |
| **$n-k$** (BaÅŸarÄ±sÄ±zlÄ±k SayÄ±sÄ±) | BaÅŸarÄ±sÄ±z atÄ±ÅŸ sayÄ±sÄ± | $20 - 7 = \mathbf{13}$ |

---

### 2. FormÃ¼lÃ¼n UygulanmasÄ±

Bulunan deÄŸerler formÃ¼lde yerine konur. $C(20, 7)$ ifadesi, kombinasyon gÃ¶sterimi olan $\binom{20}{7}$ ÅŸeklinde yazÄ±lÄ±r:

$$P(X=7) = \binom{20}{7} \cdot \left(\frac{1}{6}\right)^7 \cdot \left(\frac{5}{6}\right)^{13}$$

### âœ… DoÄŸru SeÃ§enek

Bu matematiksel ifadeye karÅŸÄ±lÄ±k gelen seÃ§enek, **dÃ¶rdÃ¼ncÃ¼ (alttan birinci) seÃ§enektir**.

$$P(X=7) = \binom{20}{7} \cdot \left(\frac{1}{6}\right)^7 \cdot \left(\frac{5}{6}\right)^{13}$$

---
---

<img width="763" height="616" alt="image" src="https://github.com/user-attachments/assets/f69d8cc5-702d-47bc-9460-cc0addb2f6fd" />

# ğŸš• AyrÄ±k OlasÄ±lÄ±k Ã‡Ã¶zÃ¼mÃ¼: KÃ¼mÃ¼latif DaÄŸÄ±lÄ±m

Bu, bir taksi yolculuÄŸunda yolcu sayÄ±sÄ±nÄ±n ($X$) **3 veya daha az** olma olasÄ±lÄ±ÄŸÄ±nÄ± hesaplayan bir **AyrÄ±k OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ±** problemidir. Ä°stenen olasÄ±lÄ±k $\mathbf{P(X \le 3)}$'tÃ¼r.

### ğŸ“ Ã‡Ã¶zÃ¼m: KÃ¼mÃ¼latif OlasÄ±lÄ±k Hesaplama

$P(X \le 3)$ olasÄ±lÄ±ÄŸÄ±, $X$'in 0, 1, 2 veya 3 olduÄŸu ayrÄ± olasÄ±lÄ±klarÄ±n toplamÄ±na eÅŸittir:

$$P(X \le 3) = P(X=0) + P(X=1) + P(X=2) + P(X=3)$$

### 1. Tablodan OlasÄ±lÄ±klarÄ± Alma

| Yolcu SayÄ±sÄ± ($x_i$) | OlasÄ±lÄ±k ($p_i$) |
| :--- | :--- |
| $X=0$ | $0.10$ |
| $X=1$ | $0.25$ |
| $X=2$ | $0.25$ |
| $X=3$ | $0.15$ |

### 2. OlasÄ±lÄ±klarÄ± Toplama

Ä°stenen kÃ¼mÃ¼latif olasÄ±lÄ±ÄŸÄ± bulmak iÃ§in deÄŸerleri toplarÄ±z:

$$P(X \le 3) = 0.10 + 0.25 + 0.25 + 0.15$$

$$\mathbf{P(X \le 3)} = \mathbf{0.75}$$

### âœ… SonuÃ§

Rastgele seÃ§ilen bir taksi yolculuÄŸunda yolcu sayÄ±sÄ±nÄ±n 3 veya daha az olma olasÄ±lÄ±ÄŸÄ± $\mathbf{0.75}$'tir (veya **%75**).

---
---

<img width="827" height="529" alt="image" src="https://github.com/user-attachments/assets/c48b6a1e-6605-4e0e-a500-d76c386a4d64" />

<img width="674" height="524" alt="image" src="https://github.com/user-attachments/assets/4c938733-bd84-49ce-b1d1-f1ebfef7b961" />

# ğŸ“‰ DÃ¶rt Normal DaÄŸÄ±lÄ±mÄ±n (Gaussian) KarÅŸÄ±laÅŸtÄ±rmalÄ± Analizi

Bu analiz, dÃ¶rt farklÄ± Normal DaÄŸÄ±lÄ±mÄ±n (Ã‡an EÄŸrisi) iki temel parametresi olan **Ortalama ($\mu$)** ve **Standart Sapma ($\sigma$)** deÄŸerlerinin grafikte nasÄ±l yorumlandÄ±ÄŸÄ±nÄ± gÃ¶sterir.

### ğŸ§  Normal DaÄŸÄ±lÄ±m Parametrelerinin YorumlanmasÄ±

* **Ortalama ($\mu$) Konumu:** EÄŸrinin **en yÃ¼ksek noktasÄ± (tepesi)** $\mu$ deÄŸerine denk gelir.
* **Standart Sapma ($\sigma$) YayÄ±lÄ±mÄ±:** EÄŸri ne kadar **dar ve uzunsa**, $\sigma$ o kadar **kÃ¼Ã§Ã¼ktÃ¼r** (dÃ¼ÅŸÃ¼k varyans). EÄŸri ne kadar **geniÅŸ ve alÃ§aksa**, $\sigma$ o kadar **bÃ¼yÃ¼ktÃ¼r** (yÃ¼ksek varyans).

---

### 1. DaÄŸÄ±lÄ±mlarÄ±n DetaylÄ± Analizi Tablosu

| DaÄŸÄ±lÄ±m | Renk/Ã‡izgi Tipi | Ortalama ($\mu$) Yorumu (Tepe NoktasÄ±) | Standart Sapma ($\sigma$) Yorumu (GeniÅŸlik/YÃ¼kseklik) |
| :--- | :--- | :--- | :--- |
| **normal\_A** | Mavi, DÃ¼z | $\mathbf{x \approx -2.5}$ civarÄ±ndadÄ±r. | En **dar** ve en **yÃ¼ksek** eÄŸridir. **En kÃ¼Ã§Ã¼k $\sigma$** deÄŸerine sahiptir. |
| **normal\_B** | Turuncu, Kesik | $\mathbf{x \approx 0}$ civarÄ±ndadÄ±r. | normal\_A'dan daha geniÅŸ, ancak diÄŸerlerinden kÃ¼Ã§Ã¼ktÃ¼r. |
| **normal\_C** | YeÅŸil, Nokta-Kesik | $\mathbf{x \approx 1.5}$ civarÄ±ndadÄ±r. | normal\_B'den daha geniÅŸtir. |
| **normal\_D** | KÄ±rmÄ±zÄ±, NoktalÄ± | $\mathbf{x \approx 4}$ civarÄ±ndadÄ±r. | En **geniÅŸ** ve en **alÃ§ak** eÄŸridir. **En bÃ¼yÃ¼k $\sigma$** deÄŸerine sahiptir. |

---

### 2. SÄ±ralamalarÄ±n Ã–zeti

| Parametre | SÄ±ralama (KÃ¼Ã§Ã¼kten BÃ¼yÃ¼ÄŸe) |
| :--- | :--- |
| **Ortalama ($\mu$)** | $\mu_{\text{normal\_A}} < \mu_{\text{normal\_B}} < \mu_{\text{normal\_C}} < \mu_{\text{normal\_D}}$ |
| **Standart Sapma ($\sigma$)** | $\sigma_{\text{normal\_A}} < \sigma_{\text{normal\_B}} < \sigma_{\text{normal\_C}} < \sigma_{\text{normal\_D}}$ |

---

### 3. âœ… DoÄŸru Ä°fadelerin SeÃ§imi

Bu sÄ±ralamalara gÃ¶re, grafiÄŸi doÄŸru yorumlayan ifadeler ÅŸunlardÄ±r:

* $$\mathbf{\sigma_{\text{normal\_D}} > \sigma_{\text{normal\_A}}}$$
    (En geniÅŸ olan D, en dar olan A'dan bÃ¼yÃ¼ktÃ¼r.)

* $$\mathbf{\mu_{\text{normal\_D}} > \mu_{\text{normal\_C}}}$$
    (En saÄŸdaki D, C'den daha bÃ¼yÃ¼k ortalamaya sahiptir.)

* $$\mathbf{\sigma_{\text{normal\_C}} > \sigma_{\text{normal\_B}}}$$
    (C, B'den daha yayvan/geniÅŸ bir daÄŸÄ±lÄ±ma sahiptir.)



