# ğŸ§  Makine Ã–ÄŸrenimi'nin OlasÄ±lÄ±k Temelleri (Probability Foundations of Machine Learning)

Makine Ã¶ÄŸrenimi, bÃ¼yÃ¼k Ã¶lÃ§Ã¼de bilinmeyen bir sonucun, elimizdeki verilere dayanarak ortaya Ã§Ä±kma **olasÄ±lÄ±ÄŸÄ±nÄ± hesaplama** sanatÄ±dÄ±r. Temelde ML, bir olasÄ±lÄ±k hesaplama makinesi olarak iÅŸlev gÃ¶rÃ¼r.

---

## 1. KoÅŸullu OlasÄ±lÄ±k (Conditional Probability) ğŸ“Š

Makine Ã¶ÄŸrenimindeki en yaygÄ±n kullanÄ±m alanÄ±, bir ÅŸeyin olasÄ±lÄ±ÄŸÄ±nÄ± **baÅŸka faktÃ¶rler (features)** verildiÄŸinde hesaplamaktÄ±r.

| Uygulama (Application) | Hesaplanan KoÅŸullu OlasÄ±lÄ±k | AÃ§Ä±klama (Explanation) |
| :--- | :--- | :--- |
| **Spam Tespiti** (Spam Detection) ğŸ“§ | P(Spam \| Kelimeler, AlÄ±cÄ±lar, ...) | Bir e-postanÄ±n **istenmeyen posta (spam)** olma olasÄ±lÄ±ÄŸÄ±, e-postadaki **kelimeler (words)** ve diÄŸer **Ã¶zellikler (features)** verildiÄŸinde. |
| **Duygu Analizi** (Sentiment Analysis) ğŸ˜Š | P(Mutlu \| Metindeki Kelimeler) | Bir metnin **mutlu (happy)** olma olasÄ±lÄ±ÄŸÄ±, iÃ§erdiÄŸi **kelimeler (words)** verildiÄŸinde. |
| **GÃ¶rÃ¼ntÃ¼ TanÄ±ma** (Image Recognition) ğŸ“¸ | P(Kedi \| Pikseller) | Bir resimde **kedi (cat)** olma olasÄ±lÄ±ÄŸÄ±, resimdeki **pikseller (pixels)** verildiÄŸinde. |

**Teknik TanÄ±m:** KoÅŸullu olasÄ±lÄ±k, **P(A \| B)** formÃ¼lÃ¼ ile ifade edilir ve "**B olayÄ± gerÃ§ekleÅŸtiÄŸinde A olayÄ±nÄ±n gerÃ§ekleÅŸme olasÄ±lÄ±ÄŸÄ±**" anlamÄ±na gelir. Makine Ã¶ÄŸrenimi **sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±nÄ±n (classifiers)** yaptÄ±ÄŸÄ± temel iÅŸ budur.

---

## 2. SÃ¼pervizyonlu Ã–ÄŸrenme ve KoÅŸullu OlasÄ±lÄ±k (Supervised Learning and Conditional Probability)

Metinde bahsedilen Spam Tespiti, Duygu Analizi ve GÃ¶rÃ¼ntÃ¼ TanÄ±ma Ã¶rnekleri **SÃ¼pervizyonlu Ã–ÄŸrenme (Supervised Learning)** alanÄ±na aittir.

* Bu alanda, model **etiketli veri (labeled data)** kullanÄ±larak eÄŸitilir ve sorulara cevap arar.
* **AmaÃ§:** Verilen girdi iÃ§in doÄŸru **etiketi (label)** tahmin etmektir.
* **Ã–rnekler:** Resim kedi mi? CÃ¼mle olumlu mu? E-posta spam mi?

---

## 3. Bayes Teoremi ve ArtÃ§Ä± OlasÄ±lÄ±k (Bayes' Theorem and Posterior Probability) ğŸ²

Bayes Teoremi, bir **sÄ±nÄ±flandÄ±rÄ±cÄ± (classifier)** oluÅŸturarak bir ÅŸeyin olasÄ±lÄ±ÄŸÄ±nÄ± baÅŸka bir ÅŸey verildiÄŸinde hesaplamanÄ±zÄ± saÄŸlayan matematiksel bir mekanizma sunar.

$$\mathbf{P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}}$$

OlasÄ±lÄ±ÄŸÄ±n hesaplanmasÄ±nda **Bayes Teoremi'nin** nasÄ±l kullanÄ±ldÄ±ÄŸÄ± aÃ§Ä±klanmÄ±ÅŸtÄ±r:

1.  **Ã–nsel OlasÄ±lÄ±k (Prior Probability):** BaÅŸlangÄ±Ã§ olasÄ±lÄ±ÄŸÄ±dÄ±r (Ã–rn: TÃ¼m e-postalar iÃ§inde spam oranÄ±, P(Spam)).
2.  **KanÄ±t (Evidence) veya Olay (Event):** Yeni bir bilginin ortaya Ã§Ä±kmasÄ± (Ã–rn: E-postada "lottery" kelimesinin geÃ§mesi).
3.  **ArtÃ§Ä± OlasÄ±lÄ±k (Posterior Probability):** Ã–nsel olasÄ±lÄ±ÄŸÄ±n yeni bilgiyle gÃ¼ncellenmiÅŸ halidir (Ã–rn: P(Spam \| Lottery)).

---

## 4. Jeneratif Modeller ve Saf OlasÄ±lÄ±k (Generative Models and Pure Probability) âœ¨

Metin, koÅŸullu olasÄ±lÄ±ÄŸÄ±n yanÄ± sÄ±ra **saf olasÄ±lÄ±klarÄ±n (pure probabilities)** kullanÄ±ldÄ±ÄŸÄ± bÃ¼yÃ¼k bir ML alanÄ±nÄ± daha tanÄ±tÄ±r: **Jeneratif Makine Ã–ÄŸrenimi (Generative Machine Learning)**. Bu, **GÃ¶zetimsiz Ã–ÄŸrenme (Unsupervised Learning)** alanÄ±nÄ±n bir parÃ§asÄ±dÄ±r.

* **AmaÃ§:** Modelin, var olan veriye benzeyen **yeni iÃ§erik** (gÃ¶rÃ¼ntÃ¼, metin, ses) Ã¼retmesini saÄŸlamaktÄ±r.
* **Ä°ÅŸleyiÅŸ:** Burada amaÃ§, koÅŸullu olasÄ±lÄ±k hesaplamak yerine, yeni Ã¼retilen verinin gerÃ§ekÃ§i olma olasÄ±lÄ±ÄŸÄ±nÄ± **maksimize etmektir (maximize probability)**.
    * **GÃ¶rÃ¼ntÃ¼ Ãœretimi (Image Generation - Ã–rn: StyleGAN):** Model, rastgele piksellerin insan yÃ¼zÃ¼ oluÅŸturma olasÄ±lÄ±ÄŸÄ±nÄ± **maksimize etmeye** Ã§alÄ±ÅŸÄ±r.
    * **Metin Ãœretimi (Text Generation):** Model, rastgele kelimelerin anlamlÄ± ve baÄŸlamÄ±na uygun bir metin oluÅŸturma olasÄ±lÄ±ÄŸÄ±nÄ± **maksimize etmeye** Ã§alÄ±ÅŸÄ±r.
 
    * # ğŸ’¡ Makine Ã–ÄŸrenmesinde Bayes Teoremi ve Ä°lgili Konular

Bayes Teoremi, makine Ã¶ÄŸrenmesinde **olasÄ±lÄ±ksal sÄ±nÄ±flandÄ±rma** algoritmalarÄ±nÄ±n temelini oluÅŸturur. Ã–zellikle **NaÃ¯ve Bayes SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±** gibi yaygÄ±n algoritmalarÄ± anlamak iÃ§in bu kavramlara derinlemesine hakim olmak kritiktir.

---

## ğŸ“ Bayes Teoremi'nin FormÃ¼lÃ¼ ve BileÅŸenleri

Bayes Teoremi, bir olayÄ±n gerÃ§ekleÅŸme olasÄ±lÄ±ÄŸÄ±nÄ±, Ã¶nceden bilinen koÅŸullu ve marjinal olasÄ±lÄ±klarÄ± kullanarak hesaplar.

$$\huge P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

| Terim | AdÄ± | AÃ§Ä±klama (Makine Ã–ÄŸrenmesi) |
| :--- | :--- | :--- |
| **P(A|B)** | **Sonsal OlasÄ±lÄ±k (Posterior)** | Verilen veri (B) ile Ã¶rneÄŸin belli bir sÄ±nÄ±fa (A) ait olma olasÄ±lÄ±ÄŸÄ±. (Hedefimiz budur!) |
| **P(B|A)** | **Olabilirlik (Likelihood)** | Verilen sÄ±nÄ±f (A) iÃ§in verinin (B) gÃ¶zlemlenme olasÄ±lÄ±ÄŸÄ±. |
| **P(A)** | **Ã–nsel OlasÄ±lÄ±k (Prior)** | B olayÄ± hakkÄ±nda hiÃ§bir bilgi olmadan A sÄ±nÄ±fÄ±nÄ±n genel olasÄ±lÄ±ÄŸÄ±. |
| **P(B)** | **KanÄ±t (Evidence)** | Sonsal olasÄ±lÄ±ÄŸÄ± normalize eden sabittir. |

## ğŸ¤– Naive Bayes SÄ±nÄ±flandÄ±rÄ±cÄ± Ã‡eÅŸitleri ve KarÅŸÄ±laÅŸtÄ±rmasÄ±

Naive Bayes, **Ã¶zelliklerin birbirinden baÄŸÄ±msÄ±z olduÄŸu** (saf varsayÄ±m) varsayÄ±mÄ±na dayanÄ±r ve basitliÄŸi ile Ã¶ne Ã§Ä±kar.

| Algoritma AdÄ± | Temel Ã–zellik VarsayÄ±mÄ± | Uygulama AlanÄ± | Ã–rnek Veri Tipi | AvantajlarÄ± |
| :--- | :--- | :--- | :--- | :--- |
| **Gaussian Naive Bayes** | Ã–zellikler **Normal (Gauss) daÄŸÄ±lÄ±mÄ±na** (Normal/Gaussian Distribution) uyar. | SÃ¼rekli sayÄ±sal verilerin olduÄŸu sÄ±nÄ±flandÄ±rma problemleri. | Boy, kilo, sÄ±caklÄ±k gibi sÃ¼rekli deÄŸerler. | HÄ±zlÄ± ve kÃ¼Ã§Ã¼k veri kÃ¼melerinde baÅŸarÄ±lÄ±dÄ±r. |
| **Multinomial Naive Bayes** | Ã–zellikler **Multinomial daÄŸÄ±lÄ±mÄ±na** (Multinomial Distribution) uyar (sayÄ±m verileri). | Metin sÄ±nÄ±flandÄ±rma (spam, duygu analizi). | Bir belgedeki kelimelerin frekansÄ± (sayÄ±mÄ±). | Metin verilerinde en baÅŸarÄ±lÄ± Ã§eÅŸitlerdendir. |
| **Bernoulli Naive Bayes** | Ã–zellikler **Bernoulli daÄŸÄ±lÄ±mÄ±na** (Bernoulli Distribution) uyar (ikili/Boolean). | Belge varlÄ±ÄŸÄ±/yokluÄŸu, ikili Ã¶zelliklerin olduÄŸu sÄ±nÄ±flandÄ±rmalar. | Kelimenin bir belgede bulunup bulunmamasÄ± (1/0). | Ä°kili Ã¶zellik setleri iÃ§in etkilidir. |

---

## ğŸ§  Bilinmesi Gereken Kritik Ek Konular

Bayes algoritmalarÄ±nÄ± etkili kullanmak iÃ§in anlaÅŸÄ±lmasÄ± gereken temel kavramlar:

### 1. KoÅŸullu BaÄŸÄ±msÄ±zlÄ±k VarsayÄ±mÄ± (Conditional Independence)
* **AÃ§Ä±klama:** NaÃ¯ve Bayes'in "saf" kÄ±smÄ± buradan gelir. Hedef sÄ±nÄ±f verildiÄŸinde, girdilerin (Ã¶zelliklerin) birbirlerinden baÄŸÄ±msÄ±z olduÄŸu varsayÄ±lÄ±r. Bu, hesaplama karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r.
* **Matematiksel Ä°fade:** $P(x_1, x_2, \dots, x_n | C) = \prod_{i=1}^{n} P(x_i | C)$

### 2. SÄ±fÄ±r Frekans Problemi ve Ã‡Ã¶zÃ¼mÃ¼
* **Problem:** EÄŸitim verisinde hiÃ§ gÃ¶rÃ¼lmeyen bir Ã¶zellik-sÄ±nÄ±f kombinasyonu test verisinde ortaya Ã§Ä±karsa, ilgili **Olabilirlik** ($P(B|A)$) sÄ±fÄ±r olur. Bu durumda, sonuÃ§ **Sonsal OlasÄ±lÄ±k** da sÄ±fÄ±rlanÄ±r.
* **Ã‡Ã¶zÃ¼m:** **Laplace YumuÅŸatmasÄ± (Laplace Smoothing)** kullanÄ±lÄ±r. TÃ¼m sayÄ±mlara kÃ¼Ã§Ã¼k bir pozitif deÄŸer ($\alpha$, genellikle 1) eklenerek sÄ±fÄ±r olasÄ±lÄ±klar engellenir.

### 3. Maksimum Sonsal OlasÄ±lÄ±k (Maximum A Posteriori - MAP) Karar KuralÄ±

* **AÃ§Ä±klama:** SÄ±nÄ±flandÄ±rma yaparken NaÃ¯ve Bayes, olasÄ± tÃ¼m sÄ±nÄ±flar ($C_k$) arasÄ±ndan **en yÃ¼ksek sonsal olasÄ±lÄ±ÄŸa** sahip olan sÄ±nÄ±fÄ± seÃ§er. Bu, modelin tahmin mekanizmasÄ±dÄ±r.


### 4. Bayes AÄŸlarÄ± (Bayesian Networks) ğŸŒ
* **AÃ§Ä±klama:** NaÃ¯ve Bayes'in baÄŸÄ±msÄ±zlÄ±k varsayÄ±mÄ±nÄ±n Ã¶tesine geÃ§en, Ã¶zellikler arasÄ±ndaki **baÄŸÄ±mlÄ±lÄ±klarÄ±** modelleyebilen daha geliÅŸmiÅŸ olasÄ±lÄ±ksal grafik modellerdir.
* **Ã–nemi:** Ã–zellikler arasÄ±ndaki nedensel iliÅŸkileri (YÃ¶nlendirilmiÅŸ Asiklik Grafikler - DAG) kullanarak daha doÄŸru, ancak daha karmaÅŸÄ±k Ã§Ä±karÄ±mlar saÄŸlar.

---

## âœ‰ï¸ Ã–rnek Uygulama: E-posta Spam Tespiti (Multinomial NB)

**AmaÃ§:** "Ãœcretsiz para" e-postasÄ±nÄ± sÄ±nÄ±flandÄ±rmak.

### 1. Ã–nsel OlasÄ±lÄ±klar (Prior)

| SÄ±nÄ±f | SayÄ±m | $P(C)$ |
| :--- | :--- | :--- |
| Spam | 3 | $3/5 = 0.6$ |
| Ham | 2 | $2/5 = 0.4$ |

### 2. Olabilirlikler (Likelihood) - Laplace YumuÅŸatmasÄ± UygulanmÄ±ÅŸ

KullanÄ±lan kelimeler: "Ãœcretsiz" ve "Para".

* $P(\text{Ãœcretsiz}|\text{Spam}) = 3/17$
* $P(\text{Para}|\text{Spam}) = 2/17$

* $P(\text{Ãœcretsiz}|\text{Ham}) = 1/14$
* $P(\text{Para}|\text{Ham}) = 1/14$

### 3. Sonsal OlasÄ±lÄ±k HesabÄ±

MAP kuralÄ±nÄ± uygulayarak:

* **Spam PuanÄ±:** $P(\text{Spam}|D) \propto P(\text{Ãœcretsiz}|\text{Spam}) \cdot P(\text{Para}|\text{Spam}) \cdot P(\text{Spam})$
    * Spam PuanÄ± $\propto (3/17) \cdot (2/17) \cdot 0.6 \approx 0.0124$

* **Ham PuanÄ±:** $P(\text{Ham}|D) \propto P(\text{Ãœcretsiz}|\text{Ham}) \cdot P(\text{Para}|\text{Ham}) \cdot P(\text{Ham})$
    * Ham PuanÄ± $\propto (1/14) \cdot (1/14) \cdot 0.4 \approx 0.0020$

**SonuÃ§:** $0.0124 > 0.0020$ olduÄŸu iÃ§in model, e-postayÄ± **SPAM** olarak sÄ±nÄ±flandÄ±rÄ±r. âœ…


